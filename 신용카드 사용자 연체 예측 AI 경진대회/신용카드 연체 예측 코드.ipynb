{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGi6414zmvG9"
   },
   "source": [
    " # 신용카드 사용자 연체 예측 AI 경진대회\n",
    " - 2021.04.05 ~ 2021.05.24\n",
    " - private : 0.67995 (165등, 상위 22%)\n",
    " ---\n",
    " 정형 데이터 대회 참가는 처음이었다.\n",
    "  처음 코드를 짤 때는 코드공유 게시판의 `최정명`님의 코드를 바탕으로 작성하였고, 이후 내가 원하는 방식으로 변수나, 모델을 수정하며 대회를 참가하였다.   \n",
    "    \n",
    "이번 대회를 통해 얻을 수 있었던 것은  \n",
    "1. 어떤 모델이든 일단 적용해 보고 봐야한다는것. \n",
    "    - RF의 성능이 꽤 괜찮았음.\n",
    "    - 앙상블은 어떤 경우라도 성능 향상이 보장됨.\n",
    "2. 정형데이터의 경우 Feature engineering가 정말 중요하다는 것.\n",
    "    - 다른 사람의 코드를 보니, 변수 추가나, 다양한 방식으로 전처리를 진행한 것을 보고 내가 조금 게을렀다고 생각 들었다.  \n",
    "  \n",
    "  \n",
    "  끝으로 결과가 다소 아쉽지만, 여러 가지 배울점이 많았던 대회이고 게을러지지 말아야겠다고 생각 드는 대회였다. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stuck-muslim"
   },
   "source": [
    "# 라이브러리 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ancient-translator"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>gender</th>\n",
       "      <th>car</th>\n",
       "      <th>reality</th>\n",
       "      <th>child_num</th>\n",
       "      <th>income_total</th>\n",
       "      <th>income_type</th>\n",
       "      <th>edu_type</th>\n",
       "      <th>family_type</th>\n",
       "      <th>house_type</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>phone</th>\n",
       "      <th>email</th>\n",
       "      <th>occyp_type</th>\n",
       "      <th>family_size</th>\n",
       "      <th>begin_month</th>\n",
       "      <th>credit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>Municipal apartment</td>\n",
       "      <td>-13899</td>\n",
       "      <td>-4709</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-11380</td>\n",
       "      <td>-1540</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-19087</td>\n",
       "      <td>-4434</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Managers</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-15088</td>\n",
       "      <td>-2092</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>State servant</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-15037</td>\n",
       "      <td>-2105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Managers</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index gender car reality  child_num  income_total           income_type  \\\n",
       "0      0      F   N       N          0      202500.0  Commercial associate   \n",
       "1      1      F   N       Y          1      247500.0  Commercial associate   \n",
       "2      2      M   Y       Y          0      450000.0               Working   \n",
       "3      3      F   N       Y          0      202500.0  Commercial associate   \n",
       "4      4      F   Y       Y          0      157500.0         State servant   \n",
       "\n",
       "                        edu_type     family_type           house_type  \\\n",
       "0               Higher education         Married  Municipal apartment   \n",
       "1  Secondary / secondary special  Civil marriage    House / apartment   \n",
       "2               Higher education         Married    House / apartment   \n",
       "3  Secondary / secondary special         Married    House / apartment   \n",
       "4               Higher education         Married    House / apartment   \n",
       "\n",
       "   DAYS_BIRTH  DAYS_EMPLOYED  FLAG_MOBIL  work_phone  phone  email  \\\n",
       "0      -13899          -4709           1           0      0      0   \n",
       "1      -11380          -1540           1           0      0      1   \n",
       "2      -19087          -4434           1           0      1      0   \n",
       "3      -15088          -2092           1           0      1      0   \n",
       "4      -15037          -2105           1           0      0      0   \n",
       "\n",
       "    occyp_type  family_size  begin_month  credit  \n",
       "0          NaN          2.0         -6.0     1.0  \n",
       "1     Laborers          3.0         -5.0     1.0  \n",
       "2     Managers          2.0        -22.0     2.0  \n",
       "3  Sales staff          2.0        -37.0     0.0  \n",
       "4     Managers          2.0        -26.0     2.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26457 entries, 0 to 26456\n",
      "Data columns (total 20 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   index          26457 non-null  int64  \n",
      " 1   gender         26457 non-null  object \n",
      " 2   car            26457 non-null  object \n",
      " 3   reality        26457 non-null  object \n",
      " 4   child_num      26457 non-null  int64  \n",
      " 5   income_total   26457 non-null  float64\n",
      " 6   income_type    26457 non-null  object \n",
      " 7   edu_type       26457 non-null  object \n",
      " 8   family_type    26457 non-null  object \n",
      " 9   house_type     26457 non-null  object \n",
      " 10  DAYS_BIRTH     26457 non-null  int64  \n",
      " 11  DAYS_EMPLOYED  26457 non-null  int64  \n",
      " 12  FLAG_MOBIL     26457 non-null  int64  \n",
      " 13  work_phone     26457 non-null  int64  \n",
      " 14  phone          26457 non-null  int64  \n",
      " 15  email          26457 non-null  int64  \n",
      " 16  occyp_type     18286 non-null  object \n",
      " 17  family_size    26457 non-null  float64\n",
      " 18  begin_month    26457 non-null  float64\n",
      " 19  credit         26457 non-null  float64\n",
      "dtypes: float64(4), int64(8), object(8)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# occyp_type에만 결측치 존재\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "altered-latin"
   },
   "source": [
    "# Data Preprocessing\n",
    "- EDA를 통한 데이터 전처리 진행\n",
    "- 결측치 NaN 값으로 채우기\n",
    "- 원-핫인코딩 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def drop_columns(df, drop_col):\n",
    "    \"\"\"\n",
    "    eda를 통해 확인한 불필요한 변수 삭제\n",
    "\n",
    "    파라미터 \n",
    "    ---\n",
    "    df : DataFrame\n",
    "        train or test\n",
    "    drop_col : list\n",
    "        제거 할 컬럼 명\n",
    "    returns\n",
    "    ---\n",
    "    df : DataFrame\n",
    "        불필요한 columns이 제거된 Dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.drop(drop_col, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_dupli(df, mode):\n",
    "    \"\"\"\n",
    "    중복을 제거하는 코드 \n",
    "\n",
    "    파라미터 \n",
    "    ---\n",
    "    df : DataFrame\n",
    "        train or test\n",
    "    mode : int\n",
    "        0 : credit제외 중복 제거\n",
    "        1 : credit, begin_month제외 중복 제거\n",
    "\n",
    "    returns \n",
    "    ---\n",
    "    df : DataFrame\n",
    "        중복이 제거된 dataframe    \n",
    "    \"\"\"\n",
    "    assert mode < 2, 'mode는 0과 1중 하나만 입력해주세요'\n",
    "\n",
    "    if mode == 0:\n",
    "        df = df.drop_duplicates(['gender', 'car', 'reality', 'child_num', 'income_total', 'income_type',\n",
    "                                 'edu_type', 'family_type', 'house_type', 'DAYS_BIRTH', 'DAYS_EMPLOYED',\n",
    "                                 'FLAG_MOBIL', 'work_phone', 'phone', 'email', 'occyp_type',\n",
    "                                 'family_size', 'begin_month'])\n",
    "\n",
    "    else:\n",
    "        df = df.drop_duplicates(['gender', 'car', 'reality', 'child_num', 'income_total', 'income_type',\n",
    "                                 'edu_type', 'family_type', 'house_type', 'DAYS_BIRTH', 'DAYS_EMPLOYED',\n",
    "                                 'FLAG_MOBIL', 'work_phone', 'phone', 'email', 'occyp_type',\n",
    "                                 'family_size'])\n",
    "\n",
    "    # index 초기화\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_numeric(df):\n",
    "    \"\"\"\n",
    "    수치형 데이터 중 음수를 양수로 변환 시켜주고,\n",
    "    일별 데이터를 년도별 데이터로 변환\n",
    "\n",
    "    파라미터\n",
    "    ---\n",
    "    df : DataFrame\n",
    "        train or test\n",
    "\n",
    "    returns\n",
    "    ---\n",
    "    df : DataFrame\n",
    "        수치형 데이터가 변환된 dataframe\n",
    "    \"\"\"\n",
    "    df['DAYS_BIRTH'] = -1 * df['DAYS_BIRTH'] / 365\n",
    "    df['DAYS_EMPLOYED'] = -1 * df['DAYS_EMPLOYED'] / 365\n",
    "    df['begin_month'] = -1 * df['begin_month']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def scaling(df, mode):\n",
    "    \"\"\"\n",
    "    중복을 제거하는 코드 \n",
    "\n",
    "    파라미터 \n",
    "    ---\n",
    "    df : DataFrame\n",
    "        train or test\n",
    "    mode : int\n",
    "        0 : log 변환 적용\n",
    "        1 : standard scaling 적용\n",
    "\n",
    "    returns \n",
    "    ---\n",
    "    df : DataFrame\n",
    "        scaling이 적용된 dataframe    \n",
    "    \"\"\"\n",
    "    assert mode < 2, 'mode는 0과 1중 하나만 입력해주세요'\n",
    "\n",
    "    # 수치형 데이터중 변수 중요도가 높은 몇개의 변수만 변환\n",
    "    columns = ['income_total', 'DAYS_EMPLOYED', 'DAYS_BIRTH']\n",
    "\n",
    "    if mode == 0:\n",
    "        # 로그 변환\n",
    "        for col in columns:\n",
    "            train[col] = np.log1p(train[col])\n",
    "            test[col] = np.log1p(test[col])\n",
    "\n",
    "    else:\n",
    "        standardScaler = StandardScaler()\n",
    "        standardScaler = standardScaler.fit(train[columns])\n",
    "\n",
    "        train[columns] = standardScaler.transform(train[columns])\n",
    "        # test 셋에도 동일 하게 적용.\n",
    "        test[columns] = standardScaler.transform(test[columns])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_boolen_type(df):\n",
    "    \"\"\"\n",
    "    phone, mobile 등 소지 여부를 나타내는 변수가 \n",
    "    int 형으로 입력 되어있었기 때문에 카테고리화 적용.\n",
    "\n",
    "    파라미터\n",
    "    ---\n",
    "    df : DataFrame\n",
    "        train or test\n",
    "\n",
    "    returns\n",
    "    ---\n",
    "    df : DataFrame\n",
    "        수치형 데이터가 변환된 dataframe\n",
    "    \"\"\"\n",
    "    columns = ['FLAG_MOBIL', 'work_phone', 'phone', 'email']\n",
    "    df[columns] = df[columns].astype('category')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_outlier(df, column):\n",
    "    \"\"\"\n",
    "    변수 중요도가 높은 것을 우선순위로 이상치 제거\n",
    "\n",
    "\n",
    "    파라미터\n",
    "    ---\n",
    "    df : DataFrame\n",
    "        train or test\n",
    "    columns : list\n",
    "        이상치를 제거할 변수가 담겨있는 list\n",
    "    returns\n",
    "    ---\n",
    "    df : DataFrame\n",
    "        수치형 데이터가 변환된 dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    for col in column:\n",
    "        df_ = df[col]\n",
    "        # 1분위수\n",
    "        quan_25 = np.percentile(df_.values, 25)\n",
    "\n",
    "        # 3분위수\n",
    "        quan_75 = np.percentile(df_.values, 75)\n",
    "\n",
    "        iqr = quan_75 - quan_25\n",
    "\n",
    "        lowest = quan_25 - iqr * 1.5\n",
    "        highest = quan_75 + iqr * 1.5\n",
    "        outlier_index = df_[(df_ < lowest) | (df_ > highest)].index\n",
    "        df.drop(outlier_index, axis=0, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(df, drop_col, duplicate_mode, scaling_mode, drop_outlier_columns, data='None'):\n",
    "    \"\"\"\n",
    "    위에서 정의한 전처리 함수를 한번에 적용하는 함수\n",
    "\n",
    "    파라미터 \n",
    "    ---\n",
    "    df : DataFrame\n",
    "        train or test\n",
    "\n",
    "    drop_col : list\n",
    "        drop 시킬 columns\n",
    "\n",
    "    duplicate_mode : int\n",
    "        0 : credit제외 중복 제거\n",
    "        1 : credit, begin_month제외 중복 제거\n",
    "\n",
    "    scaling_mode : int \n",
    "        0 : log 변환 적용\n",
    "        1 : standard scaling 적용\n",
    "\n",
    "    drop_outlier_columns: list\n",
    "        이상치를 제거할 변수가 담겨있는 list\n",
    "\n",
    "    data : string\n",
    "        해당 값이 cat 이면 catboost용 데이터를 생성 하기 위해 원핫 인코딩 미적용\n",
    "\n",
    "    returns \n",
    "    ---\n",
    "    df : DataFrame\n",
    "        전처리가 적용된 dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    df = drop_columns(df, drop_col)\n",
    "\n",
    "    # df = drop_dupli(df, duplicate_mode)\n",
    "\n",
    "    df = change_numeric(df)\n",
    "    df = scaling(df, scaling_mode)\n",
    "    # 결측치 처리\n",
    "    df.fillna('NaN', inplace=True)\n",
    "    df = change_boolen_type(df)\n",
    "\n",
    "    #df = drop_outlier(df, drop_outlier_columns)\n",
    "\n",
    "    # 원핫인코딩\n",
    "    if data == 'cat':\n",
    "        return df\n",
    "    df = pd.get_dummies(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제할 컬럼명을 저장할 list\n",
    "drop_col = ['index', 'child_num']\n",
    "DUPLICATE_MODE = 0\n",
    "SCALING_MODE = 1\n",
    "drop_outlier_columns = ['income_total', 'DAYS_EMPLOYED', 'family_size']\n",
    "\n",
    "train = data_preprocessing(train, drop_col=drop_col, duplicate_mode=DUPLICATE_MODE, scaling_mode=SCALING_MODE,\n",
    "                           drop_outlier_columns=drop_outlier_columns)\n",
    "test = data_preprocessing(test, drop_col=drop_col, duplicate_mode=DUPLICATE_MODE, scaling_mode=SCALING_MODE,\n",
    "                          drop_outlier_columns=drop_outlier_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pressed-velvet"
   },
   "source": [
    "# 모델링\n",
    "- 모델은 `Lightgbm`,`catboost`,`RandomForest`총 3개를 앙상블하여 결과값 도출\n",
    "- lgbm 모델만 optuna 라이브러리로 최적화 진행\n",
    "- 모델 검증 방법은 stritfied KFold 사용 (k = 10)\n",
    "- 각 모델 10개를 훈련하여 저장.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델링 전 학습 타겟 label 분리\n",
    "train_x = train.drop('credit', axis=1)\n",
    "train_y = train['credit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: Trial) -> float:\n",
    "    \"\"\"\n",
    "    optuna 라이브러리를 활용하여 모델 튜닝시 사용되는 함수.\n",
    "    \"\"\"\n",
    "    params_lgb = {\n",
    "        \"random_state\": 42,\n",
    "        \"verbosity\": -1,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.05, 0.1),\n",
    "        \"n_estimators\": 500,\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 30),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 0.6),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.3, 1.0),\n",
    "        \"subsample_freq\": trial.suggest_int(\"subsample_freq\", 1, 10),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 2, 30),\n",
    "    }\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        train_x, train_y, test_size=0.2, stratify=train_y)\n",
    "\n",
    "    model = LGBMClassifier(**params_lgb)\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    lgb_pred = model.predict_proba(X_valid)\n",
    "    log_score = log_loss(y_valid, lgb_pred)\n",
    "\n",
    "    return log_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-21 17:06:47,185]\u001b[0m A new study created in memory with name: lgbm_parameter_opt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# optna를 이용해 하이퍼 파라미터 튜닝할 준비를 해줍니다.\n",
    "sampler = TPESampler(seed=42)\n",
    "lgbm_study = optuna.create_study(\n",
    "    study_name=\"lgbm_parameter_opt\",\n",
    "    direction=\"minimize\",\n",
    "    sampler=sampler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7065383925084582\n",
      "Best trial: {'learning_rate': 0.07568316785311044, 'max_depth': 17, 'num_leaves': 249, 'colsample_bytree': 0.3387403565626488, 'subsample': 0.7717804630243458, 'subsample_freq': 5, 'min_child_samples': 11}\n"
     ]
    }
   ],
   "source": [
    "# n_trais = 20 으로 설정하여 lgbm 모델을 튜닝\n",
    "lgbm_study.optimize(objective, n_trials=20, show_progress_bar=True,)\n",
    "print(\"Best Score:\", lgbm_study.best_value)\n",
    "print(\"Best trial:\", lgbm_study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "folds = []\n",
    "for train_idx, valid_idx in skf.split(train_x, train_y):\n",
    "    folds.append((train_idx, valid_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "def training(model_name):\n",
    "    \"\"\"\n",
    "    모델이름을 입력받아 10-fold로 학습된 모델 리스트를 반환하는 함수\n",
    "\n",
    "    파라미터\n",
    "    ---\n",
    "    model_name : LGBM or RF or CAT\n",
    "        학습 시킬 모델\n",
    "    returns\n",
    "    ---\n",
    "    models : \n",
    "        학습 된 10개 모델\n",
    "    \"\"\"\n",
    "    random.seed(42)\n",
    "    models = {}\n",
    "    for fold in range(10):\n",
    "        print(\n",
    "            f'===================================={fold+1}============================================')\n",
    "        train_idx, valid_idx = folds[fold]\n",
    "        X_train, y_train = train_x.iloc[train_idx], train_y.iloc[train_idx]\n",
    "        X_valid, y_valid = train_x.iloc[valid_idx], train_y.iloc[valid_idx]\n",
    "\n",
    "        if model_name == 'RF':\n",
    "            model = RandomForestClassifier(\n",
    "                random_state=42, n_estimators=1000, verbose=False)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        elif model_name == 'LGBM':\n",
    "            model = LGBMClassifier(**lgbm_study.best_trial.params)\n",
    "            model.fit(X_train, y_train,\n",
    "                    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                    early_stopping_rounds=100, eval_metric='logloss',\n",
    "                    verbose=100)\n",
    "\n",
    "        elif model_name == 'CAT':\n",
    "            model = CatBoostClassifier(random_state=42, n_estimators=2000)\n",
    "            model.fit(X_train, y_train,\n",
    "                      eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                      early_stopping_rounds=50,\n",
    "                      verbose=100)\n",
    "\n",
    "        models[fold] = model\n",
    "\n",
    "        print(f'================================================================================\\n\\n')\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================1============================================\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================2============================================\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================3============================================\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================4============================================\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================5============================================\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================6============================================\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================7============================================\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================8============================================\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================9============================================\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================10============================================\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================1============================================\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.451697\tvalid_1's multi_logloss: 0.696987\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_logloss: 0.451697\tvalid_1's multi_logloss: 0.696987\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================2============================================\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.449103\tvalid_1's multi_logloss: 0.706522\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_logloss: 0.449103\tvalid_1's multi_logloss: 0.706522\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================3============================================\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.449813\tvalid_1's multi_logloss: 0.70811\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_logloss: 0.449813\tvalid_1's multi_logloss: 0.70811\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================4============================================\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.448239\tvalid_1's multi_logloss: 0.723238\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_logloss: 0.448239\tvalid_1's multi_logloss: 0.723238\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================5============================================\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.446051\tvalid_1's multi_logloss: 0.718703\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_logloss: 0.446051\tvalid_1's multi_logloss: 0.718703\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================6============================================\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.448218\tvalid_1's multi_logloss: 0.713118\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_logloss: 0.448218\tvalid_1's multi_logloss: 0.713118\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================7============================================\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.449703\tvalid_1's multi_logloss: 0.69803\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_logloss: 0.449703\tvalid_1's multi_logloss: 0.69803\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================8============================================\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.449722\tvalid_1's multi_logloss: 0.713603\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_logloss: 0.449722\tvalid_1's multi_logloss: 0.713603\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================9============================================\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.449015\tvalid_1's multi_logloss: 0.717965\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_logloss: 0.449015\tvalid_1's multi_logloss: 0.717965\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================10============================================\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.450474\tvalid_1's multi_logloss: 0.70406\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_logloss: 0.450474\tvalid_1's multi_logloss: 0.70406\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================1============================================\n",
      "Learning rate set to 0.088282\n",
      "0:\tlearn: 1.0489666\ttest: 1.0489666\ttest1: 1.0478465\tbest: 1.0478465 (0)\ttotal: 18.7ms\tremaining: 37.4s\n",
      "100:\tlearn: 0.7779418\ttest: 0.7779418\ttest1: 0.7838188\tbest: 0.7838188 (100)\ttotal: 1.52s\tremaining: 28.6s\n",
      "200:\tlearn: 0.7483379\ttest: 0.7483379\ttest1: 0.7706023\tbest: 0.7706023 (200)\ttotal: 2.94s\tremaining: 26.3s\n",
      "300:\tlearn: 0.7239866\ttest: 0.7239866\ttest1: 0.7602168\tbest: 0.7602168 (300)\ttotal: 4.38s\tremaining: 24.7s\n",
      "400:\tlearn: 0.7022703\ttest: 0.7022703\ttest1: 0.7529334\tbest: 0.7529334 (400)\ttotal: 5.8s\tremaining: 23.1s\n",
      "500:\tlearn: 0.6826749\ttest: 0.6826749\ttest1: 0.7476058\tbest: 0.7476058 (500)\ttotal: 7.2s\tremaining: 21.6s\n",
      "600:\tlearn: 0.6663316\ttest: 0.6663316\ttest1: 0.7415318\tbest: 0.7415318 (600)\ttotal: 8.62s\tremaining: 20.1s\n",
      "700:\tlearn: 0.6499521\ttest: 0.6499521\ttest1: 0.7361359\tbest: 0.7361359 (700)\ttotal: 10s\tremaining: 18.5s\n",
      "800:\tlearn: 0.6352179\ttest: 0.6352179\ttest1: 0.7335756\tbest: 0.7334704 (794)\ttotal: 11.2s\tremaining: 16.8s\n",
      "900:\tlearn: 0.6211778\ttest: 0.6211778\ttest1: 0.7304497\tbest: 0.7303555 (898)\ttotal: 12.3s\tremaining: 15s\n",
      "1000:\tlearn: 0.6093298\ttest: 0.6093298\ttest1: 0.7276752\tbest: 0.7276752 (1000)\ttotal: 13.3s\tremaining: 13.3s\n",
      "1100:\tlearn: 0.5981162\ttest: 0.5981162\ttest1: 0.7245648\tbest: 0.7245648 (1100)\ttotal: 14.4s\tremaining: 11.7s\n",
      "1200:\tlearn: 0.5870238\ttest: 0.5870238\ttest1: 0.7225519\tbest: 0.7225131 (1197)\ttotal: 15.4s\tremaining: 10.3s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7209184499\n",
      "bestIteration = 1249\n",
      "\n",
      "Shrink model to first 1250 iterations.\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================2============================================\n",
      "Learning rate set to 0.088282\n",
      "0:\tlearn: 1.0486699\ttest: 1.0486699\ttest1: 1.0491793\tbest: 1.0491793 (0)\ttotal: 6.46ms\tremaining: 12.9s\n",
      "100:\tlearn: 0.7754589\ttest: 0.7754589\ttest1: 0.8005844\tbest: 0.8005844 (100)\ttotal: 1.14s\tremaining: 21.5s\n",
      "200:\tlearn: 0.7452347\ttest: 0.7452347\ttest1: 0.7891587\tbest: 0.7891252 (199)\ttotal: 2.7s\tremaining: 24.2s\n",
      "300:\tlearn: 0.7211343\ttest: 0.7211343\ttest1: 0.7816077\tbest: 0.7816077 (300)\ttotal: 4.08s\tremaining: 23s\n",
      "400:\tlearn: 0.6995148\ttest: 0.6995148\ttest1: 0.7746430\tbest: 0.7746430 (400)\ttotal: 5.46s\tremaining: 21.8s\n",
      "500:\tlearn: 0.6803126\ttest: 0.6803126\ttest1: 0.7684764\tbest: 0.7684245 (499)\ttotal: 6.83s\tremaining: 20.4s\n",
      "600:\tlearn: 0.6636221\ttest: 0.6636221\ttest1: 0.7633107\tbest: 0.7633107 (600)\ttotal: 8.17s\tremaining: 19s\n",
      "700:\tlearn: 0.6477516\ttest: 0.6477516\ttest1: 0.7599971\tbest: 0.7598504 (685)\ttotal: 9.5s\tremaining: 17.6s\n",
      "800:\tlearn: 0.6337684\ttest: 0.6337684\ttest1: 0.7558230\tbest: 0.7558230 (800)\ttotal: 10.8s\tremaining: 16.2s\n",
      "900:\tlearn: 0.6205896\ttest: 0.6205896\ttest1: 0.7540756\tbest: 0.7540042 (899)\ttotal: 12.1s\tremaining: 14.8s\n",
      "1000:\tlearn: 0.6083641\ttest: 0.6083641\ttest1: 0.7511033\tbest: 0.7510809 (997)\ttotal: 13.3s\tremaining: 13.2s\n",
      "1100:\tlearn: 0.5971587\ttest: 0.5971587\ttest1: 0.7492046\tbest: 0.7491526 (1089)\ttotal: 14.5s\tremaining: 11.8s\n",
      "1200:\tlearn: 0.5859376\ttest: 0.5859376\ttest1: 0.7473606\tbest: 0.7473606 (1200)\ttotal: 15.9s\tremaining: 10.6s\n",
      "1300:\tlearn: 0.5758183\ttest: 0.5758183\ttest1: 0.7464942\tbest: 0.7464137 (1287)\ttotal: 17.3s\tremaining: 9.32s\n",
      "1400:\tlearn: 0.5660540\ttest: 0.5660540\ttest1: 0.7454595\tbest: 0.7454438 (1398)\ttotal: 18.7s\tremaining: 7.98s\n",
      "1500:\tlearn: 0.5568810\ttest: 0.5568810\ttest1: 0.7446962\tbest: 0.7446962 (1500)\ttotal: 20s\tremaining: 6.64s\n",
      "1600:\tlearn: 0.5474712\ttest: 0.5474712\ttest1: 0.7432723\tbest: 0.7432496 (1582)\ttotal: 22.5s\tremaining: 5.6s\n",
      "1700:\tlearn: 0.5387156\ttest: 0.5387156\ttest1: 0.7423614\tbest: 0.7423371 (1698)\ttotal: 24.7s\tremaining: 4.34s\n",
      "1800:\tlearn: 0.5305682\ttest: 0.5305682\ttest1: 0.7411993\tbest: 0.7411993 (1800)\ttotal: 26.3s\tremaining: 2.9s\n",
      "1900:\tlearn: 0.5232001\ttest: 0.5232001\ttest1: 0.7404557\tbest: 0.7401715 (1874)\ttotal: 28.3s\tremaining: 1.47s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7401714826\n",
      "bestIteration = 1874\n",
      "\n",
      "Shrink model to first 1875 iterations.\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================3============================================\n",
      "Learning rate set to 0.088282\n",
      "0:\tlearn: 1.0486211\ttest: 1.0486211\ttest1: 1.0493164\tbest: 1.0493164 (0)\ttotal: 10.3ms\tremaining: 20.7s\n",
      "100:\tlearn: 0.7770263\ttest: 0.7770263\ttest1: 0.8035185\tbest: 0.8035185 (100)\ttotal: 2.13s\tremaining: 40s\n",
      "200:\tlearn: 0.7463204\ttest: 0.7463204\ttest1: 0.7925762\tbest: 0.7925514 (199)\ttotal: 3.28s\tremaining: 29.4s\n",
      "300:\tlearn: 0.7205204\ttest: 0.7205204\ttest1: 0.7834357\tbest: 0.7834357 (300)\ttotal: 4.54s\tremaining: 25.6s\n",
      "400:\tlearn: 0.6994977\ttest: 0.6994977\ttest1: 0.7761410\tbest: 0.7761410 (400)\ttotal: 5.93s\tremaining: 23.7s\n",
      "500:\tlearn: 0.6803988\ttest: 0.6803988\ttest1: 0.7691722\tbest: 0.7691722 (500)\ttotal: 7.19s\tremaining: 21.5s\n",
      "600:\tlearn: 0.6636272\ttest: 0.6636272\ttest1: 0.7648047\tbest: 0.7648047 (600)\ttotal: 8.37s\tremaining: 19.5s\n",
      "700:\tlearn: 0.6488496\ttest: 0.6488496\ttest1: 0.7610870\tbest: 0.7609684 (699)\ttotal: 9.77s\tremaining: 18.1s\n",
      "800:\tlearn: 0.6344007\ttest: 0.6344007\ttest1: 0.7579569\tbest: 0.7579569 (800)\ttotal: 11.4s\tremaining: 17s\n",
      "900:\tlearn: 0.6214499\ttest: 0.6214499\ttest1: 0.7551068\tbest: 0.7551068 (900)\ttotal: 12.7s\tremaining: 15.5s\n",
      "1000:\tlearn: 0.6091259\ttest: 0.6091259\ttest1: 0.7526108\tbest: 0.7526108 (1000)\ttotal: 13.9s\tremaining: 13.9s\n",
      "1100:\tlearn: 0.5977932\ttest: 0.5977932\ttest1: 0.7492781\tbest: 0.7492781 (1100)\ttotal: 15.4s\tremaining: 12.5s\n",
      "1200:\tlearn: 0.5862082\ttest: 0.5862082\ttest1: 0.7481775\tbest: 0.7478701 (1163)\ttotal: 16.7s\tremaining: 11.1s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7478700526\n",
      "bestIteration = 1163\n",
      "\n",
      "Shrink model to first 1164 iterations.\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================4============================================\n",
      "Learning rate set to 0.088282\n",
      "0:\tlearn: 1.0487716\ttest: 1.0487716\ttest1: 1.0487446\tbest: 1.0487446 (0)\ttotal: 6.64ms\tremaining: 13.3s\n",
      "100:\tlearn: 0.7755294\ttest: 0.7755294\ttest1: 0.7986287\tbest: 0.7986287 (100)\ttotal: 1.18s\tremaining: 22.3s\n",
      "200:\tlearn: 0.7437837\ttest: 0.7437837\ttest1: 0.7868447\tbest: 0.7868447 (200)\ttotal: 2.42s\tremaining: 21.6s\n",
      "300:\tlearn: 0.7196912\ttest: 0.7196912\ttest1: 0.7784592\tbest: 0.7784351 (299)\ttotal: 3.6s\tremaining: 20.3s\n",
      "400:\tlearn: 0.6985355\ttest: 0.6985355\ttest1: 0.7727185\tbest: 0.7727185 (400)\ttotal: 4.82s\tremaining: 19.2s\n",
      "500:\tlearn: 0.6797042\ttest: 0.6797042\ttest1: 0.7665889\tbest: 0.7665889 (500)\ttotal: 6.02s\tremaining: 18s\n",
      "600:\tlearn: 0.6629926\ttest: 0.6629926\ttest1: 0.7627209\tbest: 0.7626933 (591)\ttotal: 7.12s\tremaining: 16.6s\n",
      "700:\tlearn: 0.6473161\ttest: 0.6473161\ttest1: 0.7598627\tbest: 0.7598627 (700)\ttotal: 8.05s\tremaining: 14.9s\n",
      "800:\tlearn: 0.6328046\ttest: 0.6328046\ttest1: 0.7568649\tbest: 0.7567230 (787)\ttotal: 8.99s\tremaining: 13.5s\n",
      "900:\tlearn: 0.6187088\ttest: 0.6187088\ttest1: 0.7541648\tbest: 0.7541648 (900)\ttotal: 9.93s\tremaining: 12.1s\n",
      "1000:\tlearn: 0.6060626\ttest: 0.6060626\ttest1: 0.7525570\tbest: 0.7525243 (999)\ttotal: 10.9s\tremaining: 10.9s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7517989573\n",
      "bestIteration = 1038\n",
      "\n",
      "Shrink model to first 1039 iterations.\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================5============================================\n",
      "Learning rate set to 0.088282\n",
      "0:\tlearn: 1.0488419\ttest: 1.0488419\ttest1: 1.0483518\tbest: 1.0483518 (0)\ttotal: 7.62ms\tremaining: 15.2s\n",
      "100:\tlearn: 0.7763784\ttest: 0.7763784\ttest1: 0.7917349\tbest: 0.7917349 (100)\ttotal: 923ms\tremaining: 17.4s\n",
      "200:\tlearn: 0.7455053\ttest: 0.7455053\ttest1: 0.7776859\tbest: 0.7776643 (199)\ttotal: 2.04s\tremaining: 18.3s\n",
      "300:\tlearn: 0.7192030\ttest: 0.7192030\ttest1: 0.7702000\tbest: 0.7701757 (299)\ttotal: 3.04s\tremaining: 17.2s\n",
      "400:\tlearn: 0.6982585\ttest: 0.6982585\ttest1: 0.7650897\tbest: 0.7650263 (399)\ttotal: 4.11s\tremaining: 16.4s\n",
      "500:\tlearn: 0.6789925\ttest: 0.6789925\ttest1: 0.7604623\tbest: 0.7604623 (500)\ttotal: 5.21s\tremaining: 15.6s\n",
      "600:\tlearn: 0.6621079\ttest: 0.6621079\ttest1: 0.7572333\tbest: 0.7572333 (600)\ttotal: 6.3s\tremaining: 14.7s\n",
      "700:\tlearn: 0.6465250\ttest: 0.6465250\ttest1: 0.7541141\tbest: 0.7541141 (700)\ttotal: 7.41s\tremaining: 13.7s\n",
      "800:\tlearn: 0.6323682\ttest: 0.6323682\ttest1: 0.7520579\tbest: 0.7520579 (800)\ttotal: 8.52s\tremaining: 12.7s\n",
      "900:\tlearn: 0.6189263\ttest: 0.6189263\ttest1: 0.7491063\tbest: 0.7491063 (900)\ttotal: 9.65s\tremaining: 11.8s\n",
      "1000:\tlearn: 0.6069520\ttest: 0.6069520\ttest1: 0.7474730\tbest: 0.7474489 (999)\ttotal: 10.8s\tremaining: 10.8s\n",
      "1100:\tlearn: 0.5961544\ttest: 0.5961544\ttest1: 0.7469638\tbest: 0.7469638 (1100)\ttotal: 11.9s\tremaining: 9.71s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7467242285\n",
      "bestIteration = 1126\n",
      "\n",
      "Shrink model to first 1127 iterations.\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================6============================================\n",
      "Learning rate set to 0.088282\n",
      "0:\tlearn: 1.0486105\ttest: 1.0486105\ttest1: 1.0494989\tbest: 1.0494989 (0)\ttotal: 7.49ms\tremaining: 15s\n",
      "100:\tlearn: 0.7763738\ttest: 0.7763738\ttest1: 0.7979229\tbest: 0.7979229 (100)\ttotal: 987ms\tremaining: 18.6s\n",
      "200:\tlearn: 0.7461910\ttest: 0.7461910\ttest1: 0.7840045\tbest: 0.7839254 (199)\ttotal: 2.31s\tremaining: 20.7s\n",
      "300:\tlearn: 0.7208345\ttest: 0.7208345\ttest1: 0.7758506\tbest: 0.7758506 (300)\ttotal: 3.35s\tremaining: 18.9s\n",
      "400:\tlearn: 0.6981430\ttest: 0.6981430\ttest1: 0.7692936\tbest: 0.7691763 (393)\ttotal: 4.36s\tremaining: 17.4s\n",
      "500:\tlearn: 0.6789422\ttest: 0.6789422\ttest1: 0.7652118\tbest: 0.7652118 (500)\ttotal: 5.37s\tremaining: 16.1s\n",
      "600:\tlearn: 0.6612362\ttest: 0.6612362\ttest1: 0.7609671\tbest: 0.7609641 (599)\ttotal: 6.4s\tremaining: 14.9s\n",
      "700:\tlearn: 0.6459778\ttest: 0.6459778\ttest1: 0.7571822\tbest: 0.7571822 (700)\ttotal: 7.42s\tremaining: 13.7s\n",
      "800:\tlearn: 0.6319983\ttest: 0.6319983\ttest1: 0.7545687\tbest: 0.7545687 (800)\ttotal: 8.45s\tremaining: 12.6s\n",
      "900:\tlearn: 0.6183252\ttest: 0.6183252\ttest1: 0.7517180\tbest: 0.7517180 (900)\ttotal: 9.61s\tremaining: 11.7s\n",
      "1000:\tlearn: 0.6058340\ttest: 0.6058340\ttest1: 0.7500737\tbest: 0.7500720 (999)\ttotal: 10.8s\tremaining: 10.8s\n",
      "1100:\tlearn: 0.5942999\ttest: 0.5942999\ttest1: 0.7484552\tbest: 0.7483932 (1098)\ttotal: 12.1s\tremaining: 9.85s\n",
      "1200:\tlearn: 0.5824008\ttest: 0.5824008\ttest1: 0.7474396\tbest: 0.7474104 (1162)\ttotal: 13.3s\tremaining: 8.87s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.747201185\n",
      "bestIteration = 1216\n",
      "\n",
      "Shrink model to first 1217 iterations.\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================7============================================\n",
      "Learning rate set to 0.088282\n",
      "0:\tlearn: 1.0487564\ttest: 1.0487564\ttest1: 1.0487355\tbest: 1.0487355 (0)\ttotal: 7.77ms\tremaining: 15.5s\n",
      "100:\tlearn: 0.7757092\ttest: 0.7757092\ttest1: 0.7986718\tbest: 0.7986718 (100)\ttotal: 1.4s\tremaining: 26.3s\n",
      "200:\tlearn: 0.7464919\ttest: 0.7464919\ttest1: 0.7854885\tbest: 0.7854885 (200)\ttotal: 2.77s\tremaining: 24.8s\n",
      "300:\tlearn: 0.7186308\ttest: 0.7186308\ttest1: 0.7744990\tbest: 0.7744990 (300)\ttotal: 5.62s\tremaining: 31.7s\n",
      "400:\tlearn: 0.6970971\ttest: 0.6970971\ttest1: 0.7655919\tbest: 0.7655919 (400)\ttotal: 7.08s\tremaining: 28.2s\n",
      "500:\tlearn: 0.6793185\ttest: 0.6793185\ttest1: 0.7592484\tbest: 0.7592484 (500)\ttotal: 8.34s\tremaining: 25s\n",
      "600:\tlearn: 0.6629469\ttest: 0.6629469\ttest1: 0.7533210\tbest: 0.7533201 (599)\ttotal: 9.53s\tremaining: 22.2s\n",
      "700:\tlearn: 0.6477365\ttest: 0.6477365\ttest1: 0.7504516\tbest: 0.7504052 (699)\ttotal: 10.7s\tremaining: 19.9s\n",
      "800:\tlearn: 0.6336545\ttest: 0.6336545\ttest1: 0.7466234\tbest: 0.7466234 (800)\ttotal: 12s\tremaining: 17.9s\n",
      "900:\tlearn: 0.6206534\ttest: 0.6206534\ttest1: 0.7434767\tbest: 0.7433511 (899)\ttotal: 13.2s\tremaining: 16s\n",
      "1000:\tlearn: 0.6090926\ttest: 0.6090926\ttest1: 0.7412552\tbest: 0.7412552 (1000)\ttotal: 14.3s\tremaining: 14.3s\n",
      "1100:\tlearn: 0.5974110\ttest: 0.5974110\ttest1: 0.7393818\tbest: 0.7393125 (1096)\ttotal: 15.5s\tremaining: 12.6s\n",
      "1200:\tlearn: 0.5861721\ttest: 0.5861721\ttest1: 0.7367793\tbest: 0.7366914 (1199)\ttotal: 16.6s\tremaining: 11s\n",
      "1300:\tlearn: 0.5758086\ttest: 0.5758086\ttest1: 0.7352865\tbest: 0.7352334 (1292)\ttotal: 17.8s\tremaining: 9.56s\n",
      "1400:\tlearn: 0.5656482\ttest: 0.5656482\ttest1: 0.7344647\tbest: 0.7340818 (1375)\ttotal: 19.1s\tremaining: 8.16s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7340817978\n",
      "bestIteration = 1375\n",
      "\n",
      "Shrink model to first 1376 iterations.\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================8============================================\n",
      "Learning rate set to 0.088282\n",
      "0:\tlearn: 1.0487208\ttest: 1.0487208\ttest1: 1.0489068\tbest: 1.0489068 (0)\ttotal: 8.71ms\tremaining: 17.4s\n",
      "100:\tlearn: 0.7748463\ttest: 0.7748463\ttest1: 0.7942140\tbest: 0.7942140 (100)\ttotal: 1.25s\tremaining: 23.5s\n",
      "200:\tlearn: 0.7465556\ttest: 0.7465556\ttest1: 0.7855561\tbest: 0.7855561 (200)\ttotal: 2.42s\tremaining: 21.7s\n",
      "300:\tlearn: 0.7209401\ttest: 0.7209401\ttest1: 0.7775537\tbest: 0.7775537 (300)\ttotal: 3.71s\tremaining: 20.9s\n",
      "400:\tlearn: 0.7000082\ttest: 0.7000082\ttest1: 0.7701413\tbest: 0.7700506 (399)\ttotal: 4.84s\tremaining: 19.3s\n",
      "500:\tlearn: 0.6806262\ttest: 0.6806262\ttest1: 0.7652937\tbest: 0.7652937 (500)\ttotal: 6.01s\tremaining: 18s\n",
      "600:\tlearn: 0.6638844\ttest: 0.6638844\ttest1: 0.7604361\tbest: 0.7604206 (599)\ttotal: 7.16s\tremaining: 16.7s\n",
      "700:\tlearn: 0.6479753\ttest: 0.6479753\ttest1: 0.7567624\tbest: 0.7567014 (699)\ttotal: 8.33s\tremaining: 15.4s\n",
      "800:\tlearn: 0.6340134\ttest: 0.6340134\ttest1: 0.7544902\tbest: 0.7544353 (796)\ttotal: 9.47s\tremaining: 14.2s\n",
      "900:\tlearn: 0.6205816\ttest: 0.6205816\ttest1: 0.7524093\tbest: 0.7524093 (900)\ttotal: 10.6s\tremaining: 12.9s\n",
      "1000:\tlearn: 0.6081616\ttest: 0.6081616\ttest1: 0.7505358\tbest: 0.7502953 (994)\ttotal: 11.8s\tremaining: 11.7s\n",
      "1100:\tlearn: 0.5963114\ttest: 0.5963114\ttest1: 0.7487734\tbest: 0.7487734 (1100)\ttotal: 12.9s\tremaining: 10.5s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7481339173\n",
      "bestIteration = 1127\n",
      "\n",
      "Shrink model to first 1128 iterations.\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================9============================================\n",
      "Learning rate set to 0.088282\n",
      "0:\tlearn: 1.0486175\ttest: 1.0486175\ttest1: 1.0494392\tbest: 1.0494392 (0)\ttotal: 12.9ms\tremaining: 25.8s\n",
      "100:\tlearn: 0.7774536\ttest: 0.7774536\ttest1: 0.8008112\tbest: 0.8008112 (100)\ttotal: 1.37s\tremaining: 25.8s\n",
      "200:\tlearn: 0.7471463\ttest: 0.7471463\ttest1: 0.7893699\tbest: 0.7893699 (200)\ttotal: 2.79s\tremaining: 25s\n",
      "300:\tlearn: 0.7210062\ttest: 0.7210062\ttest1: 0.7798267\tbest: 0.7798267 (300)\ttotal: 4.12s\tremaining: 23.3s\n",
      "400:\tlearn: 0.6993889\ttest: 0.6993889\ttest1: 0.7725855\tbest: 0.7725347 (398)\ttotal: 5.46s\tremaining: 21.8s\n",
      "500:\tlearn: 0.6811913\ttest: 0.6811913\ttest1: 0.7665874\tbest: 0.7665546 (498)\ttotal: 6.78s\tremaining: 20.3s\n",
      "600:\tlearn: 0.6627647\ttest: 0.6627647\ttest1: 0.7619197\tbest: 0.7619197 (600)\ttotal: 8.05s\tremaining: 18.7s\n",
      "700:\tlearn: 0.6466402\ttest: 0.6466402\ttest1: 0.7595071\tbest: 0.7592864 (676)\ttotal: 9.31s\tremaining: 17.3s\n",
      "800:\tlearn: 0.6327046\ttest: 0.6327046\ttest1: 0.7568757\tbest: 0.7568757 (800)\ttotal: 10.6s\tremaining: 15.8s\n",
      "900:\tlearn: 0.6192291\ttest: 0.6192291\ttest1: 0.7544116\tbest: 0.7541076 (882)\ttotal: 11.7s\tremaining: 14.3s\n",
      "1000:\tlearn: 0.6067220\ttest: 0.6067220\ttest1: 0.7525606\tbest: 0.7524884 (989)\ttotal: 12.8s\tremaining: 12.8s\n",
      "1100:\tlearn: 0.5956428\ttest: 0.5956428\ttest1: 0.7501175\tbest: 0.7501175 (1100)\ttotal: 13.9s\tremaining: 11.3s\n",
      "1200:\tlearn: 0.5844234\ttest: 0.5844234\ttest1: 0.7492978\tbest: 0.7490825 (1171)\ttotal: 15s\tremaining: 9.96s\n",
      "1300:\tlearn: 0.5740675\ttest: 0.5740675\ttest1: 0.7472773\tbest: 0.7472273 (1295)\ttotal: 16.1s\tremaining: 8.63s\n",
      "1400:\tlearn: 0.5647549\ttest: 0.5647549\ttest1: 0.7463608\tbest: 0.7461688 (1394)\ttotal: 17.1s\tremaining: 7.31s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7461688468\n",
      "bestIteration = 1394\n",
      "\n",
      "Shrink model to first 1395 iterations.\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================10============================================\n",
      "Learning rate set to 0.088282\n",
      "0:\tlearn: 1.0489962\ttest: 1.0489962\ttest1: 1.0476717\tbest: 1.0476717 (0)\ttotal: 12.2ms\tremaining: 24.5s\n",
      "100:\tlearn: 0.7770336\ttest: 0.7770336\ttest1: 0.7830478\tbest: 0.7830478 (100)\ttotal: 1.2s\tremaining: 22.6s\n",
      "200:\tlearn: 0.7479850\ttest: 0.7479850\ttest1: 0.7707558\tbest: 0.7707558 (200)\ttotal: 2.41s\tremaining: 21.6s\n",
      "300:\tlearn: 0.7221633\ttest: 0.7221633\ttest1: 0.7599220\tbest: 0.7599047 (299)\ttotal: 3.62s\tremaining: 20.5s\n",
      "400:\tlearn: 0.7003153\ttest: 0.7003153\ttest1: 0.7515675\tbest: 0.7515675 (400)\ttotal: 4.82s\tremaining: 19.2s\n",
      "500:\tlearn: 0.6807148\ttest: 0.6807148\ttest1: 0.7459645\tbest: 0.7459645 (500)\ttotal: 6s\tremaining: 18s\n",
      "600:\tlearn: 0.6640850\ttest: 0.6640850\ttest1: 0.7424733\tbest: 0.7424733 (600)\ttotal: 7.2s\tremaining: 16.8s\n",
      "700:\tlearn: 0.6483903\ttest: 0.6483903\ttest1: 0.7387094\tbest: 0.7387094 (700)\ttotal: 8.54s\tremaining: 15.8s\n",
      "800:\tlearn: 0.6341639\ttest: 0.6341639\ttest1: 0.7358666\tbest: 0.7358666 (800)\ttotal: 9.83s\tremaining: 14.7s\n",
      "900:\tlearn: 0.6200796\ttest: 0.6200796\ttest1: 0.7326338\tbest: 0.7326338 (900)\ttotal: 11s\tremaining: 13.5s\n",
      "1000:\tlearn: 0.6070434\ttest: 0.6070434\ttest1: 0.7294045\tbest: 0.7293005 (996)\ttotal: 12.2s\tremaining: 12.1s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7284690551\n",
      "bestIteration = 1037\n",
      "\n",
      "Shrink model to first 1038 iterations.\n",
      "================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_names = ['RF','LGBM','CAT']\n",
    "\n",
    "for model_name in model_names : \n",
    "    models = training(model_name)\n",
    "    # 학습 된 모델로 test inference \n",
    "    for fold in range(10):\n",
    "        submit.iloc[:, 1:] += models[fold].predict_proba(test)/30    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26457</td>\n",
       "      <td>0.112692</td>\n",
       "      <td>0.244362</td>\n",
       "      <td>0.976278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26458</td>\n",
       "      <td>0.260080</td>\n",
       "      <td>0.198007</td>\n",
       "      <td>0.875246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26459</td>\n",
       "      <td>0.110193</td>\n",
       "      <td>0.133125</td>\n",
       "      <td>1.090016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26460</td>\n",
       "      <td>0.184830</td>\n",
       "      <td>0.181942</td>\n",
       "      <td>0.966561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26461</td>\n",
       "      <td>0.157352</td>\n",
       "      <td>0.292204</td>\n",
       "      <td>0.883777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26462</td>\n",
       "      <td>0.087266</td>\n",
       "      <td>0.246333</td>\n",
       "      <td>0.999734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26463</td>\n",
       "      <td>0.585735</td>\n",
       "      <td>0.661335</td>\n",
       "      <td>0.086263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26464</td>\n",
       "      <td>0.227565</td>\n",
       "      <td>0.160282</td>\n",
       "      <td>0.945487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26465</td>\n",
       "      <td>0.091522</td>\n",
       "      <td>0.173047</td>\n",
       "      <td>1.068765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26466</td>\n",
       "      <td>0.126698</td>\n",
       "      <td>0.210394</td>\n",
       "      <td>0.996242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>26467</td>\n",
       "      <td>0.117686</td>\n",
       "      <td>0.175220</td>\n",
       "      <td>1.040427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>26468</td>\n",
       "      <td>0.145805</td>\n",
       "      <td>0.186700</td>\n",
       "      <td>1.000829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26469</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>0.212212</td>\n",
       "      <td>0.607397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26470</td>\n",
       "      <td>0.286790</td>\n",
       "      <td>0.202701</td>\n",
       "      <td>0.843843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>26471</td>\n",
       "      <td>0.168809</td>\n",
       "      <td>0.177172</td>\n",
       "      <td>0.987353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>26472</td>\n",
       "      <td>0.112829</td>\n",
       "      <td>0.404223</td>\n",
       "      <td>0.816281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>26473</td>\n",
       "      <td>0.122799</td>\n",
       "      <td>0.131105</td>\n",
       "      <td>1.079429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26474</td>\n",
       "      <td>0.431211</td>\n",
       "      <td>0.853394</td>\n",
       "      <td>0.048728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26475</td>\n",
       "      <td>0.437382</td>\n",
       "      <td>0.352139</td>\n",
       "      <td>0.543813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26476</td>\n",
       "      <td>0.075913</td>\n",
       "      <td>0.331373</td>\n",
       "      <td>0.926047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index         0         1         2\n",
       "0   26457  0.112692  0.244362  0.976278\n",
       "1   26458  0.260080  0.198007  0.875246\n",
       "2   26459  0.110193  0.133125  1.090016\n",
       "3   26460  0.184830  0.181942  0.966561\n",
       "4   26461  0.157352  0.292204  0.883777\n",
       "5   26462  0.087266  0.246333  0.999734\n",
       "6   26463  0.585735  0.661335  0.086263\n",
       "7   26464  0.227565  0.160282  0.945487\n",
       "8   26465  0.091522  0.173047  1.068765\n",
       "9   26466  0.126698  0.210394  0.996242\n",
       "10  26467  0.117686  0.175220  1.040427\n",
       "11  26468  0.145805  0.186700  1.000829\n",
       "12  26469  0.513724  0.212212  0.607397\n",
       "13  26470  0.286790  0.202701  0.843843\n",
       "14  26471  0.168809  0.177172  0.987353\n",
       "15  26472  0.112829  0.404223  0.816281\n",
       "16  26473  0.122799  0.131105  1.079429\n",
       "17  26474  0.431211  0.853394  0.048728\n",
       "18  26475  0.437382  0.352139  0.543813\n",
       "19  26476  0.075913  0.331373  0.926047"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답파일 생성\n",
    "submit.to_csv('final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Simple_Baseline LGBM - LB 0.72728.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
