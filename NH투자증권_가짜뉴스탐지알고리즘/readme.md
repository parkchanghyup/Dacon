# NH투자증권 빅데이터 경진대회
---
[League1] 가짜뉴스 탐지 알고리즘 개발 : [AI야, 진짜뉴스를 찾아줘!](https://dacon.io/competitions/official/235658/overview/description/)

- 544팀중 2등을 차지하여 장려상 수상


## 전처리

- 형태소 분석기로 `mecab` 사용
	- 분석 속도, 적절한 크기의 형태소 분리, 사용자 사전 추가의 편리성을 고려하여 `mecab`을 형태소 분석기로 선정
- 조사 제거
	- `-은`, `-이` 등 조사는 글자 수가 한개인 경우가 많고, **조사 단독으로는 의미를 지니지 못하기** 때문에 조사를 제거 해줌.
- 정규표현식을 이용하여 단어를 통일 및 제거
	- 통일
		- `OOO 기자 -> REPOETER` : 기자 이름은 중요하지 않으므로 REPOTER로 통일
		- `[,(,{` -> `[` : 비슷한 의미를 지닌 특수 기호 통일
		- `3억,200만원` -> `money` , `2018년` -> `year` : 돈, 시간 등은 숫자에 따라 다양한 단어가 될 수있음.그러나 숫자의 크기 보다는 **양사의 의미가 필요**하기 때문에 단어를 통일
	- 제거
		- `&rdquo;`,`{font-family}` : css 또는 html 문법이 문장 내부에 포함 된 경우가 있었음. 불필요한 단어 이므로 제거
	
	
- 사용자 사전 추가
	- 문장 내부에 복합명사나 고유명사가 많이 등장하였음
	- `추천주, 확진자, 셀트리온, NH투자증권` 등 **복합명사나 고유명사를 사용자 사전에 추가**

## 변수추가

전처리된 데이터를 바탕으로 총 6개의 변수를 추가함   
먼저 Content와 Title 모두 가짜뉴스와 진짜뉴스의 시작과 끝의 품사에서 큰 차이를 보였기 때문에 다음 4개의 변수를 추가해줌. 
<br/>  

`First_pos_content`, `Last_pos_content`, `First_pos_title `, `Last_pos_tite `  

그리고 가짜/진짜 뉴스에 따라 기사 내에서 문장의 위치가 조금씩 차이를 보였기 때문에, `ord_div` 변수를 추가해주고, 똑같은 문장의 반복 등장 횟수인 `counts`를 추가 함.

- First_pos_content : Content의 시작 단어의 품사
- Last_pos_content : Content의 끝 단어의 품사
- First_pos_title : Title의 시작 단어의 품사
- Last_pos_tite : Title의 끝 단어 품사
- ord_div : 문장 내 기사의 위치
- counts : 문장의 반복 등장 횟수

## 모델링

- 머신러닝(LGBM)과 딥러닝 모델(Multi kernel CNN) 두개를 사용
- 정확도는 두개의 모델 다 99.3%로 거의 동일 하였으나 분석 속도는 LGBM이 더 빠름.
- 그리고 LGBM 모델은 CNN 모델과 달리 변수해석이 가능하다는 큰 장점이 존재.
- 위의 근거를 바탕으로 머신러닝(LGBM)모델을 최종 모델로 선정
- 최종 private score는 `0.99183`으로 단순 정확도만으로 전체 8등 기록.


