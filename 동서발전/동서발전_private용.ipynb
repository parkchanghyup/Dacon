{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "동서발전.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peEFCG5MxEtq"
      },
      "source": [
        "## 모듈 임포트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dgHzDk2xEtr"
      },
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import lightgbm as lgb"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XvNCa0cxEts"
      },
      "source": [
        "## 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wM2mlOr266NW",
        "outputId": "2ce1c0bb-06be-47f3-f615-a3f13b2c19c7"
      },
      "source": [
        "!wget 'https://bit.ly/3dD5MU9'\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile('3dD5MU9', 'r') as existing_zip:\n",
        "    existing_zip.extractall('data')"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-09 13:24:30--  https://bit.ly/3dD5MU9\n",
            "Resolving bit.ly (bit.ly)... 67.199.248.10, 67.199.248.11\n",
            "Connecting to bit.ly (bit.ly)|67.199.248.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://drive.google.com/uc?export=download&id=1kkF00wW8v0npJ8S2nA7--eMTH3gOL03z [following]\n",
            "--2021-06-09 13:24:31--  https://drive.google.com/uc?export=download&id=1kkF00wW8v0npJ8S2nA7--eMTH3gOL03z\n",
            "Resolving drive.google.com (drive.google.com)... 142.250.141.113, 142.250.141.138, 142.250.141.102, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.250.141.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-14-94-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/5nnm76ck6o8qmdtldmil2jot6aqe9mr3/1623245025000/00192245294648390361/*/1kkF00wW8v0npJ8S2nA7--eMTH3gOL03z?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-06-09 13:24:38--  https://doc-14-94-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/5nnm76ck6o8qmdtldmil2jot6aqe9mr3/1623245025000/00192245294648390361/*/1kkF00wW8v0npJ8S2nA7--eMTH3gOL03z?e=download\n",
            "Resolving doc-14-94-docs.googleusercontent.com (doc-14-94-docs.googleusercontent.com)... 216.58.192.97, 2607:f8b0:4026:803::2001\n",
            "Connecting to doc-14-94-docs.googleusercontent.com (doc-14-94-docs.googleusercontent.com)|216.58.192.97|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-zip-compressed]\n",
            "Saving to: ‘3dD5MU9.1’\n",
            "\n",
            "3dD5MU9.1               [ <=>                ]   2.07M  11.5MB/s    in 0.2s    \n",
            "\n",
            "2021-06-09 13:24:39 (11.5 MB/s) - ‘3dD5MU9.1’ saved [2172031]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc5-Zx_kxEts"
      },
      "source": [
        "energy = pd.read_csv('data/energy.csv')\n",
        "dangjin_fcst = pd.read_csv('./data/dangjin_fcst_data.csv')\n",
        "ulsan_fcst = pd.read_csv('./data/ulsan_fcst_data.csv')"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaxITLK3xEtt"
      },
      "source": [
        "## 데이터 병합 \n",
        "- 가장 나중의 예측 데이터가 가장 좋다고 가정."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAqZEnduxEtt"
      },
      "source": [
        "def to_date(x):\n",
        "    return timedelta(hours=x)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioZjk_yFxEtt"
      },
      "source": [
        "def generate_df(df_):\n",
        "    df = df_.copy()\n",
        "\n",
        "    df['Forecast_time'] = pd.to_datetime(df['Forecast time'])\n",
        "\n",
        "    # 20 시\n",
        "    a = df[df[\"forecast\"] == 4.0]\n",
        "    a = a[a[\"Forecast time\"].apply(lambda x: \"20:00:00\" in x)]\n",
        "    a.loc[:, 'Forecast_time'] = a.loc[:, 'Forecast_time'] + a.loc[:, 'forecast'].map(to_date)\n",
        "\n",
        "    # 23 시\n",
        "    b = df[df[\"forecast\"] <= 22]\n",
        "    b = b[b[\"Forecast time\"].apply(lambda x: \"23:00:00\" in x)]\n",
        "    b.loc[:, 'Forecast_time'] = b.loc[:, 'Forecast_time'] + b.loc[:, 'forecast'].map(to_date)\n",
        "\n",
        "    # 병합\n",
        "    c = pd.concat([a, b])\n",
        "    print(f\"20시 사용 데이터 길이 : {len(a)}\")\n",
        "    print(f\"23시 사용 데이터 길이 : {len(b)}\")\n",
        "    print(f\"합친 데이터 길이 : {len(c)}\")\n",
        "    print()\n",
        "\n",
        "    # 정렬\n",
        "    c.sort_values(by=['Forecast_time'], inplace=True)\n",
        "    c = c[['Forecast_time', 'Temperature', 'Humidity', 'WindSpeed', 'WindDirection', 'Cloud']]\n",
        "\n",
        "    return c"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy4imRuixEtu",
        "outputId": "6ab46389-126f-484f-81fc-9a72222500b5"
      },
      "source": [
        "dangjin_filled = generate_df(dangjin_fcst)\n",
        "ulsan_filled = generate_df(ulsan_fcst)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20시 사용 데이터 길이 : 1096\n",
            "23시 사용 데이터 길이 : 7672\n",
            "합친 데이터 길이 : 8768\n",
            "\n",
            "20시 사용 데이터 길이 : 1096\n",
            "23시 사용 데이터 길이 : 7672\n",
            "합친 데이터 길이 : 8768\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXgEGLQhxEtu"
      },
      "source": [
        "## 보간"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2jTqIiJxEtu"
      },
      "source": [
        "def interpolate_df(df, method='linear'):\n",
        "    new_df = pd.DataFrame()\n",
        "    new_df['Forecast_time'] = pd.date_range(start=df['Forecast_time'].iloc[0], end=df['Forecast_time'].iloc[-1], freq='H')\n",
        "    new_df = pd.merge(new_df, df, on='Forecast_time', how='outer')\n",
        "    return new_df.interpolate(method=method)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4OTPM8DxEtv"
      },
      "source": [
        "dangjin_interpolated = interpolate_df(dangjin_filled, method='linear')\n",
        "ulsan_interpolated = interpolate_df(ulsan_filled, method='linear')"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bk82ximn-Sc"
      },
      "source": [
        "## 피처엔지니어링"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmnCH_mr0iko",
        "outputId": "ef4ae60c-6310-49ee-a7c6-6be84a206550"
      },
      "source": [
        "!pip install Catboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/41/24e14322b9986cf72a8763e0a0a69cc256cf963cf9502c8f0044a62c1ae8/catboost-0.26-cp37-none-manylinux1_x86_64.whl (69.2MB)\n",
            "\u001b[K     |████████████████████████████████| 69.2MB 71kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from Catboost) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from Catboost) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from Catboost) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from Catboost) (3.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from Catboost) (4.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from Catboost) (0.10.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from Catboost) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->Catboost) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->Catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->Catboost) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->Catboost) (2.4.7)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->Catboost) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->Catboost) (2018.9)\n",
            "Installing collected packages: Catboost\n",
            "Successfully installed Catboost-0.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS9O3qBt0xds"
      },
      "source": [
        "from catboost import CatBoostRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7-tPohPxEtv"
      },
      "source": [
        "## 학습 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM6Rd7mCxEtw"
      },
      "source": [
        "def train_datast(energy_df, fcst_df, target):\n",
        "    # 일기 예보 있는 날짜만 선택\n",
        "    energy = energy_df.loc[24:]\n",
        "    energy.index = range(energy.shape[0])\n",
        "    \n",
        "    # 발전량 데이터가 있는 날짜만 선택\n",
        "    fcst = fcst_df.loc[:25608-1]\n",
        "    fcst.index = range(fcst.shape[0])\n",
        "    \n",
        "    # 발전량과 일기예보 연결\n",
        "    concat_df = pd.concat([energy, fcst], axis=1)\n",
        "    \n",
        "    # 예보 시간 및 날짜 정보 feature로 추가\n",
        "    concat_df['date'] = concat_df['Forecast_time'].str.split(' ').str[0]\n",
        "    concat_df['hour'] = concat_df['Forecast_time'].str.split(' ').str[1].str.split(':').str[0].astype(int)\n",
        "    \n",
        "    concat_df['year'] = concat_df['date'].str.split('-').str[0].astype(int)\n",
        "    concat_df['month'] = concat_df['date'].str.split('-').str[1].astype(int)\n",
        "    concat_df['day'] = concat_df['date'].str.split('-').str[2].astype(int)\n",
        "    \n",
        "    # 예보 시간, 날짜, 기상 예보 및 발전량 선택\n",
        "    feature_df = concat_df[['year', 'month', 'day', 'hour', 'Temperature', 'Humidity', 'WindSpeed', 'WindDirection', 'Cloud', target]]\n",
        "    \n",
        "    # 마지막 30일을 검증데이터셋으로 나머지를 학습 데이터셋으로 선택\n",
        "    train_df = feature_df.iloc[:-24*90]\n",
        "    val_df = feature_df.iloc[-24*90:]\n",
        "    \n",
        "    # 발전량이 0인 데이터를 제외\n",
        "    #train_df = train_df[train_df[target]!=0]\n",
        "    \n",
        "    train_x = train_df.loc[:, 'year':'Cloud'].to_numpy()\n",
        "    train_y = train_df[target].to_numpy()\n",
        "    val_x = val_df.loc[:, 'year':'Cloud'].to_numpy()\n",
        "    val_y = val_df[target].to_numpy()\n",
        "    \n",
        "    return train_x, train_y, val_x, val_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbqi4HHwfgXY"
      },
      "source": [
        "## bayesian optimization \n",
        "---\n",
        "- bayesian optimization 를 이용하여 하이퍼 파라미터 튜닝\n",
        "- lgbm만 적용."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PMHrrknfhhV",
        "outputId": "5282defa-f6bc-4d79-9c74-27bbbaee8ade"
      },
      "source": [
        "# bayesian optimization 패키지 설치\n",
        "!pip install bayesian-optimization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7a/fd8059a3881d3ab37ac8f72f56b73937a14e8bb14a9733e68cc8b17dbe3c/bayesian-optimization-1.2.0.tar.gz\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.0.1)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-cp37-none-any.whl size=11686 sha256=04502a0c57d5e9fa1de9dfcb44241bd0aceef1a45256e0266a7979db97ad5c61\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/56/ae/e0e3c1fc1954dc3ec712e2df547235ed072b448094d8f94aec\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPzroRg_flq3"
      },
      "source": [
        "#from bayes_opt import BayesianOptimization\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import log_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC577FiJxEtx"
      },
      "source": [
        "## LightGBM Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbrhwrghxEtx"
      },
      "source": [
        "dangjin_interpolated['Forecast_time'] = dangjin_interpolated['Forecast_time'].astype('str')\n",
        "ulsan_interpolated['Forecast_time'] = ulsan_interpolated['Forecast_time'].astype('str')"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imlrsCkKxEty"
      },
      "source": [
        "## 당진 수상태양광 예측 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3ssEf4c1yuv"
      },
      "source": [
        "energy = energy.fillna(0)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIg1h8Os6SpV"
      },
      "source": [
        "bayesian_params = {\n",
        "    'max_depth': (5, 20), \n",
        "    'num_leaves': (24, 64), \n",
        "    'min_child_samples': (10, 200), \n",
        "    'min_child_weight':(1, 50),\n",
        "    'subsample':(0.5, 1.0),\n",
        "    'colsample_bytree': (0.5, 1.0),\n",
        "    'max_bin':(10, 500),\n",
        "    'reg_lambda':(0.001, 10),\n",
        "    'reg_alpha': (0.01, 50) \n",
        "}\n",
        "\n",
        "def lgb_eval(max_depth, num_leaves, min_child_samples, min_child_weight, subsample, \n",
        "                colsample_bytree,max_bin, reg_lambda, reg_alpha):\n",
        "    params = {\n",
        "        \"n_estimators\":1000, \"learning_rate\":0.01,\n",
        "        'max_depth': int(round(max_depth)), #  호출 시 실수형 값이 들어오므로 정수형 하이퍼 파라미터는 정수형으로 변경 \n",
        "        'num_leaves': int(round(num_leaves)), \n",
        "        'min_child_samples': int(round(min_child_samples)),\n",
        "        'min_child_weight': int(round(min_child_weight)),\n",
        "        'subsample': max(min(subsample, 1), 0), \n",
        "        'colsample_bytree': max(min(colsample_bytree, 1), 0),\n",
        "        'max_bin':  max(int(round(max_bin)),10),\n",
        "        'reg_lambda': max(reg_lambda,0),\n",
        "        'reg_alpha': max(reg_alpha, 0),\n",
        "        \"metric\" : 'rmse'\n",
        "    }\n",
        "    cv_result = lgb.cv(params, train_data, nfold=5, seed=0, verbose_eval =200,stratified=False)\n",
        "    return (-1.0 * np.array(cv_result['rmse-mean'])).max()\n",
        "\n",
        "train_x, train_y, val_x, val_y = train_datast(energy, dangjin_interpolated, target='dangjin_floating')\n",
        "train_data = lgb.Dataset(train_x, train_y)\n",
        "lgbBO = BayesianOptimization(lgb_eval, bayesian_params, random_state=42)\n",
        "\n",
        "\n",
        "lgbBO.maximize(init_points=5, n_iter=25)\n",
        "####################################################\n",
        "# dictionary에 있는 target값을 모두 추출\n",
        "target_list = []\n",
        "for result in lgbBO.res:\n",
        "    target = result['target']\n",
        "    target_list.append(target)\n",
        "print(target_list)\n",
        "# 가장 큰 target 값을 가지는 순번(index)를 추출\n",
        "print('maximum target index:', np.argmax(np.array(target_list)))\n",
        "\n",
        "#################################################################\n",
        "# 가장 큰 target값을 가지는 index값을 기준으로 res에서 해당 parameter 추출. \n",
        "max_dict = lgbBO.res[np.argmax(np.array(target_list))]\n",
        "print(max_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm4_s5w0KAKT"
      },
      "source": [
        "## K-fold dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhRkvI5oAB1R"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhDXMNMiAaf1"
      },
      "source": [
        "def kfold_datast(energy_df, fcst_df, target):\n",
        "    # 일기 예보 있는 날짜만 선택\n",
        "    energy = energy_df.loc[24:]\n",
        "    energy.index = range(energy.shape[0])\n",
        "    \n",
        "    # 발전량 데이터가 있는 날짜만 선택\n",
        "    fcst = fcst_df.loc[:25608-1]\n",
        "    fcst.index = range(fcst.shape[0])\n",
        "    \n",
        "    # 발전량과 일기예보 연결\n",
        "    concat_df = pd.concat([energy, fcst], axis=1)\n",
        "    \n",
        "    # 예보 시간 및 날짜 정보 feature로 추가\n",
        "    concat_df['date'] = concat_df['Forecast_time'].str.split(' ').str[0]\n",
        "    concat_df['hour'] = concat_df['Forecast_time'].str.split(' ').str[1].str.split(':').str[0].astype(int)\n",
        "    \n",
        "    concat_df['year'] = concat_df['date'].str.split('-').str[0].astype(int)\n",
        "    concat_df['month'] = concat_df['date'].str.split('-').str[1].astype(int)\n",
        "    concat_df['day'] = concat_df['date'].str.split('-').str[2].astype(int)\n",
        "    \n",
        "    # 예보 시간, 날짜, 기상 예보 및 발전량 선택\n",
        "    feature_df = concat_df[['year', 'month', 'day', 'hour', 'Temperature', 'Humidity', 'WindSpeed', 'WindDirection', 'Cloud', target]]\n",
        "    return feature_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD9U_zfLA-ew"
      },
      "source": [
        "random.seed(42)\n",
        "cat1_models={}\n",
        "target = 'dangjin_floating'\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "folds=[]\n",
        "train = kfold_datast (energy, dangjin_interpolated, target=target)\n",
        "\n",
        "\n",
        "for train_idx, valid_idx in skf.split(train, train['dangjin_floating']):\n",
        "    folds.append((train_idx, valid_idx))\n",
        "\n",
        "for fold in range(10):\n",
        "    print(f'===================================={fold+1}============================================')\n",
        "    train_idx, valid_idx = folds[fold]\n",
        "    train_x, val_x, train_y, val_y = train.drop([target],axis=1).iloc[train_idx].values, train.drop([target],axis=1).iloc[valid_idx].values,\\\n",
        "                                         train[target][train_idx].values, train[target][valid_idx].values \n",
        "    cat1 = CatBoostRegressor(n_estimators=5000 ,random_seed=42, learning_rate=0.005,depth = 10,loss_function='MultiRMSE')\n",
        "    cat1.fit(train_x, train_y,\n",
        "                    eval_set=[(train_x, train_y), (val_x, val_y)],\n",
        "                    early_stopping_rounds=50,verbose=100)\n",
        "    cat1_models[fold]=cat1\n",
        "    print(f'================================================================================\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTggmqyFBvoD"
      },
      "source": [
        "random.seed(42)\n",
        "lgb1_models={}\n",
        "target = 'dangjin_floating'\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "folds=[]\n",
        "train = kfold_datast (energy, dangjin_interpolated, target=target)\n",
        "\n",
        "\n",
        "for train_idx, valid_idx in skf.split(train, train['dangjin_floating']):\n",
        "    folds.append((train_idx, valid_idx))\n",
        "\n",
        "for fold in range(10):\n",
        "    print(f'===================================={fold+1}============================================')\n",
        "    train_idx, valid_idx = folds[fold]\n",
        "    train_x, val_x, train_y, val_y = train.drop([target],axis=1).iloc[train_idx].values, train.drop([target],axis=1).iloc[valid_idx].values,\\\n",
        "                                         train[target][train_idx].values, train[target][valid_idx].values \n",
        "    lgb = LGBMRegressor(n_estimators=5000 ,random_seed=42, learning_rate=0.005,depth = 8,loss_function='MultiRMSE',\n",
        "                                        colsample_bytree =  1,max_depth = 17, min_child_samples = 17, min_child_weight = 14, num_leaves = 63, reg_alpha=49.75855787791481, reg_lambda= 0.026935271560602856, subsample= 1.0)\n",
        "    lgb.fit(train_x, train_y,\n",
        "                    eval_set=[(train_x, train_y), (val_x, val_y)],\n",
        "                    early_stopping_rounds=100,verbose=100)\n",
        "    lgb1_models[fold]=lgb\n",
        "    print(f'================================================================================\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XQQ7cKV06e0",
        "outputId": "33cd8f97-641a-4b66-90ad-368685e6af03"
      },
      "source": [
        "train_x, train_y, val_x, val_y = train_datast(energy, dangjin_interpolated, target='dangjin_floating')\n",
        "cat1 = CatBoostRegressor(n_estimators=5000 ,random_seed=42, learning_rate=0.005,depth = 10,loss_function='MultiRMSE')\n",
        "cat1.fit(train_x, train_y,\n",
        "                  eval_set=[(train_x, train_y), (val_x, val_y)],\n",
        "                  early_stopping_rounds=100,verbose=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 194.1432430\ttest: 194.1432430\ttest1: 155.7049481\tbest: 155.7049481 (0)\ttotal: 70.8ms\tremaining: 5m 53s\n",
            "100:\tlearn: 136.4752349\ttest: 136.4752349\ttest1: 111.4580269\tbest: 111.4580269 (100)\ttotal: 1.85s\tremaining: 1m 29s\n",
            "200:\tlearn: 103.8935196\ttest: 103.8935196\ttest1: 87.9731854\tbest: 87.9731854 (200)\ttotal: 3.62s\tremaining: 1m 26s\n",
            "300:\tlearn: 86.1496839\ttest: 86.1496839\ttest1: 75.7249464\tbest: 75.7249464 (300)\ttotal: 5.35s\tremaining: 1m 23s\n",
            "400:\tlearn: 76.7953546\ttest: 76.7953546\ttest1: 69.8562012\tbest: 69.8562012 (400)\ttotal: 7.1s\tremaining: 1m 21s\n",
            "500:\tlearn: 71.4403474\ttest: 71.4403474\ttest1: 66.9486053\tbest: 66.9486053 (500)\ttotal: 8.86s\tremaining: 1m 19s\n",
            "600:\tlearn: 68.1910431\ttest: 68.1910431\ttest1: 65.4323814\tbest: 65.4323814 (600)\ttotal: 10.7s\tremaining: 1m 18s\n",
            "700:\tlearn: 65.8717864\ttest: 65.8717864\ttest1: 64.6853087\tbest: 64.6853087 (700)\ttotal: 12.4s\tremaining: 1m 16s\n",
            "800:\tlearn: 64.2065314\ttest: 64.2065314\ttest1: 64.3165454\tbest: 64.3165454 (800)\ttotal: 14.2s\tremaining: 1m 14s\n",
            "900:\tlearn: 62.7378599\ttest: 62.7378599\ttest1: 64.0612224\tbest: 64.0612224 (900)\ttotal: 16s\tremaining: 1m 12s\n",
            "1000:\tlearn: 61.4458588\ttest: 61.4458588\ttest1: 63.8980314\tbest: 63.8963338 (999)\ttotal: 17.7s\tremaining: 1m 10s\n",
            "1100:\tlearn: 60.2755377\ttest: 60.2755377\ttest1: 63.7624696\tbest: 63.7503183 (1092)\ttotal: 19.4s\tremaining: 1m 8s\n",
            "1200:\tlearn: 59.1528959\ttest: 59.1528959\ttest1: 63.7256630\tbest: 63.7256630 (1200)\ttotal: 21.2s\tremaining: 1m 7s\n",
            "1300:\tlearn: 58.1144010\ttest: 58.1144010\ttest1: 63.8099953\tbest: 63.7256630 (1200)\ttotal: 23s\tremaining: 1m 5s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 63.72566296\n",
            "bestIteration = 1200\n",
            "\n",
            "Shrink model to first 1201 iterations.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostRegressor at 0x7f52e9658c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "KP8YijeVm8xG",
        "outputId": "15317328-d806-4053-bddd-ade08e8355c9"
      },
      "source": [
        "train_x, train_y, val_x, val_y = train_datast(energy, dangjin_interpolated, target='dangjin_floating')\n",
        "dangjin_floating_model = LGBMRegressor(n_estimators=5000 ,random_seed=42, learning_rate=0.005,depth = 8,loss_function='MultiRMSE',\n",
        "                                       colsample_bytree =  1,max_depth = 17, min_child_samples = 17, min_child_weight = 14, num_leaves = 63, reg_alpha=49.75855787791481, reg_lambda= 0.026935271560602856, subsample= 1.0)\n",
        "dangjin_floating_model.fit(train_x, train_y,\n",
        "                  eval_set=[(train_x, train_y), (val_x, val_y)],\n",
        "                  early_stopping_rounds=100,verbose=100)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's l2: 17468.2\tvalid_1's l2: 12314.7\n",
            "[200]\ttraining's l2: 9505.46\tvalid_1's l2: 7518.53\n",
            "[300]\ttraining's l2: 6160.28\tvalid_1's l2: 5552.15\n",
            "[400]\ttraining's l2: 4621.98\tvalid_1's l2: 4734.6\n",
            "[500]\ttraining's l2: 3850.62\tvalid_1's l2: 4397.85\n",
            "[600]\ttraining's l2: 3360.87\tvalid_1's l2: 4265.15\n",
            "[700]\ttraining's l2: 3025.62\tvalid_1's l2: 4199.41\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-01fb0134dc47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m dangjin_floating_model.fit(train_x, train_y,\n\u001b[1;32m      5\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                   early_stopping_rounds=100,verbose=100)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    683\u001b[0m                                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                                        \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                                        callbacks=callbacks)\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    542\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    216\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1800\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1802\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1803\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvlPbI_oxEtz"
      },
      "source": [
        "## 당진 자재 창고 태양광 예측 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs0NsAnsrLjJ"
      },
      "source": [
        "bayesian_params = {\n",
        "    'max_depth': (5, 20), \n",
        "    'num_leaves': (24, 64), \n",
        "    'min_child_samples': (10, 200), \n",
        "    'min_child_weight':(1, 50),\n",
        "    'subsample':(0.5, 1.0),\n",
        "    'colsample_bytree': (0.5, 1.0),\n",
        "    'max_bin':(10, 500),\n",
        "    'reg_lambda':(0.001, 10),\n",
        "    'reg_alpha': (0.01, 50) \n",
        "}\n",
        "\n",
        "def lgb_eval(max_depth, num_leaves, min_child_samples, min_child_weight, subsample, \n",
        "                colsample_bytree,max_bin, reg_lambda, reg_alpha):\n",
        "    params = {\n",
        "        \"n_estimators\":1000, \"learning_rate\":0.01,\n",
        "        'max_depth': int(round(max_depth)), #  호출 시 실수형 값이 들어오므로 정수형 하이퍼 파라미터는 정수형으로 변경 \n",
        "        'num_leaves': int(round(num_leaves)), \n",
        "        'min_child_samples': int(round(min_child_samples)),\n",
        "        'min_child_weight': int(round(min_child_weight)),\n",
        "        'subsample': max(min(subsample, 1), 0), \n",
        "        'colsample_bytree': max(min(colsample_bytree, 1), 0),\n",
        "        'max_bin':  max(int(round(max_bin)),10),\n",
        "        'reg_lambda': max(reg_lambda,0),\n",
        "        'reg_alpha': max(reg_alpha, 0),\n",
        "        \"metric\" : 'rmse'\n",
        "    }\n",
        "    cv_result = lgb.cv(params, train_data, nfold=5, seed=0, verbose_eval =200,stratified=False)\n",
        "    return (-1.0 * np.array(cv_result['rmse-mean'])).max()\n",
        "\n",
        "train_x, train_y, val_x, val_y = train_datast(energy, dangjin_interpolated, target='dangjin_warehouse')\n",
        "train_data = lgb.Dataset(train_x, train_y)\n",
        "lgbBO = BayesianOptimization(lgb_eval, bayesian_params, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "lgbBO.maximize(init_points=5, n_iter=25)\n",
        "####################################################\n",
        "# dictionary에 있는 target값을 모두 추출\n",
        "target_list = []\n",
        "for result in lgbBO.res:\n",
        "    target = result['target']\n",
        "    target_list.append(target)\n",
        "print(target_list)\n",
        "# 가장 큰 target 값을 가지는 순번(index)를 추출\n",
        "print('maximum target index:', np.argmax(np.array(target_list)))\n",
        "\n",
        "#################################################################\n",
        "# 가장 큰 target값을 가지는 index값을 기준으로 res에서 해당 parameter 추출. \n",
        "max_dict = lgbBO.res[np.argmax(np.array(target_list))]\n",
        "print(max_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kotOVQ2gOM2a"
      },
      "source": [
        "random.seed(42)\n",
        "cat2_models={}\n",
        "target = 'dangjin_warehouse'\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "folds=[]\n",
        "train = kfold_datast (energy, dangjin_interpolated, target=target)\n",
        "\n",
        "\n",
        "for train_idx, valid_idx in skf.split(train, train['dangjin_warehouse']):\n",
        "    folds.append((train_idx, valid_idx))\n",
        "\n",
        "for fold in range(10):\n",
        "    print(f'===================================={fold+1}============================================')\n",
        "    train_idx, valid_idx = folds[fold]\n",
        "    train_x, val_x, train_y, val_y = train.drop([target],axis=1).iloc[train_idx].values, train.drop([target],axis=1).iloc[valid_idx].values,\\\n",
        "                                         train[target][train_idx].values, train[target][valid_idx].values \n",
        "    cat = CatBoostRegressor(n_estimators=5000 ,random_seed=42, learning_rate=0.005,depth = 10,loss_function='MultiRMSE')\n",
        "    cat.fit(train_x, train_y,\n",
        "                    eval_set=[(train_x, train_y), (val_x, val_y)],\n",
        "                    early_stopping_rounds=100,verbose=100)\n",
        "    cat2_models[fold]=cat\n",
        "    print(f'================================================================================\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz2M3oeqOVu7"
      },
      "source": [
        "random.seed(42)\n",
        "lgb2_models={}\n",
        "target = 'dangjin_warehouse'\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "folds=[]\n",
        "train = kfold_datast (energy, dangjin_interpolated, target=target)\n",
        "\n",
        "\n",
        "for train_idx, valid_idx in skf.split(train, train['dangjin_warehouse']):\n",
        "    folds.append((train_idx, valid_idx))\n",
        "\n",
        "\n",
        "for fold in range(10):\n",
        "    print(f'===================================={fold+1}============================================')\n",
        "    train_idx, valid_idx = folds[fold]\n",
        "    train_x, val_x, train_y, val_y = train.drop([target],axis=1).iloc[train_idx].values, train.drop([target],axis=1).iloc[valid_idx].values,\\\n",
        "                                         train[target][train_idx].values, train[target][valid_idx].values \n",
        "    lgb = LGBMRegressor(n_estimators=5000 ,random_seed=42, learning_rate=0.005,depth = 8,loss_function='MultiRMSE',\n",
        "                                        colsample_bytree =  1,max_depth = 17, min_child_samples = 17, min_child_weight = 14, num_leaves = 63, reg_alpha=49.75855787791481, reg_lambda= 0.026935271560602856, subsample= 1.0)\n",
        "    lgb.fit(train_x, train_y,\n",
        "                    eval_set=[(train_x, train_y), (val_x, val_y)],\n",
        "                    early_stopping_rounds=100,verbose=100)\n",
        "    lgb2_models[fold]=lgb\n",
        "    print(f'================================================================================\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As6giXXL2NzL",
        "outputId": "ac4c6a04-eb47-421b-e5a6-b2fbe06d75b0"
      },
      "source": [
        "train_x, train_y, val_x, val_y = train_datast(energy, dangjin_interpolated, target='dangjin_warehouse')\n",
        "cat2 = CatBoostRegressor(n_estimators=5000 ,random_seed=42, learning_rate=0.005,depth = 10,loss_function='MultiRMSE')\n",
        "cat2.fit(train_x, train_y,\n",
        "                  eval_set=[(train_x, train_y), (val_x, val_y)],\n",
        "                  early_stopping_rounds=100,verbose=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 147.2777493\ttest: 147.2777493\ttest1: 127.8906322\tbest: 127.8906322 (0)\ttotal: 20.1ms\tremaining: 1m 40s\n",
            "100:\tlearn: 103.6944464\ttest: 103.6944464\ttest1: 91.7248245\tbest: 91.7248245 (100)\ttotal: 1.76s\tremaining: 1m 25s\n",
            "200:\tlearn: 79.2017736\ttest: 79.2017736\ttest1: 72.3140566\tbest: 72.3140566 (200)\ttotal: 3.5s\tremaining: 1m 23s\n",
            "300:\tlearn: 65.9537681\ttest: 65.9537681\ttest1: 62.8602773\tbest: 62.8602773 (300)\ttotal: 5.24s\tremaining: 1m 21s\n",
            "400:\tlearn: 58.8730529\ttest: 58.8730529\ttest1: 58.3327560\tbest: 58.3327560 (400)\ttotal: 6.99s\tremaining: 1m 20s\n",
            "500:\tlearn: 54.7668253\ttest: 54.7668253\ttest1: 56.4786361\tbest: 56.4786361 (500)\ttotal: 8.71s\tremaining: 1m 18s\n",
            "600:\tlearn: 52.1889608\ttest: 52.1889608\ttest1: 55.4925947\tbest: 55.4925947 (600)\ttotal: 10.5s\tremaining: 1m 17s\n",
            "700:\tlearn: 50.3383994\ttest: 50.3383994\ttest1: 54.9446819\tbest: 54.9446819 (700)\ttotal: 12.3s\tremaining: 1m 15s\n",
            "800:\tlearn: 48.9941662\ttest: 48.9941662\ttest1: 54.7032289\tbest: 54.6956555 (792)\ttotal: 14s\tremaining: 1m 13s\n",
            "900:\tlearn: 47.8638333\ttest: 47.8638333\ttest1: 54.5639910\tbest: 54.5628820 (899)\ttotal: 15.8s\tremaining: 1m 11s\n",
            "1000:\tlearn: 46.8137927\ttest: 46.8137927\ttest1: 54.5328637\tbest: 54.5164144 (977)\ttotal: 17.5s\tremaining: 1m 9s\n",
            "1100:\tlearn: 45.8980880\ttest: 45.8980880\ttest1: 54.4402683\tbest: 54.4278601 (1091)\ttotal: 19.2s\tremaining: 1m 7s\n",
            "1200:\tlearn: 45.0772775\ttest: 45.0772775\ttest1: 54.4182723\tbest: 54.3833887 (1164)\ttotal: 20.9s\tremaining: 1m 6s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 54.38338872\n",
            "bestIteration = 1164\n",
            "\n",
            "Shrink model to first 1165 iterations.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostRegressor at 0x7f52dc7d7190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FTpn6zuxEtd"
      },
      "source": [
        "{'colsample_bytree': 0.7840043724584478, 'max_bin': 109.42082906265013, 'max_depth': 11.939485103471496, 'min_child_samples': 47.27436173622021, 'min_child_weight': 44.12615815161272, 'num_leaves': 61.168181706089655, 'reg_alpha': 7.967786769707356, 'reg_lambda': 1.4818125424587414, 'subsample': 0.835744966051806}}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy5JgE3Ereti",
        "outputId": "9f306aba-2c56-4072-b262-f512d0e2d513"
      },
      "source": [
        "train_x, train_y, val_x, val_y = train_datast(energy, dangjin_interpolated, target='dangjin_warehouse')\n",
        "dangjin_warehouse_model = LGBMRegressor(n_estimators=5000 ,random_seed=42, learning_rate=0.005,depth = 8,loss_function='MultiRMSE',\n",
        "                                       colsample_bytree =  1,max_depth = 17, min_child_samples = 17, min_child_weight = 14, num_leaves = 63, reg_alpha=49.75855787791481, reg_lambda= 0.026935271560602856, subsample= 1.0)\n",
        "dangjin_warehouse_model.fit(train_x, train_y,\n",
        "                  eval_set=[(train_x, train_y), (val_x, val_y)],\n",
        "                  early_stopping_rounds=100,verbose=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's l2: 10057.3\tvalid_1's l2: 8089.53\n",
            "[200]\ttraining's l2: 5471.98\tvalid_1's l2: 4970.63\n",
            "[300]\ttraining's l2: 3539.38\tvalid_1's l2: 3813.67\n",
            "[400]\ttraining's l2: 2674.14\tvalid_1's l2: 3368.68\n",
            "[500]\ttraining's l2: 2229.72\tvalid_1's l2: 3195.32\n",
            "[600]\ttraining's l2: 1963\tvalid_1's l2: 3129.7\n",
            "[700]\ttraining's l2: 1785.8\tvalid_1's l2: 3105.45\n",
            "[800]\ttraining's l2: 1651.59\tvalid_1's l2: 3057.7\n",
            "[900]\ttraining's l2: 1547.15\tvalid_1's l2: 3032.77\n",
            "[1000]\ttraining's l2: 1460.65\tvalid_1's l2: 3021.56\n",
            "[1100]\ttraining's l2: 1380.61\tvalid_1's l2: 3024.25\n",
            "Early stopping, best iteration is:\n",
            "[1051]\ttraining's l2: 1417.22\tvalid_1's l2: 3020.03\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1,\n",
              "              depth=8, importance_type='split', learning_rate=0.005,\n",
              "              loss_function='MultiRMSE', max_depth=17, min_child_samples=17,\n",
              "              min_child_weight=14, min_split_gain=0.0, n_estimators=5000,\n",
              "              n_jobs=-1, num_leaves=63, objective=None, random_seed=42,\n",
              "              random_state=None, reg_alpha=49.75855787791481,\n",
              "              reg_lambda=0.026935271560602856, silent=True, subsample=1.0,\n",
              "              subsample_for_bin=200000, subsample_freq=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbC-9EokxEtz"
      },
      "source": [
        "## 당진 태양광 예측 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1ffH0mx1OxI"
      },
      "source": [
        "bayesian_params = {\n",
        "    'max_depth': (5, 20), \n",
        "    'num_leaves': (24, 64), \n",
        "    'min_child_samples': (10, 200), \n",
        "    'min_child_weight':(1, 50),\n",
        "    'subsample':(0.5, 1.0),\n",
        "    'colsample_bytree': (0.5, 1.0),\n",
        "    'max_bin':(10, 500),\n",
        "    'reg_lambda':(0.001, 10),\n",
        "    'reg_alpha': (0.01, 50) \n",
        "}\n",
        "\n",
        "def lgb_eval(max_depth, num_leaves, min_child_samples, min_child_weight, subsample, \n",
        "                colsample_bytree,max_bin, reg_lambda, reg_alpha):\n",
        "    params = {\n",
        "        \"n_estimators\":1000, \"learning_rate\":0.01,\n",
        "        'max_depth': int(round(max_depth)), #  호출 시 실수형 값이 들어오므로 정수형 하이퍼 파라미터는 정수형으로 변경 \n",
        "        'num_leaves': int(round(num_leaves)), \n",
        "        'min_child_samples': int(round(min_child_samples)),\n",
        "        'min_child_weight': int(round(min_child_weight)),\n",
        "        'subsample': max(min(subsample, 1), 0), \n",
        "        'colsample_bytree': max(min(colsample_bytree, 1), 0),\n",
        "        'max_bin':  max(int(round(max_bin)),10),\n",
        "        'reg_lambda': max(reg_lambda,0),\n",
        "        'reg_alpha': max(reg_alpha, 0),\n",
        "        \"metric\" : 'rmse'\n",
        "    }\n",
        "    cv_result = lgb.cv(params, train_data, nfold=5, seed=0, verbose_eval =200,stratified=False)\n",
        "    return (-1.0 * np.array(cv_result['rmse-mean'])).max()\n",
        "\n",
        "train_x, train_y, val_x, val_y = train_datast(energy, dangjin_interpolated, target='dangjin')\n",
        "train_data = lgb.Dataset(train_x, train_y)\n",
        "lgbBO = BayesianOptimization(lgb_eval, bayesian_params, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "lgbBO.maximize(init_points=5, n_iter=25)\n",
        "####################################################\n",
        "# dictionary에 있는 target값을 모두 추출\n",
        "target_list = []\n",
        "for result in lgbBO.res:\n",
        "    target = result['target']\n",
        "    target_list.append(target)\n",
        "print(target_list)\n",
        "# 가장 큰 target 값을 가지는 순번(index)를 추출\n",
        "print('maximum target index:', np.argmax(np.array(target_list)))\n",
        "\n",
        "#################################################################\n",
        "# 가장 큰 target값을 가지는 index값을 기준으로 res에서 해당 parameter 추출. \n",
        "max_dict = lgbBO.res[np.argmax(np.array(target_list))]\n",
        "print(max_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfMH4iLpOldj"
      },
      "source": [
        "random.seed(42)\n",
        "cat3_models={}\n",
        "target = 'dangjin'\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "folds=[]\n",
        "train = kfold_datast (energy, dangjin_interpolated, target=target)\n",
        "\n",
        "\n",
        "for train_idx, valid_idx in skf.split(train, train['dangjin']):\n",
        "    folds.append((train_idx, valid_idx))\n",
        "\n",
        "for fold in range(10):\n",
        "    print(f'===================================={fold+1}============================================')\n",
        "    train_idx, valid_idx = folds[fold]\n",
        "    train_x, val_x, train_y, val_y = train.drop([target],axis=1).iloc[train_idx].values, train.drop([target],axis=1).iloc[valid_idx].values,\\\n",
        "                                         train[target][train_idx].values, train[target][valid_idx].values \n",
        "    cat = CatBoostRegressor(n_estimators=5000 ,random_seed=42, learning_rate=0.005,depth = 10,loss_function='MultiRMSE')\n",
        "    cat.fit(train_x, train_y,\n",
        "                    eval_set=[(train_x, train_y), (val_x, val_y)],\n",
        "                    early_stopping_rounds=100,verbose=100)\n",
        "    cat3_models[fold]=cat\n",
        "    print(f'================================================================================\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG7Fg_DQOtsA"
      },
      "source": [
        "random.seed(42)\n",
        "lgb3_models={}\n",
        "target = 'dangjin'\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "folds=[]\n",
        "train = kfold_datast (energy, dangjin_interpolated, target=target)\n",
        "\n",
        "\n",
        "for train_idx, valid_idx in skf.split(train, train['dangjin']):\n",
        "    folds.append((train_idx, valid_idx))\n",
        "\n",
        "for fold in range(10):\n",
        "    print(f'===================================={fold+1}============================================')\n",
        "    train_idx, valid_idx = folds[fold]\n",
        "    train_x, val_x, train_y, val_y = train.drop([target],axis=1).iloc[train_idx].values, train.drop([target],axis=1).iloc[valid_idx].values,\\\n",
        "                                         train[target][train_idx].values, train[target][valid_idx].values \n",
        "    lgb = LGBMRegressor(n_estimators=5000 ,random_seed=42, learning_rate=0.005,depth = 8,loss_function='MultiRMSE',\n",
        "                                        colsample_bytree =  1,max_depth = 17, min_child_samples = 17, min_child_weight = 14, num_leaves = 63, reg_alpha=49.75855787791481, reg_lambda= 0.026935271560602856, subsample= 1.0)\n",
        "    lgb.fit(train_x, train_y,\n",
        "                    eval_set=[(train_x, train_y), (val_x, val_y)],\n",
        "                    early_stopping_rounds=100,verbose=100)\n",
        "    lgb3_models[fold]=lgb\n",
        "    print(f'================================================================================\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiYN0duz2TLv",
        "outputId": "944833a9-8614-4baa-ae0f-88034cd32ea6"
      },
      "source": [
        "train_x, train_y, val_x, val_y = train_datast(energy, dangjin_interpolated, target='dangjin')\n",
        "cat3 = CatBoostRegressor(n_estimators=5000 ,random_seed=42, learning_rate=0.005,depth = 10,loss_function='MultiRMSE')\n",
        "cat3.fit(train_x, train_y,\n",
        "                  eval_set=[(train_x, train_y), (val_x, val_y)],\n",
        "                  early_stopping_rounds=100,verbose=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 221.6627612\ttest: 221.6627612\ttest1: 195.8197076\tbest: 195.8197076 (0)\ttotal: 20ms\tremaining: 1m 39s\n",
            "100:\tlearn: 154.3536660\ttest: 154.3536660\ttest1: 140.5623408\tbest: 140.5623408 (100)\ttotal: 1.73s\tremaining: 1m 23s\n",
            "200:\tlearn: 116.2758635\ttest: 116.2758635\ttest1: 111.7606646\tbest: 111.7606646 (200)\ttotal: 3.42s\tremaining: 1m 21s\n",
            "300:\tlearn: 95.6359842\ttest: 95.6359842\ttest1: 97.2736954\tbest: 97.2736954 (300)\ttotal: 5.09s\tremaining: 1m 19s\n",
            "400:\tlearn: 84.8683633\ttest: 84.8683633\ttest1: 90.2021170\tbest: 90.2021170 (400)\ttotal: 6.77s\tremaining: 1m 17s\n",
            "500:\tlearn: 78.9467163\ttest: 78.9467163\ttest1: 86.7140935\tbest: 86.7140935 (500)\ttotal: 8.47s\tremaining: 1m 16s\n",
            "600:\tlearn: 75.4799602\ttest: 75.4799602\ttest1: 85.0015122\tbest: 85.0015122 (600)\ttotal: 10.1s\tremaining: 1m 14s\n",
            "700:\tlearn: 73.1411108\ttest: 73.1411108\ttest1: 84.1336129\tbest: 84.1215786 (699)\ttotal: 11.8s\tremaining: 1m 12s\n",
            "800:\tlearn: 71.4765393\ttest: 71.4765393\ttest1: 83.5197950\tbest: 83.5197950 (800)\ttotal: 13.6s\tremaining: 1m 11s\n",
            "900:\tlearn: 69.9903153\ttest: 69.9903153\ttest1: 83.1620043\tbest: 83.1620043 (900)\ttotal: 15.3s\tremaining: 1m 9s\n",
            "1000:\tlearn: 68.7283489\ttest: 68.7283489\ttest1: 83.0468016\tbest: 83.0328890 (984)\ttotal: 17s\tremaining: 1m 7s\n",
            "1100:\tlearn: 67.6294485\ttest: 67.6294485\ttest1: 82.9540623\tbest: 82.9409399 (1095)\ttotal: 18.8s\tremaining: 1m 6s\n",
            "1200:\tlearn: 66.5143704\ttest: 66.5143704\ttest1: 82.8940944\tbest: 82.8903610 (1154)\ttotal: 20.5s\tremaining: 1m 4s\n",
            "1300:\tlearn: 65.4871967\ttest: 65.4871967\ttest1: 82.7963800\tbest: 82.7895490 (1297)\ttotal: 22.3s\tremaining: 1m 3s\n",
            "1400:\tlearn: 64.5038851\ttest: 64.5038851\ttest1: 82.7766160\tbest: 82.7654476 (1391)\ttotal: 24s\tremaining: 1m 1s\n",
            "1500:\tlearn: 63.5711604\ttest: 63.5711604\ttest1: 82.7989629\tbest: 82.7612857 (1414)\ttotal: 25.8s\tremaining: 1m\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 82.76128574\n",
            "bestIteration = 1414\n",
            "\n",
            "Shrink model to first 1415 iterations.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostRegressor at 0x7f52dce3cf90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USqFbSNL12bR"
      },
      "source": [
        "{'target': -67.37835160276464, 'params': {'colsample_bytree': 0.8803371255183132, 'max_bin': 366.3312849753787, 'max_depth': 14.426679148899519, 'min_child_samples': 24.334988996735756, 'min_child_weight': 14.85309783894488, 'num_leaves': 41.115245176939176, 'reg_alpha': 1.1811080746620453, 'reg_lambda': 9.672295351116277, 'subsample': 0.6051769440265253}}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNKGUwHq3HNO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfc25bda-3608-455e-f24a-0884fa8b3470"
      },
      "source": [
        "train_x, train_y, val_x, val_y = train_datast(energy, dangjin_interpolated, target='dangjin')\n",
        "dangjin_model = LGBMRegressor(n_estimators=5000 ,random_seed=42, learning_rate=0.005,depth = 8,loss_function='MultiRMSE',\n",
        "                                       colsample_bytree =  0.7840043724584478,max_bin= 109,num_leaves = 61,\n",
        "                                        max_depth = 12, min_child_samples = 47, min_child_weight = 44, reg_alpha=7.96, reg_lambda= 1.48, subsample= 0.835744966051806)\n",
        "dangjin_model.fit(train_x, train_y,\n",
        "                  eval_set=[(train_x, train_y), (val_x, val_y)],\n",
        "                  early_stopping_rounds=100,verbose=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's l2: 23972.9\tvalid_1's l2: 20038.7\n",
            "[200]\ttraining's l2: 13505.7\tvalid_1's l2: 12722.1\n",
            "[300]\ttraining's l2: 8680.92\tvalid_1's l2: 9453.09\n",
            "[400]\ttraining's l2: 6494.53\tvalid_1's l2: 8076.26\n",
            "[500]\ttraining's l2: 5396.67\tvalid_1's l2: 7532.7\n",
            "[600]\ttraining's l2: 4788.04\tvalid_1's l2: 7312.69\n",
            "[700]\ttraining's l2: 4394.52\tvalid_1's l2: 7184.58\n",
            "[800]\ttraining's l2: 4115.53\tvalid_1's l2: 7123.25\n",
            "[900]\ttraining's l2: 3903.11\tvalid_1's l2: 7085.49\n",
            "[1000]\ttraining's l2: 3718.13\tvalid_1's l2: 7095.42\n",
            "Early stopping, best iteration is:\n",
            "[912]\ttraining's l2: 3878.86\tvalid_1's l2: 7080.32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(boosting_type='gbdt', class_weight=None,\n",
              "              colsample_bytree=0.7840043724584478, depth=8,\n",
              "              importance_type='split', learning_rate=0.005,\n",
              "              loss_function='MultiRMSE', max_bin=109, max_depth=12,\n",
              "              min_child_samples=47, min_child_weight=44, min_split_gain=0.0,\n",
              "              n_estimators=5000, n_jobs=-1, num_leaves=61, objective=None,\n",
              "              random_seed=42, random_state=None, reg_alpha=7.96,\n",
              "              reg_lambda=1.48, silent=True, subsample=0.835744966051806,\n",
              "              subsample_for_bin=200000, subsample_freq=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnYH_ovOxEt0"
      },
      "source": [
        "## 울산 태양광 예측 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6A1Yj8p3627"
      },
      "source": [
        "bayesian_params = {\n",
        "    'max_depth': (5, 20), \n",
        "    'num_leaves': (24, 64), \n",
        "    'min_child_samples': (10, 200), \n",
        "    'min_child_weight':(1, 50),\n",
        "    'subsample':(0.5, 1.0),\n",
        "    'colsample_bytree': (0.5, 1.0),\n",
        "    'max_bin':(10, 500),\n",
        "    'reg_lambda':(0.001, 10),\n",
        "    'reg_alpha': (0.01, 50) \n",
        "}\n",
        "\n",
        "def lgb_eval(max_depth, num_leaves, min_child_samples, min_child_weight, subsample, \n",
        "                colsample_bytree,max_bin, reg_lambda, reg_alpha):\n",
        "    params = {\n",
        "        \"n_estimators\":1000, \"learning_rate\":0.01,\n",
        "        'max_depth': int(round(max_depth)), #  호출 시 실수형 값이 들어오므로 정수형 하이퍼 파라미터는 정수형으로 변경 \n",
        "        'num_leaves': int(round(num_leaves)), \n",
        "        'min_child_samples': int(round(min_child_samples)),\n",
        "        'min_child_weight': int(round(min_child_weight)),\n",
        "        'subsample': max(min(subsample, 1), 0), \n",
        "        'colsample_bytree': max(min(colsample_bytree, 1), 0),\n",
        "        'max_bin':  max(int(round(max_bin)),10),\n",
        "        'reg_lambda': max(reg_lambda,0),\n",
        "        'reg_alpha': max(reg_alpha, 0),\n",
        "        \"metric\" : 'rmse'\n",
        "    }\n",
        "    cv_result = lgb.cv(params, train_data, nfold=5, seed=0, verbose_eval =200,stratified=False)\n",
        "    return (-1.0 * np.array(cv_result['rmse-mean'])).max()\n",
        "\n",
        "train_x, train_y, val_x, val_y = train_datast(energy, ulsan_interpolated, target='ulsan')\n",
        "train_data = lgb.Dataset(train_x, train_y)\n",
        "\n",
        "lgbB1 = BayesianOptimization(lgb_eval, bayesian_params, random_state=42)\n",
        "\n",
        "\n",
        "lgbB1.maximize(init_points=5, n_iter=25)\n",
        "####################################################\n",
        "# dictionary에 있는 target값을 모두 추출\n",
        "target_list = []\n",
        "for result in lgbB1.res:\n",
        "    target = result['target']\n",
        "    target_list.append(target)\n",
        "print(target_list)\n",
        "# 가장 큰 target 값을 가지는 순번(index)를 추출\n",
        "print('maximum target index:', np.argmax(np.array(target_list)))\n",
        "\n",
        "#################################################################\n",
        "# 가장 큰 target값을 가지는 index값을 기준으로 res에서 해당 parameter 추출. \n",
        "max_dict = lgbB1.res[np.argmax(np.array(target_list))]\n",
        "print(max_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1TlZZQwO2wk"
      },
      "source": [
        "random.seed(42)\n",
        "cat4_models={}\n",
        "target = 'ulsan'\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "folds=[]\n",
        "train = kfold_datast (energy, dangjin_interpolated, target=target)\n",
        "\n",
        "\n",
        "for train_idx, valid_idx in skf.split(train, train['ulsan']):\n",
        "    folds.append((train_idx, valid_idx))\n",
        "\n",
        "for fold in range(10):\n",
        "    print(f'===================================={fold+1}============================================')\n",
        "    train_idx, valid_idx = folds[fold]\n",
        "    train_x, val_x, train_y, val_y = train.drop([target],axis=1).iloc[train_idx].values, train.drop([target],axis=1).iloc[valid_idx].values,\\\n",
        "                                         train[target][train_idx].values, train[target][valid_idx].values \n",
        "    cat = CatBoostRegressor(n_estimators=5000 ,random_seed=42, learning_rate=0.005,depth = 10,loss_function='MultiRMSE')\n",
        "    cat.fit(train_x, train_y,\n",
        "                    eval_set=[(train_x, train_y), (val_x, val_y)],\n",
        "                    early_stopping_rounds=100,verbose=100)\n",
        "    cat4_models[fold]=cat\n",
        "    print(f'================================================================================\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkUp_zCaO8Gc"
      },
      "source": [
        "random.seed(42)\n",
        "lgb4_models={}\n",
        "target = 'ulsan'\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "folds=[]\n",
        "train = kfold_datast (energy, dangjin_interpolated, target=target)\n",
        "\n",
        "\n",
        "for train_idx, valid_idx in skf.split(train, train['ulsan']):\n",
        "    folds.append((train_idx, valid_idx))\n",
        "\n",
        "for fold in range(10):\n",
        "    print(f'===================================={fold+1}============================================')\n",
        "    train_idx, valid_idx = folds[fold]\n",
        "    train_x, val_x, train_y, val_y = train.drop([target],axis=1).iloc[train_idx].values, train.drop([target],axis=1).iloc[valid_idx].values,\\\n",
        "                                         train[target][train_idx].values, train[target][valid_idx].values \n",
        "    lgb = LGBMRegressor(n_estimators=5000 ,random_seed=42, learning_rate=0.005,depth = 8,loss_function='MultiRMSE',\n",
        "                                        colsample_bytree =  1,max_depth = 17, min_child_samples = 17, min_child_weight = 14, num_leaves = 63, reg_alpha=49.75855787791481, reg_lambda= 0.026935271560602856, subsample= 1.0)\n",
        "    lgb.fit(train_x, train_y,\n",
        "                    eval_set=[(train_x, train_y), (val_x, val_y)],\n",
        "                    early_stopping_rounds=100,verbose=100)\n",
        "    lgb4_models[fold]=lgb\n",
        "    print(f'================================================================================\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxF51gPG2XRo"
      },
      "source": [
        "train_x, train_y, val_x, val_y = train_datast(energy, ulsan_interpolated, target='ulsan')\n",
        "cat4 = CatBoostRegressor(n_estimators=5000 ,random_seed=42, learning_rate=0.005,depth = 10,loss_function='MultiRMSE',)\n",
        "cat4.fit(train_x, train_y,\n",
        "                  eval_set=[(train_x, train_y), (val_x, val_y)],\n",
        "                  early_stopping_rounds=100,verbose=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Untm9rje4B6U"
      },
      "source": [
        "train_x, train_y, val_x, val_y = train_datast(energy, ulsan_interpolated, target='ulsan')\n",
        "ulsan_model = LGBMRegressor(n_estimators=5000 ,random_seed=42, learning_rate=0.005,depth = 8,loss_function='MultiRMSE',\n",
        "                                       colsample_bytree =  1,max_depth = 17, min_child_samples = 17, min_child_weight = 14, num_leaves = 63, reg_alpha=49.75855787791481, reg_lambda= 0.026935271560602856, subsample= 1.0)\n",
        "ulsan_model.fit(train_x, train_y,\n",
        "                  eval_set=[(train_x, train_y), (val_x, val_y)],\n",
        "                  early_stopping_rounds=100,verbose=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO9Tqf0kxEt0"
      },
      "source": [
        "## 테스트 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P__bIgCK3Dr7"
      },
      "source": [
        "import pandas as pd\n",
        "import urllib\n",
        "import urllib.request\n",
        "import json\n",
        "\n",
        "ServiceKey = 'k4ddN+RdAKoBExDTI0PS+2M3QtLVZZkW7Bd8in1h4j5sgfrd2cyVRmYieYHcJNTTnPd+b7X8epYmZS5Ngj18Ww=='"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-Dq7wa-9ufm"
      },
      "source": [
        "## 파라미터 수정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZxKb5zn9t22"
      },
      "source": [
        "#dangjin = 53 , 44\n",
        "#ulsan = 102, 83\n",
        "nx, ny = '53','44'\n",
        "fcst_day='20210610'# 날짜 수정\n",
        "date = '2021-06-10'  \n",
        "day = 2 #6월 9일  = 1"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIrKdXDo3HXP"
      },
      "source": [
        "url = 'http://apis.data.go.kr/1360000/VilageFcstInfoService/getVilageFcst'\n",
        "\n",
        "\n",
        " queryParams = '?' + urllib.parse.urlencode(\n",
        "    {\n",
        "        urllib.parse.quote_plus('ServiceKey') : 'k4ddN+RdAKoBExDTI0PS+2M3QtLVZZkW7Bd8in1h4j5sgfrd2cyVRmYieYHcJNTTnPd+b7X8epYmZS5Ngj18Ww==', # key를 바로 입력해도 됩니다.\n",
        "        urllib.parse.quote_plus('numOfRows') : '113', # 총 14개의 항목을 3시간 단위로 순차적으로 불러옵니다. 다음날 24시간예보에 필요한 만큼만 가져왔습니다.\n",
        "        urllib.parse.quote_plus('dataType') : 'JSON', # JSON, XML 두가지 포멧을 제공합니다.\n",
        "        urllib.parse.quote_plus('base_date') : fcst_day, # 예보 받을 날짜를 입력합니다. 최근 1일간의 자료만 제공합니다.\n",
        "        urllib.parse.quote_plus('base_time') : '2000', # 예보 시간을 입력합니다. 2시부터 시작하여 3시간 단위로 입력 가능합니다.\n",
        "        urllib.parse.quote_plus('nx') : nx, # 울산 태양광 발전소 x 좌표입니다. '기상청18_동네예보 조회서비스_오픈API활용가이드.zip'에 포함 된 excel파일을 통해 확인 가능합니다.\n",
        "        urllib.parse.quote_plus('ny') : ny # 울산 태양광 발전소 y 좌표입니다. '기상청18_동네예보 조회서비스_오픈API활용가이드.zip'에 포함 된 excel파일을 통해 확인 가능합니다.\n",
        "    }\n",
        ")\n",
        "\n",
        "response = urllib.request.urlopen(url + queryParams).read()\n",
        "response = json.loads(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YngpqpBz3Ieh"
      },
      "source": [
        "fcst_df = pd.DataFrame()\n",
        "\n",
        "fcst_df['Forecast_time'] = [f'{date} {hour}:00' for hour in range(24)]\n",
        "row_idx = 0\n",
        "\n",
        "for i, data in enumerate(response['response']['body']['items']['item']):\n",
        "    if i > 19:\n",
        "        if data['category']=='REH':\n",
        "            fcst_df.loc[row_idx, 'Humidity'] = float(data['fcstValue'])\n",
        "            print('category:Humidity,',data['category'], 'baseTime:',data['baseTime'], ', fcstTime:', data['fcstTime'], ', fcstValue:', data['fcstValue'])\n",
        "        elif data['category']=='T3H':\n",
        "            fcst_df.loc[row_idx, 'Temperature'] = float(data['fcstValue'])\n",
        "            print('category:Temperature,',data['category'], 'baseTime:',data['baseTime'], ', fcstTime:', data['fcstTime'], ', fcstValue:', data['fcstValue'])\n",
        "        elif data['category']=='SKY':\n",
        "            fcst_df.loc[row_idx, 'Cloud'] = float(data['fcstValue'])\n",
        "            print('category:Cloud,',data['category'], 'baseTime:',data['baseTime'], ', fcstTime:', data['fcstTime'], ', fcstValue:', data['fcstValue'])\n",
        "        elif data['category']=='VEC':\n",
        "            fcst_df.loc[row_idx, 'WindDirection'] = float(data['fcstValue'])\n",
        "            print('category:WindDirection,',data['category'], 'baseTime:',data['baseTime'], ', fcstTime:', data['fcstTime'], ', fcstValue:', data['fcstValue'])\n",
        "        elif data['category']=='WSD':\n",
        "            fcst_df.loc[row_idx, 'WindSpeed'] = float(data['fcstValue'])\n",
        "            print('category:WindSpeed,',data['category'], 'baseTime:',data['baseTime'], ', fcstTime:', data['fcstTime'], ', fcstValue:', data['fcstValue'], '\\n')\n",
        "            row_idx+=3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq4gNpSA3MuO"
      },
      "source": [
        "ulsan = fcst_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIqDnRJwGOAj"
      },
      "source": [
        "dangjin = fcst_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7u0S7BN7YAy"
      },
      "source": [
        "def test_datast(fcst_df):\n",
        "    start = '2021-06-10 0:00'\n",
        "    end = '2021-06-10 23:00'\n",
        "    \n",
        "    start_idx = fcst_df[fcst_df['Forecast_time']==start].index[0]\n",
        "    end_idx = fcst_df[fcst_df['Forecast_time']==end].index[0]\n",
        "    \n",
        "    test_df = fcst_df.loc[start_idx:end_idx, :].copy()\n",
        "    \n",
        "    test_df['date'] = test_df['Forecast_time'].str.split(' ').str[0]\n",
        "    test_df['hour'] = test_df['Forecast_time'].str.split(' ').str[1].str.split(':').str[0].astype(int)\n",
        "    \n",
        "    test_df['year'] = test_df['date'].str.split('-').str[0].astype(int)\n",
        "    test_df['month'] = test_df['date'].str.split('-').str[1].astype(int)\n",
        "    test_df['day'] = test_df['date'].str.split('-').str[2].astype(int)\n",
        "    \n",
        "    test_df = test_df[['year', 'month', 'day', 'hour', 'Temperature', 'Humidity', 'WindSpeed', 'WindDirection', 'Cloud']]\n",
        "    \n",
        "    test_x = test_df.to_numpy()\n",
        "    \n",
        "    return test_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpkUloADxEt1"
      },
      "source": [
        "dangjin_test = test_datast(dangjin)\n",
        "ulsan_test = test_datast(ulsan)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KsBuuIR7WCd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEoy9yFexEt1"
      },
      "source": [
        "## 각 발전소 발전량 추론"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRuSpMEW-jLO"
      },
      "source": [
        "submission = pd.read_csv('./data/sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaS69B4v4sqq"
      },
      "source": [
        "dangjin_floating_pred = dangjin_floating_pred.to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By9dPYWaqZ-I"
      },
      "source": [
        "dangjin_floating_pred = submission.iloc[:24, 1]\n",
        "\n",
        "for fold in range(10):\n",
        "    dangjin_floating_pred += lgb1_models[fold].predict(dangjin_test)/10\n",
        "    #dangjin_floating_pred += cat1_models[fold].predict(dangjin_test)/20\n",
        "\n",
        "\n",
        "submission.iloc[24*28+24*(day-1):24*28+24*day, 1] = dangjin_floating_pred.to_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVpsVwqg_Bkz"
      },
      "source": [
        "dangjin_warehouse_pred = submission.iloc[:24, 2]\n",
        "\n",
        "for fold in range(10):\n",
        "    #dangjin_warehouse_pred += lgb2_models[fold].predict(dangjin_test)/20\n",
        "    dangjin_warehouse_pred += cat2_models[fold].predict(dangjin_test)/10\n",
        "\n",
        "submission.iloc[24*28+24*(day-1):24*28+24*day, 2] = dangjin_warehouse_pred.to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YvM9zkR_FTT"
      },
      "source": [
        "dangjin_pred = submission.iloc[:24, 3]\n",
        "\n",
        "for fold in range(10):\n",
        "    #dangjin_pred += lgb3_models[fold].predict(dangjin_test)/20\n",
        "    dangjin_pred += cat3_models[fold].predict(dangjin_test)/10\n",
        "\n",
        "submission.iloc[24*28+24*(day-1):24*28+24*day, 3] = dangjin_pred.to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRHM7sSa_F71"
      },
      "source": [
        "ulsan_pred = submission.iloc[:24, 4]\n",
        "\n",
        "for fold in range(10):\n",
        "    #ulsan_pred += lgb4_models[fold].predict(ulsan_test)/20\n",
        "    ulsan_pred += cat4_models[fold].predict(ulsan_test)/10\n",
        "submission.iloc[24*28+24*(day-1):24*28+24*day, 4] = ulsan_pred.to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_kr3Uqg_7sJ"
      },
      "source": [
        "submission.iloc[24*28+24*(day-1):24*28+24*day,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_qVLiIp_Vq8"
      },
      "source": [
        "submission.to_csv(fcst_day+'.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSCZsBMMxEt1"
      },
      "source": [
        "## 제출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n866yFCN7h9p"
      },
      "source": [
        "def test_datast(fcst_df):\n",
        "    start = '2021-02-01 00:00:00'\n",
        "    end = '2021-02-28 23:00:00'\n",
        "    \n",
        "    start_idx = fcst_df[fcst_df['Forecast_time']==start].index[0]\n",
        "    end_idx = fcst_df[fcst_df['Forecast_time']==end].index[0]\n",
        "    \n",
        "    test_df = fcst_df.loc[start_idx:end_idx, :].copy()\n",
        "    \n",
        "    test_df['date'] = test_df['Forecast_time'].str.split(' ').str[0]\n",
        "    test_df['hour'] = test_df['Forecast_time'].str.split(' ').str[1].str.split(':').str[0].astype(int)\n",
        "    \n",
        "    test_df['year'] = test_df['date'].str.split('-').str[0].astype(int)\n",
        "    test_df['month'] = test_df['date'].str.split('-').str[1].astype(int)\n",
        "    test_df['day'] = test_df['date'].str.split('-').str[2].astype(int)\n",
        "    \n",
        "    test_df = test_df[['year', 'month', 'day', 'hour', 'Temperature', 'Humidity', 'WindSpeed', 'WindDirection', 'Cloud']]\n",
        "    \n",
        "    test_x = test_df.to_numpy()\n",
        "    \n",
        "    return test_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgDhn7tF7iwh"
      },
      "source": [
        "dangjin_test = test_datast(dangjin_interpolated)\n",
        "ulsan_test = test_datast(ulsan_interpolated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfS6ZJQY8JLt"
      },
      "source": [
        "submission = pd.read_csv('./data/sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4vXsrbm7uZR"
      },
      "source": [
        "dangjin_floating_pred = submission.iloc[:24*28, 1]\n",
        "\n",
        "for fold in range(10):\n",
        "    dangjin_floating_pred += lgb1_models[fold].predict(dangjin_test)/10\n",
        "    #dangjin_floating_pred += cat1_models[fold].predict(dangjin_test)/20\n",
        "\n",
        "\n",
        "submission.iloc[:24*28, 1] = dangjin_floating_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Mh8owZ5725-"
      },
      "source": [
        "dangjin_warehouse_pred = submission.iloc[:24*28, 2]\n",
        "\n",
        "for fold in range(10):\n",
        "    #dangjin_warehouse_pred += lgb2_models[fold].predict(dangjin_test)/20\n",
        "    dangjin_warehouse_pred += cat2_models[fold].predict(dangjin_test)/10\n",
        "\n",
        "submission.iloc[:24*28, 2] = dangjin_warehouse_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br_XVAFy8AZh"
      },
      "source": [
        "dangjin_pred = submission.iloc[:24*28, 2]\n",
        "\n",
        "for fold in range(10):\n",
        "    #dangjin_pred += lgb3_models[fold].predict(dangjin_test)/20\n",
        "    dangjin_pred += cat3_models[fold].predict(dangjin_test)/10\n",
        "\n",
        "submission.iloc[:24*28, 3] = dangjin_pred.to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMlbWcSj8A9h"
      },
      "source": [
        "ulsan_pred = submission.iloc[:24*28, 4]\n",
        "\n",
        "for fold in range(10):\n",
        "    #ulsan_pred += lgb4_models[fold].predict(ulsan_test)/20\n",
        "    ulsan_pred += cat4_models[fold].predict(ulsan_test)/10\n",
        "ulsan_pred = submission.iloc[:24*28, 4] = ulsan_pred.to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgA1xvQ2xEt1"
      },
      "source": [
        "submission.to_csv('final222.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGMvMCX28PFt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "8c84f9e0-b3ea-4d2d-b1bf-6deee0b8e6b9"
      },
      "source": [
        "submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>dangjin_floating</th>\n",
              "      <th>dangjin_warehouse</th>\n",
              "      <th>dangjin</th>\n",
              "      <th>ulsan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-02-01 01:00:00</td>\n",
              "      <td>-14.030844</td>\n",
              "      <td>-1.886297</td>\n",
              "      <td>-1.886297</td>\n",
              "      <td>12.487710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-02-01 02:00:00</td>\n",
              "      <td>-10.785423</td>\n",
              "      <td>-0.188655</td>\n",
              "      <td>-0.188655</td>\n",
              "      <td>12.840082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-02-01 03:00:00</td>\n",
              "      <td>-13.939630</td>\n",
              "      <td>-0.919544</td>\n",
              "      <td>-0.919544</td>\n",
              "      <td>10.925125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-02-01 04:00:00</td>\n",
              "      <td>-16.172595</td>\n",
              "      <td>-4.454196</td>\n",
              "      <td>-4.454196</td>\n",
              "      <td>7.939006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-02-01 05:00:00</td>\n",
              "      <td>-13.610172</td>\n",
              "      <td>-4.652396</td>\n",
              "      <td>-4.652396</td>\n",
              "      <td>4.616642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1387</th>\n",
              "      <td>2021-07-08 20:00:00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1388</th>\n",
              "      <td>2021-07-08 21:00:00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1389</th>\n",
              "      <td>2021-07-08 22:00:00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1390</th>\n",
              "      <td>2021-07-08 23:00:00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1391</th>\n",
              "      <td>2021-07-08 24:00:00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1392 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     time  dangjin_floating  ...   dangjin      ulsan\n",
              "0     2021-02-01 01:00:00        -14.030844  ... -1.886297  12.487710\n",
              "1     2021-02-01 02:00:00        -10.785423  ... -0.188655  12.840082\n",
              "2     2021-02-01 03:00:00        -13.939630  ... -0.919544  10.925125\n",
              "3     2021-02-01 04:00:00        -16.172595  ... -4.454196   7.939006\n",
              "4     2021-02-01 05:00:00        -13.610172  ... -4.652396   4.616642\n",
              "...                   ...               ...  ...       ...        ...\n",
              "1387  2021-07-08 20:00:00          0.000000  ...  0.000000   0.000000\n",
              "1388  2021-07-08 21:00:00          0.000000  ...  0.000000   0.000000\n",
              "1389  2021-07-08 22:00:00          0.000000  ...  0.000000   0.000000\n",
              "1390  2021-07-08 23:00:00          0.000000  ...  0.000000   0.000000\n",
              "1391  2021-07-08 24:00:00          0.000000  ...  0.000000   0.000000\n",
              "\n",
              "[1392 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy6wYaulxEt1"
      },
      "source": [
        "submission.iloc[:24*28, 1] = dangjin_floating_pred\n",
        "submission.iloc[:24*28, 2] = dangjin_warehouse_pred\n",
        "submission.iloc[:24*28, 3] = dangjin_pred\n",
        "submission.iloc[:24*28, 4] = ulsan_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgD6QmdMxEt2"
      },
      "source": [
        "submission2 = pd.read_csv('./data/sample_submission.csv')\n",
        "submission2.iloc[:24*28, 1] = dangjin_floating_pred\n",
        "submission2.iloc[:24*28, 2] = dangjin_warehouse_pred\n",
        "submission2.iloc[:24*28, 3] = dangjin_pred\n",
        "submission2.iloc[:24*28, 4] = ulsan_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si8jt5a8_F1y"
      },
      "source": [
        "submission[['dangjin_floating','dangjin_warehouse','dangjin','ulsan']] = (submission[['dangjin_floating','dangjin_warehouse','dangjin','ulsan']] + submission2[['dangjin_floating','dangjin_warehouse','dangjin','ulsan']]) / 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "287-uObdIbrF",
        "outputId": "6b571003-46bb-423b-8467-7e314f66b898"
      },
      "source": [
        "submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>dangjin_floating</th>\n",
              "      <th>dangjin_warehouse</th>\n",
              "      <th>dangjin</th>\n",
              "      <th>ulsan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-02-01 01:00:00</td>\n",
              "      <td>-6.904098</td>\n",
              "      <td>-0.891064</td>\n",
              "      <td>0.659742</td>\n",
              "      <td>-1.984275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-02-01 02:00:00</td>\n",
              "      <td>-6.691012</td>\n",
              "      <td>-0.693226</td>\n",
              "      <td>0.816881</td>\n",
              "      <td>-1.073283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-02-01 03:00:00</td>\n",
              "      <td>-6.429722</td>\n",
              "      <td>-1.361885</td>\n",
              "      <td>0.809705</td>\n",
              "      <td>-0.190118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-02-01 04:00:00</td>\n",
              "      <td>-5.708050</td>\n",
              "      <td>-1.485486</td>\n",
              "      <td>0.548285</td>\n",
              "      <td>-0.191640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-02-01 05:00:00</td>\n",
              "      <td>-3.146568</td>\n",
              "      <td>-1.651132</td>\n",
              "      <td>0.530432</td>\n",
              "      <td>-0.169720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1387</th>\n",
              "      <td>2021-07-08 20:00:00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1388</th>\n",
              "      <td>2021-07-08 21:00:00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1389</th>\n",
              "      <td>2021-07-08 22:00:00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1390</th>\n",
              "      <td>2021-07-08 23:00:00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1391</th>\n",
              "      <td>2021-07-08 24:00:00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1392 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     time  dangjin_floating  ...   dangjin     ulsan\n",
              "0     2021-02-01 01:00:00         -6.904098  ...  0.659742 -1.984275\n",
              "1     2021-02-01 02:00:00         -6.691012  ...  0.816881 -1.073283\n",
              "2     2021-02-01 03:00:00         -6.429722  ...  0.809705 -0.190118\n",
              "3     2021-02-01 04:00:00         -5.708050  ...  0.548285 -0.191640\n",
              "4     2021-02-01 05:00:00         -3.146568  ...  0.530432 -0.169720\n",
              "...                   ...               ...  ...       ...       ...\n",
              "1387  2021-07-08 20:00:00          0.000000  ...  0.000000  0.000000\n",
              "1388  2021-07-08 21:00:00          0.000000  ...  0.000000  0.000000\n",
              "1389  2021-07-08 22:00:00          0.000000  ...  0.000000  0.000000\n",
              "1390  2021-07-08 23:00:00          0.000000  ...  0.000000  0.000000\n",
              "1391  2021-07-08 24:00:00          0.000000  ...  0.000000  0.000000\n",
              "\n",
              "[1392 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwdYltLMAGQG"
      },
      "source": [
        "submission.to_csv('lgb+cat.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wVRHA8K43Nn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}