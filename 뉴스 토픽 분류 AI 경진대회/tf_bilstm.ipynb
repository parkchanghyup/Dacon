{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "N6ipWdDE4S9J"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dn8f4zec4T4R"
   },
   "outputs": [],
   "source": [
    "PATH = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jrZOsL5_WuAt"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(PATH + \"train_data.csv\")\n",
    "test = pd.read_csv(PATH + \"test_data.csv\")\n",
    "submission = pd.read_csv(PATH + \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usvUmwRUFuiJ"
   },
   "source": [
    "\n",
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z9GYTuxrFsTu",
    "outputId": "570e00f8-8166-4751-c3b4-6c2d9ba09843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45654,)\n",
      "(9131,)\n",
      "(45654,)\n"
     ]
    }
   ],
   "source": [
    "# 먼저 train 데이터와 test 데이터 인덱스 없이 배열로 만들기\n",
    "X_train = np.array([x for x in train['title']])\n",
    "X_test = np.array([x for x in test['title']])\n",
    "Y_train = np.array([x for x in train['topic_idx']])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xaqbq5U8FsP8",
    "outputId": "425abcf5-ab1c-48d6-da4f-d6a546d1555d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45654 9131\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "vocab_size = 2000  \n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size)  \n",
    "  # Tokenizer 는 데이터에 출현하는 모든 단어의 개수를 세고 빈도 수로 정렬해서 \n",
    "  # num_words 에 지정된 만큼만 숫자로 반환하고, 나머지는 0 으로 반환합니다                 \n",
    "tokenizer.fit_on_texts(X_train) # Tokenizer 에 데이터 실제로 입력\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train)    # 문장 내 모든 단어를 시퀀스 번호로 변환\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)      # 문장 내 모든 단어를 시퀀스 번호로 변환\n",
    "\n",
    "print(len(sequences_train), len(sequences_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7_1s_hVzFsMg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HI2A_vgaF28U"
   },
   "source": [
    "## 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xlcZ1_pkFsIe"
   },
   "outputs": [],
   "source": [
    "# 변환된 시퀀스 번호를 이용해 단어 임베딩 벡터 생성\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NZbBcnV7FsB_",
    "outputId": "9bf9f92e-429a-420d-f178-ee9237dd274f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45654, 14) (9131, 14)\n"
     ]
    }
   ],
   "source": [
    "# 독립변수 데이터 전처리\n",
    "  ## 문장의 길이기 제각각이기 때문에 벡터 크기 다 다름\n",
    "  ## 그러므로 최대 시퀀스 길이 크기(211) 만큼 넉넉하게 늘리고\n",
    "  ## 패딩(padding) 작업을 통해 나머지 빈 공간을 0으로 채움\n",
    "max_length = 14    # 위에서 그래프 확인 후 정함\n",
    "padding_type='post'\n",
    "\n",
    "train_x = pad_sequences(sequences_train, padding='post', maxlen=max_length)\n",
    "test_x = pad_sequences(sequences_test, padding=padding_type, maxlen=max_length)\n",
    "\n",
    "print(train_x.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8yZbUX1Fr9D",
    "outputId": "3ddf65ca-8782-402a-c112-6d8160536d66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n",
      "(45654, 7)\n"
     ]
    }
   ],
   "source": [
    "# 종속변수 데이터 전처리\n",
    "train_y = np_utils.to_categorical(Y_train) # Y_train 에 원-핫 인코딩\n",
    "print(train_y)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pURKcu2dFpWl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgYcVGvjGBGa"
   },
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "DeT2dBDSGCZw"
   },
   "outputs": [],
   "source": [
    "#파라미터 설정\n",
    "vocab_size = 2000 # 제일 많이 사용하는 사이즈\n",
    "embedding_dim = 200  \n",
    "max_length = 14    # 위에서 그래프 확인 후 정함\n",
    "padding_type='post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJGLeFN-GDO4",
    "outputId": "386c9013-adf3-4d6a-86c2-d2265e420d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 14, 200)           400000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 14, 64)            67840     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 14, 64)            33024     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 534,343\n",
      "Trainable params: 534,343\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM 레이어를 사용한 모델 (model2) 정의\n",
    "model2 = Sequential([Embedding(vocab_size, embedding_dim, input_length =max_length),\n",
    "        tf.keras.layers.Bidirectional(LSTM(units = 64, return_sequences = True)),\n",
    "        tf.keras.layers.Bidirectional(LSTM(units = 64, return_sequences = True)),\n",
    "        tf.keras.layers.Bidirectional(LSTM(units = 64)),\n",
    "        Dense(7, activation='softmax')    # 결과값이 0~4 이므로 Dense(5)\n",
    "    ])\n",
    "    \n",
    "model2.compile(loss= 'categorical_crossentropy', #여러개 정답 중 하나 맞추는 문제이므로 손실 함수는 categorical_crossentropy\n",
    "              optimizer= 'adam',\n",
    "              metrics = ['accuracy']) \n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79ZEHbFXGG9a",
    "outputId": "6ccc8362-fe48-452b-a4b0-a6a0e24abf17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "366/366 [==============================] - 33s 76ms/step - loss: 1.1099 - accuracy: 0.5889 - val_loss: 1.1619 - val_accuracy: 0.5925\n",
      "Epoch 2/10\n",
      "366/366 [==============================] - 27s 74ms/step - loss: 0.8126 - accuracy: 0.7192 - val_loss: 1.1608 - val_accuracy: 0.5768\n",
      "Epoch 3/10\n",
      "366/366 [==============================] - 27s 74ms/step - loss: 0.7633 - accuracy: 0.7399 - val_loss: 1.1802 - val_accuracy: 0.5681\n",
      "Epoch 4/10\n",
      "366/366 [==============================] - 27s 75ms/step - loss: 0.7331 - accuracy: 0.7480 - val_loss: 1.1730 - val_accuracy: 0.5716\n",
      "Epoch 5/10\n",
      "366/366 [==============================] - 27s 74ms/step - loss: 0.7123 - accuracy: 0.7530 - val_loss: 1.1003 - val_accuracy: 0.5979\n",
      "Epoch 6/10\n",
      "366/366 [==============================] - 29s 79ms/step - loss: 0.6908 - accuracy: 0.7591 - val_loss: 1.1719 - val_accuracy: 0.5745\n",
      "Epoch 7/10\n",
      "366/366 [==============================] - 29s 79ms/step - loss: 0.6718 - accuracy: 0.7630 - val_loss: 1.1488 - val_accuracy: 0.5722\n",
      "Epoch 8/10\n",
      "366/366 [==============================] - 28s 76ms/step - loss: 0.6574 - accuracy: 0.7660 - val_loss: 1.1782 - val_accuracy: 0.5723\n",
      "Epoch 9/10\n",
      "366/366 [==============================] - 27s 74ms/step - loss: 0.6432 - accuracy: 0.7705 - val_loss: 1.1898 - val_accuracy: 0.5739\n",
      "Epoch 10/10\n",
      "366/366 [==============================] - 27s 74ms/step - loss: 0.6252 - accuracy: 0.7752 - val_loss: 1.2616 - val_accuracy: 0.5465\n"
     ]
    }
   ],
   "source": [
    "# 모델 실행해보기\n",
    "history = model2.fit(train_x, train_y, epochs=10, batch_size=100, validation_split= 0.2) \n",
    "  # 데이터가 50000개가 넘어 학습시간이 오래 걸리기 때문에 batch size 를 100으로 크게 잡았다\n",
    "  # 추이를 확인하게 위해 일단 10회만 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLtTz9S_GMIa",
    "outputId": "6d190336-5b46-4165-9314-90ab5bdf7a73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for CV #1\n",
      "Epoch 1/10\n",
      "72/72 [==============================] - 18s 255ms/step - loss: 0.6858 - accuracy: 0.7564 - val_loss: 0.6686 - val_accuracy: 0.7609\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 18s 252ms/step - loss: 0.6480 - accuracy: 0.7693 - val_loss: 0.6714 - val_accuracy: 0.7559\n",
      "Epoch 3/10\n",
      "72/72 [==============================] - 18s 253ms/step - loss: 0.6318 - accuracy: 0.7724 - val_loss: 0.6819 - val_accuracy: 0.7582\n",
      "Epoch 4/10\n",
      "72/72 [==============================] - 19s 257ms/step - loss: 0.6186 - accuracy: 0.7766 - val_loss: 0.6956 - val_accuracy: 0.7540\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00004: early stopping\n",
      "training model for CV #2\n",
      "Epoch 1/10\n",
      "72/72 [==============================] - 19s 264ms/step - loss: 0.6575 - accuracy: 0.7649 - val_loss: 0.6450 - val_accuracy: 0.7707\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 19s 270ms/step - loss: 0.6364 - accuracy: 0.7701 - val_loss: 0.6569 - val_accuracy: 0.7667\n",
      "Epoch 3/10\n",
      "72/72 [==============================] - 19s 271ms/step - loss: 0.6226 - accuracy: 0.7749 - val_loss: 0.6731 - val_accuracy: 0.7599\n",
      "Epoch 4/10\n",
      "72/72 [==============================] - 19s 260ms/step - loss: 0.6115 - accuracy: 0.7768 - val_loss: 0.6886 - val_accuracy: 0.7594\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00004: early stopping\n",
      "training model for CV #3\n",
      "Epoch 1/10\n",
      "72/72 [==============================] - 19s 263ms/step - loss: 0.6459 - accuracy: 0.7677 - val_loss: 0.6319 - val_accuracy: 0.7744\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 20s 274ms/step - loss: 0.6277 - accuracy: 0.7728 - val_loss: 0.6478 - val_accuracy: 0.7672\n",
      "Epoch 3/10\n",
      "72/72 [==============================] - 19s 259ms/step - loss: 0.6150 - accuracy: 0.7769 - val_loss: 0.6635 - val_accuracy: 0.7638\n",
      "Epoch 4/10\n",
      "72/72 [==============================] - 19s 260ms/step - loss: 0.6046 - accuracy: 0.7790 - val_loss: 0.6831 - val_accuracy: 0.7560\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00004: early stopping\n",
      "training model for CV #4\n",
      "Epoch 1/10\n",
      "72/72 [==============================] - 18s 257ms/step - loss: 0.6329 - accuracy: 0.7714 - val_loss: 0.6366 - val_accuracy: 0.7699\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 18s 254ms/step - loss: 0.6182 - accuracy: 0.7754 - val_loss: 0.6546 - val_accuracy: 0.7605\n",
      "Epoch 3/10\n",
      "72/72 [==============================] - 18s 254ms/step - loss: 0.6071 - accuracy: 0.7775 - val_loss: 0.6750 - val_accuracy: 0.7558\n",
      "Epoch 4/10\n",
      "72/72 [==============================] - 18s 255ms/step - loss: 0.5960 - accuracy: 0.7824 - val_loss: 0.6958 - val_accuracy: 0.7496\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00004: early stopping\n",
      "training model for CV #5\n",
      "Epoch 1/10\n",
      "72/72 [==============================] - 18s 255ms/step - loss: 0.6245 - accuracy: 0.7734 - val_loss: 0.6323 - val_accuracy: 0.7717\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 18s 253ms/step - loss: 0.6096 - accuracy: 0.7782 - val_loss: 0.6502 - val_accuracy: 0.7636\n",
      "Epoch 3/10\n",
      "72/72 [==============================] - 19s 258ms/step - loss: 0.5974 - accuracy: 0.7806 - val_loss: 0.6751 - val_accuracy: 0.7571\n",
      "Epoch 4/10\n",
      "72/72 [==============================] - 18s 256ms/step - loss: 0.5891 - accuracy: 0.7831 - val_loss: 0.7049 - val_accuracy: 0.7506\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 계층 교차 검증\n",
    "n_fold = 5  \n",
    "seed = 42\n",
    "\n",
    "cv = StratifiedKFold(n_splits = n_fold, shuffle=True, random_state=seed)\n",
    "\n",
    "# 테스트데이터의 예측값 담을 곳 생성\n",
    "test_y = np.zeros((test_x.shape[0], 7))\n",
    "\n",
    "# 조기 종료 옵션 추가\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3,\n",
    "                   verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
    "\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(train_x, Y_train), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "\n",
    "    model2.fit(train_x[i_trn], \n",
    "            to_categorical(Y_train[i_trn]),\n",
    "            validation_data=(train_x[i_val], to_categorical(Y_train[i_val])),\n",
    "            epochs=10,\n",
    "            batch_size=512,\n",
    "            callbacks=[es])     # 조기 종료 옵션\n",
    "                      \n",
    "    test_y += model2.predict(test_x) / n_fold    # 나온 예측값들을 교차 검증 횟수로 나눈다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eOFNFpQpHZLV",
    "outputId": "7beeb407-a10d-418e-f189-dd3c94f5a388"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02572614, 0.10739847, 0.80665508, ..., 0.00346195, 0.00225981,\n",
       "        0.00187478],\n",
       "       [0.07950623, 0.10726345, 0.2322131 , ..., 0.11540738, 0.07888728,\n",
       "        0.11123841],\n",
       "       [0.00992322, 0.13168615, 0.84162672, ..., 0.00213506, 0.00088051,\n",
       "        0.00453327],\n",
       "       ...,\n",
       "       [0.01147092, 0.00539301, 0.79948118, ..., 0.1354564 , 0.00741784,\n",
       "        0.01007499],\n",
       "       [0.24999254, 0.04271241, 0.32225451, ..., 0.0395082 , 0.03881319,\n",
       "        0.02081436],\n",
       "       [0.00618821, 0.00268449, 0.74549425, ..., 0.01032806, 0.00938298,\n",
       "        0.20711877]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터의 예측값 확인\n",
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-Pl1ABIeKoJF"
   },
   "outputs": [],
   "source": [
    "topic = []\n",
    "for i in range(len(test_y)):\n",
    "    topic.append(np.argmax(test_y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "-Fs5JyInKo-e",
    "outputId": "49e94e66-192e-4cd3-f515-1fec442e24f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>topic_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45654</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45657</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45658</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9126</th>\n",
       "      <td>54780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9127</th>\n",
       "      <td>54781</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9128</th>\n",
       "      <td>54782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9129</th>\n",
       "      <td>54783</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9130</th>\n",
       "      <td>54784</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9131 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  topic_idx\n",
       "0     45654          0\n",
       "1     45655          0\n",
       "2     45656          0\n",
       "3     45657          0\n",
       "4     45658          0\n",
       "...     ...        ...\n",
       "9126  54780          0\n",
       "9127  54781          0\n",
       "9128  54782          0\n",
       "9129  54783          0\n",
       "9130  54784          0\n",
       "\n",
       "[9131 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzRnIpGQKpnL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
