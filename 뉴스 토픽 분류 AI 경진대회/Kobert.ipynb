{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "pch",
      "language": "python",
      "name": "pch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "Kobert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdvKC3HRx7ai"
      },
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7leMjwbx7al"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
        "\n",
        "from transformers import AdamW\n",
        "from adamp import AdamP\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup\n",
        "\n",
        "##GPU 사용 시\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMzotZISx7am",
        "outputId": "3b69dc4b-1eac-42dc-93f8-7fcf409f48ae"
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.9.0+cu111'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_1GyCuCx7an",
        "outputId": "258566e0-0bcc-418c-d89c-2ac51a227cbe"
      },
      "source": [
        "# 학습용 데이터셋 불러오기\n",
        "import pandas as pd\n",
        "# 판다스로 훈련셋과 테스트셋 데이터 로드\n",
        "train = pd.read_csv('train_data.csv')\n",
        "test = pd.read_csv('test_data.csv')\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(45654, 3)\n",
            "(9131, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTOQAQWRx7an"
      },
      "source": [
        "train = train.iloc[:,1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjtulSF2x7an"
      },
      "source": [
        "from konlpy.tag import Okt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSziZSADx7ao"
      },
      "source": [
        "# 형태소 분석기(Okt) 불러오기 \n",
        "okt=Okt() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGe2mpC_x7ao"
      },
      "source": [
        "# 조사, 어미, 구두점 제거\n",
        "def func(text):\n",
        "    clean = []\n",
        "    for word in okt.pos(text, stem=True): #어간 추출\n",
        "        if word[1] not in ['Josa', 'Eomi', 'Punctuation']: #조사, 어미, 구두점 제외 \n",
        "            clean.append(word[0])\n",
        "    \n",
        "    \n",
        "    return \" \".join(clean) \n",
        "\n",
        "train['title'] = train['title'].apply(lambda x : func(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zmQZJw9x7ao",
        "outputId": "32998333-8bff-4d2e-c45b-f64c3de5247b"
      },
      "source": [
        "bertmodel, vocab = get_pytorch_kobert_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cached model\n",
            "using cached model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_pZCTdpx7ap",
        "outputId": "83f5331c-c8a3-4092-dd88-292eb8f6390d"
      },
      "source": [
        "# 기본 Bert tokenizer 사용\n",
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cached model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IkrCQecx7aq"
      },
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair) \n",
        "\n",
        "#         self.sentences = [transform([i[sent_idx]]) for i in dataset.to_numpy()]\n",
        "        self.token_ids = []\n",
        "        self.valid_length =[]\n",
        "        self.segment_ids = []\n",
        "        for i in dataset.to_numpy():\n",
        "            out = transform([i[sent_idx]])\n",
        "            self.token_ids.append(out[0])\n",
        "            self.valid_length.append(out[1])\n",
        "            self.segment_ids.append(out[2])\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset.to_numpy()]\n",
        "        \n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        token_ids = self.token_ids[i]\n",
        "        valid_length = self.valid_length[i]\n",
        "        segment_ids = self.segment_ids[i]\n",
        "        return {\n",
        "            'token_ids' : torch.tensor(token_ids, dtype=torch.long),\n",
        "            'valid_length' : torch.tensor(valid_length, dtype=torch.long),\n",
        "            'segment_ids' : torch.tensor(segment_ids, dtype=torch.long),\n",
        "            'label' : torch.tensor(self.labels[i], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ86xqs8x7ar"
      },
      "source": [
        "# Setting parameters\n",
        "max_len = 64 # 해당 길이를 초과하는 단어에 대해선 bert가 학습하지 않음\n",
        "batch_size = 64\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 5\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate = 5e-5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P7FZtUPx7ar",
        "outputId": "f75f9ac3-ec5a-4e1e-cd5d-92649c9465c6"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>topic_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>인천 → 핀란드 항공기 결항 휴가 철 여행객 분통</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>실리콘밸리 넘어서다 구글 15조원 들이다 美 전역 거점 화</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>이란 외무 긴장 완화 해결 책 미국 경제 전쟁 멈추다 것</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NYT 클린턴 측근 韓 기업 특수 관계 조명 공과 사 맞다 물리다 종합</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>시진핑 트럼프 중미 무역 협상 조속 타결 희망</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     title  topic_idx\n",
              "0              인천 → 핀란드 항공기 결항 휴가 철 여행객 분통          4\n",
              "1         실리콘밸리 넘어서다 구글 15조원 들이다 美 전역 거점 화          4\n",
              "2          이란 외무 긴장 완화 해결 책 미국 경제 전쟁 멈추다 것          4\n",
              "3  NYT 클린턴 측근 韓 기업 특수 관계 조명 공과 사 맞다 물리다 종합          4\n",
              "4                시진핑 트럼프 중미 무역 협상 조속 타결 희망          4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTqYtkozx7as"
      },
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes = 7, # softmax 사용 <- binary일 경우는 2\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        bert_output = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        pooler = bert_output['pooler_output']\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)\n",
        "      \n",
        "model = BERTClassifier(bertmodel, dr_rate=0.7).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fedXWSLx7at"
      },
      "source": [
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "# 옵티마이저 선언\n",
        "optimizer = AdamP(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss() # softmax용 Loss Function 정하기 <- binary classification도 해당 loss function 사용 가능"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxPR3DuQx7au"
      },
      "source": [
        "# data_train = BERTDataset(train, 0, 1, tok, max_len, True, False)\n",
        "# data_test = BERTDataset(valid, 0, 1, tok, max_len, True, False)\n",
        "\n",
        "# # pytorch용 DataLoader 사용\n",
        "# train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
        "# test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zxncILRx7au"
      },
      "source": [
        "\n",
        "# 학습 평가 지표인 accuracy 계산 -> 얼마나 타겟값을 많이 맞추었는가\n",
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "referenced_widgets": [
            "081d4025a38146f2a61612a698f1a74d",
            "823a1bc911454c4fab506b77b8b79ede",
            "21a129cf359947b78d364c0b7a0cea73",
            "5b5e9431c0584a7c86a35b841ddc3931",
            "9559ca07b3ad432eb6f14049dfac3c6b",
            "637540c27b0e4ba8a9510d18f83a8625",
            "ecf31a2c2e8648e68b1429f7a2acf8f8",
            "802733ca7ad84d669102b59953881bea",
            "b51656fd9d2443c2a77b157972456dd6",
            "792576135eac43e5a40303c577aafec0",
            "62fdd6cbf19245178c5684dc484c5637",
            "b838f77cbd344df794715adaf78671e8",
            "43daeaaea37f43d4b2fde7ce23e66fb4",
            "94dab56e303c4d24b51c1c2c57d5bf0c",
            "382a4db7696c4b699c42d75b2cea103f",
            "4a4c304e93db40e3b24595d98395bb7e",
            "d8d592d926c64c688f1cadc37c482296",
            "235dc45b87864767b4f30eafdebd2746",
            "030465bad6e649bb8dfd7a5c0190187c",
            "49813f82340b4aaa88351b4719c4850d",
            "f9483f2eaaff4d39a6455e099983d729",
            "b8bbc74b629a468f89205d9694961151",
            "4952a6a2ab024b509ed0c6b65fc085e9",
            "b564d7869d9d410b8f0e4451a0bf871d",
            "6a7e0ccb05cc4ab0b9b845245a488a2f",
            "ac7bd64ec6504d0ca9847e98c50e2f92",
            "da957b4035864525bc2d51bbe5a95a9e",
            "9d0f49ca207746ce844ef30aa47d36f4",
            "e7a82a4dd97147aba7aff1802889cc3e",
            "30e01fa3a8824a2eb7cd47d1fcb1aea0"
          ]
        },
        "id": "F9ISdEahx7au",
        "outputId": "1b4add28-2a81-48e1-97d3-6e4bb31c9821"
      },
      "source": [
        "best_models = [] # 폴드별로 가장 validation acc가 높은 모델 저장\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "\n",
        "# dirty_mnist_answer에서 train_idx와 val_idx를 생성\n",
        "best_models = [] # 폴드별로 가장 validation acc가 높은 모델 저장\n",
        "for fold_index, (trn_idx, val_idx) in enumerate(kfold.split(train['title'],train['topic_idx']),1):\n",
        "    \n",
        "    # cuda cache 초기화\n",
        "    torch.cuda.empty_cache()\n",
        "    train_data = train.loc[trn_idx]\n",
        "    valid_data = train.loc[val_idx]\n",
        "\n",
        "    data_train = BERTDataset(train_data, 0, 1, tok, max_len, True, False)\n",
        "    data_test = BERTDataset(valid_data, 0, 1, tok, max_len, True, False)\n",
        "\n",
        "    # pytorch용 DataLoader 사용\n",
        "    train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
        "    test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)\n",
        "    bertmodel, _ = get_pytorch_kobert_model()\n",
        "    model = BERTClassifier(bertmodel, dr_rate=0.7).to(device)\n",
        "    \n",
        "    # Prepare optimizer and schedule (linear warmup and decay)\n",
        "    no_decay = ['bias', 'LayerNorm.weight']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "\n",
        "    # 옵티마이저 선언\n",
        "    optimizer = AdamP(optimizer_grouped_parameters, lr=learning_rate)\n",
        "    loss_fn = nn.CrossEntropyLoss() # softmax용 Loss Function 정하기 <- binary classification도 해당 loss function 사용 가능\n",
        "   \n",
        "    #scheduler\n",
        "    t_total = len(train_dataloader) * num_epochs\n",
        "    warmup_step = int(t_total * warmup_ratio)\n",
        "    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "    valid_acc_max = 0\n",
        "    # 모델 학습 시작\n",
        "    model.train()\n",
        "    \n",
        "    for e in range(3):\n",
        "        train_acc = 0.0\n",
        "        test_acc = 0.0\n",
        "        tqdm_dataset = tqdm(enumerate(train_dataloader))\n",
        "        for batch_id, items in tqdm_dataset:\n",
        "            optimizer.zero_grad()\n",
        "            token_ids = items['token_ids'].to(device)\n",
        "            segment_ids = items['segment_ids'].to(device)\n",
        "            valid_length= items['valid_length']\n",
        "            label = items['label'].to(device)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                out = model(token_ids, valid_length, segment_ids)\n",
        "                loss = loss_fn(out, label)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm) # gradient clipping\n",
        "            optimizer.step()\n",
        "            scheduler.step()  # Update learning rate schedule\n",
        "            train_acc += calc_accuracy(out, label)\n",
        "            if batch_id % log_interval == 0:\n",
        "                print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "        print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "        \n",
        "        \n",
        "        model.eval() # 평가 모드로 변경\n",
        "        tqdm_dataset = tqdm(enumerate(test_dataloader))\n",
        "        for batch_id, items in tqdm_dataset:\n",
        "            token_ids = items['token_ids'].to(device)\n",
        "            segment_ids = items['segment_ids'].to(device)\n",
        "            valid_length= items['valid_length']\n",
        "            label = items['label'].to(device)\n",
        "            with torch.no_grad():\n",
        "                out = model(token_ids, valid_length, segment_ids)\n",
        "                test_acc += calc_accuracy(out, label)\n",
        "        print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n",
        "        \n",
        "                # 모델 저장\n",
        "        if valid_acc_max < test_acc:\n",
        "            valid_acc_max = test_acc\n",
        "            best_model = model\n",
        "\n",
        "\n",
        "    # 폴드별로 가장 좋은 모델 저장\n",
        "    best_models.append(best_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cached model\n",
            "using cached model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "081d4025a38146f2a61612a698f1a74d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1 loss 2.0061492919921875 train acc 0.1875\n",
            "epoch 1 batch id 201 loss 0.5755143165588379 train acc 0.5356809701492538\n",
            "epoch 1 batch id 401 loss 0.05438694357872009 train acc 0.6998519326683291\n",
            "epoch 1 train acc 0.7538036339754816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "823a1bc911454c4fab506b77b8b79ede",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 test acc 0.8706852740282973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21a129cf359947b78d364c0b7a0cea73",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1 loss 0.5779359340667725 train acc 0.84375\n",
            "epoch 2 batch id 201 loss 0.31804943084716797 train acc 0.857431592039801\n",
            "epoch 2 batch id 401 loss 0.01813340187072754 train acc 0.8801044264339152\n",
            "epoch 2 train acc 0.892595227670753\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b5e9431c0584a7c86a35b841ddc3931",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2 test acc 0.8806869003089933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9559ca07b3ad432eb6f14049dfac3c6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1 loss 0.25641071796417236 train acc 0.90625\n",
            "epoch 3 batch id 201 loss 0.19398295879364014 train acc 0.9064054726368159\n",
            "epoch 3 batch id 401 loss 0.00566469132900238 train acc 0.9252649625935162\n",
            "epoch 3 train acc 0.9353522227426384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "637540c27b0e4ba8a9510d18f83a8625",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3 test acc 0.882214079525126\n",
            "using cached model\n",
            "using cached model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ecf31a2c2e8648e68b1429f7a2acf8f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1 loss 1.98712158203125 train acc 0.140625\n",
            "epoch 1 batch id 201 loss 0.6489734649658203 train acc 0.5366138059701493\n",
            "epoch 1 batch id 401 loss 0.08132278919219971 train acc 0.6982543640897756\n",
            "epoch 1 train acc 0.7532977131104143\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "802733ca7ad84d669102b59953881bea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 test acc 0.8698670515530981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b51656fd9d2443c2a77b157972456dd6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1 loss 0.39500248432159424 train acc 0.90625\n",
            "epoch 2 batch id 201 loss 0.5004416704177856 train acc 0.8585976368159204\n",
            "epoch 2 batch id 401 loss 0.0609494149684906 train acc 0.880143391521197\n",
            "epoch 2 train acc 0.8941142630228486\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "792576135eac43e5a40303c577aafec0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2 test acc 0.8641852333712798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62fdd6cbf19245178c5684dc484c5637",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1 loss 0.3072355091571808 train acc 0.90625\n",
            "epoch 3 batch id 201 loss 0.37536120414733887 train acc 0.9055503731343284\n",
            "epoch 3 batch id 401 loss 0.01277652382850647 train acc 0.9233167082294265\n",
            "epoch 3 train acc 0.9349417586445649\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b838f77cbd344df794715adaf78671e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3 test acc 0.8759859326719791\n",
            "using cached model\n",
            "using cached model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43daeaaea37f43d4b2fde7ce23e66fb4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1 loss 1.9434280395507812 train acc 0.171875\n",
            "epoch 1 batch id 201 loss 0.4452838897705078 train acc 0.5318718905472637\n",
            "epoch 1 batch id 401 loss 0.24816960096359253 train acc 0.694942331670823\n",
            "epoch 1 train acc 0.750506557243514\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94dab56e303c4d24b51c1c2c57d5bf0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 test acc 0.8773530248820947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "382a4db7696c4b699c42d75b2cea103f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1 loss 0.2268916368484497 train acc 0.9375\n",
            "epoch 2 batch id 201 loss 0.15333521366119385 train acc 0.8575093283582089\n",
            "epoch 2 batch id 401 loss 0.009874433279037476 train acc 0.8802992518703242\n",
            "epoch 2 train acc 0.8943331772084878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a4c304e93db40e3b24595d98395bb7e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2 test acc 0.8827070458611156\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8d592d926c64c688f1cadc37c482296",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1 loss 0.18833497166633606 train acc 0.9375\n",
            "epoch 3 batch id 201 loss 0.1568985879421234 train acc 0.9078047263681592\n",
            "epoch 3 batch id 401 loss 0.005997747182846069 train acc 0.9271352867830424\n",
            "epoch 3 train acc 0.9368979859894921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "235dc45b87864767b4f30eafdebd2746",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3 test acc 0.8826511424621889\n",
            "using cached model\n",
            "using cached model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "030465bad6e649bb8dfd7a5c0190187c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1 loss 2.0920639038085938 train acc 0.15625\n",
            "epoch 1 batch id 201 loss 0.5848350524902344 train acc 0.5513059701492538\n",
            "epoch 1 batch id 401 loss 0.18772101402282715 train acc 0.7067877182044888\n",
            "epoch 1 train acc 0.759358581436077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49813f82340b4aaa88351b4719c4850d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 test acc 0.8783364164904862\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9483f2eaaff4d39a6455e099983d729",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1 loss 0.2806488275527954 train acc 0.9375\n",
            "epoch 2 batch id 201 loss 0.31155669689178467 train acc 0.8559546019900498\n",
            "epoch 2 batch id 401 loss 0.012970715761184692 train acc 0.8820137157107232\n",
            "epoch 2 train acc 0.8955505691768827\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8bbc74b629a468f89205d9694961151",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2 test acc 0.8745121157911856\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4952a6a2ab024b509ed0c6b65fc085e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1 loss 0.2784668803215027 train acc 0.953125\n",
            "epoch 3 batch id 201 loss 0.16624504327774048 train acc 0.9090485074626866\n",
            "epoch 3 batch id 401 loss 0.004858300089836121 train acc 0.9270963216957606\n",
            "epoch 3 train acc 0.937732914511465\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b564d7869d9d410b8f0e4451a0bf871d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3 test acc 0.8718338347698813\n",
            "using cached model\n",
            "using cached model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a7e0ccb05cc4ab0b9b845245a488a2f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1 loss 1.9492645263671875 train acc 0.171875\n",
            "epoch 1 batch id 201 loss 0.5073766708374023 train acc 0.4986007462686567\n",
            "epoch 1 batch id 401 loss 0.18247419595718384 train acc 0.6780704488778054\n",
            "epoch 1 train acc 0.7392483282916733\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac7bd64ec6504d0ca9847e98c50e2f92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 test acc 0.8760354229104229\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da957b4035864525bc2d51bbe5a95a9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1 loss 0.2128760814666748 train acc 0.9375\n",
            "epoch 2 batch id 201 loss 0.3520752191543579 train acc 0.8566542288557214\n",
            "epoch 2 batch id 401 loss 0.035223305225372314 train acc 0.8799096009975063\n",
            "epoch 2 train acc 0.8940057315714058\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d0f49ca207746ce844ef30aa47d36f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2 test acc 0.8714462620712621\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7a82a4dd97147aba7aff1802889cc3e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1 loss 0.1029348373413086 train acc 0.9375\n",
            "epoch 3 batch id 201 loss 0.20599442720413208 train acc 0.9063277363184079\n",
            "epoch 3 batch id 401 loss 0.04179313778877258 train acc 0.9261221945137157\n",
            "epoch 3 train acc 0.9375273642732049\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30e01fa3a8824a2eb7cd47d1fcb1aea0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3 test acc 0.8791468947718948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylYZfBL6x7av",
        "outputId": "4cd4e589-154a-4a2e-a5f7-8cd15ca91b3c"
      },
      "source": [
        "len(best_models)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR9PKKd1x7aw"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "# 시간 표시 함수\n",
        "def format_time(elapsed):\n",
        "\n",
        "    # 반올림\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # hh:mm:ss으로 형태 변경\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KThGnwDOx7aw"
      },
      "source": [
        "preds = []\n",
        "#시작 시간 설정\n",
        "t0 = time.time()\n",
        "\n",
        "\n",
        "for idx,Best_Model in enumerate(best_models):\n",
        "    print('#'*10,idx+1,\": 번째 모델 예측 진행\",'#'*10)\n",
        "    \n",
        "    model = Best_Model\n",
        "    model.eval()\n",
        "    pred = []\n",
        "    for step in range(len(test)):\n",
        "        if step % 1000 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step,len(test), elapsed))\n",
        "        test_sentence = test.title[step]\n",
        "        test_label = 0\n",
        "\n",
        "\n",
        "        unseen_test = pd.DataFrame([[test_sentence, test_label]], columns = [['title', 'topic_idx']])\n",
        "        #unseen_values = unseen_test.values\n",
        "        test_set = BERTDataset(unseen_test, 0, 1, tok, max_len, True, False)\n",
        "        test_input = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
        "\n",
        "        for batch_id, items in enumerate(test_input):\n",
        "            token_ids = items['token_ids'].to(device)\n",
        "            segment_ids = items['segment_ids'].to(device)\n",
        "            valid_length= items['valid_length']\n",
        "            #label = items['label'].to(device)\n",
        "            out = model(token_ids, valid_length, segment_ids)\n",
        "            pred.append(int(torch.argmax(out).cpu().numpy()))\n",
        "    preds.append(pred)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTFl-n9wx7aw"
      },
      "source": [
        "df = pd.DataFrame(preds).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d5cR90Bx7ax"
      },
      "source": [
        "df= df.mode(axis=1)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkb3w8q_x7ax"
      },
      "source": [
        "sub = pd.read_csv('sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqKeKJkyx7ax"
      },
      "source": [
        "sub['topic_idx'] = df\n",
        "sub['topic_idx'] = sub['topic_idx'].apply(lambda x : int(x))\n",
        "#sub.to_csv('hyup_전처리 x drop_out:0.7.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "mBL4cKctx7ax",
        "outputId": "b85c4133-92b8-4d1b-e164-d3655280bfec"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "# 테스트 데이터 예측\n",
        "\n",
        "#시작 시간 설정\n",
        "t0 = time.time()\n",
        "\n",
        "# 평가모드로 변경\n",
        "model.eval()\n",
        "\n",
        "pred = []\n",
        "for step in range(len(test)):\n",
        "    if step % 500 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step,len(test), elapsed))\n",
        "    test_sentence = test.title[step]\n",
        "    test_label = 0\n",
        "\n",
        "\n",
        "    unseen_test = pd.DataFrame([[test_sentence, test_label]], columns = [['title', 'topic_idx']])\n",
        "    #unseen_values = unseen_test.values\n",
        "    test_set = BERTDataset(unseen_test, 0, 1, tok, max_len, True, False)\n",
        "    test_input = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
        "\n",
        "    for batch_id, items in enumerate(test_input):\n",
        "        token_ids = items['token_ids'].to(device)\n",
        "        segment_ids = items['segment_ids'].to(device)\n",
        "        valid_length= items['valid_length']\n",
        "        #label = items['label'].to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        pred.append(int(torch.argmax(out).cpu().numpy()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Batch   500  of  9,131.    Elapsed: 0:00:05.\n",
            "  Batch 1,000  of  9,131.    Elapsed: 0:00:10.\n",
            "  Batch 1,500  of  9,131.    Elapsed: 0:00:15.\n",
            "  Batch 2,000  of  9,131.    Elapsed: 0:00:20.\n",
            "  Batch 2,500  of  9,131.    Elapsed: 0:00:25.\n",
            "  Batch 3,000  of  9,131.    Elapsed: 0:00:29.\n",
            "  Batch 3,500  of  9,131.    Elapsed: 0:00:34.\n",
            "  Batch 4,000  of  9,131.    Elapsed: 0:00:39.\n",
            "  Batch 4,500  of  9,131.    Elapsed: 0:00:44.\n",
            "  Batch 5,000  of  9,131.    Elapsed: 0:00:49.\n",
            "  Batch 5,500  of  9,131.    Elapsed: 0:00:54.\n",
            "  Batch 6,000  of  9,131.    Elapsed: 0:00:59.\n",
            "  Batch 6,500  of  9,131.    Elapsed: 0:01:04.\n",
            "  Batch 7,000  of  9,131.    Elapsed: 0:01:09.\n",
            "  Batch 7,500  of  9,131.    Elapsed: 0:01:14.\n",
            "  Batch 8,000  of  9,131.    Elapsed: 0:01:18.\n",
            "  Batch 8,500  of  9,131.    Elapsed: 0:01:23.\n",
            "  Batch 9,000  of  9,131.    Elapsed: 0:01:28.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdk2_t1Ex7ay",
        "outputId": "e8e2bb20-6d36-4486-ea0e-6992cbe84be5"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0.0\n",
              "1       3.0\n",
              "2       2.0\n",
              "3       0.0\n",
              "4       3.0\n",
              "       ... \n",
              "9126    3.0\n",
              "9127    2.0\n",
              "9128    3.0\n",
              "9129    2.0\n",
              "9130    2.0\n",
              "Name: 0, Length: 9131, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ju3iMqRx7az"
      },
      "source": [
        "sub = pd.read_csv('sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN5j7Q4Gx7az"
      },
      "source": [
        "sub['topic_idx'] = df\n",
        "sub['topic_idx'] = sub['topic_idx'].apply(lambda x : int(x))\n",
        "sub.to_csv('hyup_전처리 x drop_out:0.7.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}