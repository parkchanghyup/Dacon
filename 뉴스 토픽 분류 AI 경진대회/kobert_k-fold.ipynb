{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "from transformers import AdamW\n",
    "from adamp import AdamP\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "import random\n",
    "\n",
    "##GPU 사용 시\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  \n",
    "    torch.backends.cudnn.deterministic = True  \n",
    "    torch.backends.cudnn.benchmark = True  \n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0+cu111'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45654, 3)\n",
      "(9131, 2)\n"
     ]
    }
   ],
   "source": [
    "# 학습용 데이터셋 불러오기\n",
    "import pandas as pd\n",
    "# 판다스로 훈련셋과 테스트셋 데이터 로드\n",
    "train = pd.read_csv('train_data.csv')\n",
    "test = pd.read_csv('test_data.csv')\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>topic_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>인천→핀란드 항공기 결항…휴가철 여행객 분통</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>실리콘밸리 넘어서겠다…구글 15조원 들여 美전역 거점화</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>이란 외무 긴장완화 해결책은 미국이 경제전쟁 멈추는 것</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NYT 클린턴 측근韓기업 특수관계 조명…공과 사 맞물려종합</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>시진핑 트럼프에 중미 무역협상 조속 타결 희망</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45649</th>\n",
       "      <td>45649</td>\n",
       "      <td>KB금융 미국 IB 스티펠과 제휴…선진국 시장 공략</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45650</th>\n",
       "      <td>45650</td>\n",
       "      <td>1보 서울시교육청 신종코로나 확산에 개학 연기·휴업 검토</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45651</th>\n",
       "      <td>45651</td>\n",
       "      <td>게시판 키움증권 2020 키움 영웅전 실전투자대회</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45652</th>\n",
       "      <td>45652</td>\n",
       "      <td>답변하는 배기동 국립중앙박물관장</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45653</th>\n",
       "      <td>45653</td>\n",
       "      <td>2020 한국인터넷기자상 시상식 내달 1일 개최…특별상 김성후</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45654 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                               title  topic_idx\n",
       "0          0            인천→핀란드 항공기 결항…휴가철 여행객 분통          4\n",
       "1          1      실리콘밸리 넘어서겠다…구글 15조원 들여 美전역 거점화          4\n",
       "2          2      이란 외무 긴장완화 해결책은 미국이 경제전쟁 멈추는 것          4\n",
       "3          3    NYT 클린턴 측근韓기업 특수관계 조명…공과 사 맞물려종합          4\n",
       "4          4           시진핑 트럼프에 중미 무역협상 조속 타결 희망          4\n",
       "...      ...                                 ...        ...\n",
       "45649  45649        KB금융 미국 IB 스티펠과 제휴…선진국 시장 공략          1\n",
       "45650  45650     1보 서울시교육청 신종코로나 확산에 개학 연기·휴업 검토          2\n",
       "45651  45651         게시판 키움증권 2020 키움 영웅전 실전투자대회          1\n",
       "45652  45652                   답변하는 배기동 국립중앙박물관장          2\n",
       "45653  45653  2020 한국인터넷기자상 시상식 내달 1일 개최…특별상 김성후          2\n",
       "\n",
       "[45654 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.iloc[:,1:]\n",
    "test = test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "# 형태소 분석기(Okt) 불러오기 \n",
    "okt=Okt() \n",
    "\n",
    "# 조사, 어미, 구두점 제거\n",
    "def func(text):\n",
    "    clean = []\n",
    "    for word in okt.pos(text, stem=True): #어간 추출\n",
    "        if word[1] not in ['Josa', 'Eomi', 'Punctuation']: #조사, 어미, 구두점 제외 \n",
    "            clean.append(word[0])\n",
    "    \n",
    "    \n",
    "    return \" \".join(clean) \n",
    "\n",
    "train['title'] = train['title'].apply(lambda x : func(x))\n",
    "test['title'] = test['title'].apply(lambda x : func(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n",
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model()\n",
    "\n",
    "# 기본 Bert tokenizer 사용\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 커스텀 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair) \n",
    "\n",
    "#         self.sentences = [transform([i[sent_idx]]) for i in dataset.to_numpy()]\n",
    "        self.token_ids = []\n",
    "        self.valid_length =[]\n",
    "        self.segment_ids = []\n",
    "        for i in dataset.to_numpy():\n",
    "            out = transform([i[sent_idx]])\n",
    "            self.token_ids.append(out[0])\n",
    "            self.valid_length.append(out[1])\n",
    "            self.segment_ids.append(out[2])\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset.to_numpy()]\n",
    "        \n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        token_ids = self.token_ids[i]\n",
    "        valid_length = self.valid_length[i]\n",
    "        segment_ids = self.segment_ids[i]\n",
    "        return {\n",
    "            'token_ids' : torch.tensor(token_ids, dtype=torch.long),\n",
    "            'valid_length' : torch.tensor(valid_length, dtype=torch.long),\n",
    "            'segment_ids' : torch.tensor(segment_ids, dtype=torch.long),\n",
    "            'label' : torch.tensor(self.labels[i], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "max_len = 32 # 해당 길이를 초과하는 단어에 대해선 bert가 학습하지 않음\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 5\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 커스텀 모델 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes = 7, # softmax 사용 <- binary일 경우는 2\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        bert_output = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        pooler = bert_output['pooler_output']\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)\n",
    "      \n",
    "#model = BERTClassifier(bertmodel, dr_rate=0.7).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 학습 평가 지표인 accuracy 계산 -> 얼마나 타겟값을 많이 맞추었는가\n",
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af0d92c039e4ec383854c864615f4ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dacon/anaconda3/envs/pch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 1.8629302978515625 train acc 0.265625\n",
      "epoch 1 batch id 201 loss 0.6996049880981445 train acc 0.49300373134328357\n",
      "epoch 1 batch id 401 loss 0.7996517419815063 train acc 0.6878117206982544\n",
      "epoch 1 train acc 0.7144826680672269\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175b7587c0cf4747baa97133d0749f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 test acc 0.8682011554621849\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b390a0b3043b48e1aee43c9f41881f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.3858485221862793 train acc 0.890625\n",
      "epoch 2 batch id 201 loss 0.45624542236328125 train acc 0.8577425373134329\n",
      "epoch 2 batch id 401 loss 0.5289002656936646 train acc 0.8947552992518704\n",
      "epoch 2 train acc 0.8972630718954249\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbdd10d9ded494283da32753cb8bfe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 test acc 0.8720273109243697\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b67fc125aa54cebada1580e0af72063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.20861142873764038 train acc 0.90625\n",
      "epoch 3 batch id 201 loss 0.36656737327575684 train acc 0.9071828358208955\n",
      "epoch 3 batch id 401 loss 0.3397447466850281 train acc 0.934265897755611\n",
      "epoch 3 train acc 0.9378939075630253\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb08469da074862932264ce5e54e73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 test acc 0.8733403361344537\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b987d36c1433403cb5270ae1b917b56b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.1121591329574585 train acc 0.984375\n",
      "epoch 4 batch id 201 loss 0.21358102560043335 train acc 0.9469060945273632\n",
      "epoch 4 batch id 401 loss 0.21704596281051636 train acc 0.9622428304239401\n",
      "epoch 4 train acc 0.9654674369747899\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7275d49583642bfb15b3a6d34032d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 test acc 0.8773923319327731\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2799c4e9ce4bd68e9c11b689fbe823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 0.06625470519065857 train acc 0.984375\n",
      "epoch 5 batch id 201 loss 0.1298101544380188 train acc 0.9698383084577115\n",
      "epoch 5 batch id 401 loss 0.08744862675666809 train acc 0.9796991895261845\n",
      "epoch 5 train acc 0.9816504726890757\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd3fb383f2845afa4054a8c26fe8e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 test acc 0.8791465336134454\n",
      "using cached model\n",
      "using cached model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bec65ae3954dc4acaaa8db484d3edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 1.9587860107421875 train acc 0.1875\n",
      "epoch 1 batch id 201 loss 0.6254019737243652 train acc 0.5329601990049752\n",
      "epoch 1 batch id 401 loss 0.4601551294326782 train acc 0.706553927680798\n",
      "epoch 1 train acc 0.7280797735760971\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be07ac907cd486d82c549214e735bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 test acc 0.8653965336134454\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d54d66242ef48c981e69f39a42590d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.3254120349884033 train acc 0.921875\n",
      "epoch 2 batch id 201 loss 0.42282068729400635 train acc 0.8579757462686567\n",
      "epoch 2 batch id 401 loss 0.3464636206626892 train acc 0.8931187655860349\n",
      "epoch 2 train acc 0.895844275210084\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c382081aa814de9818a920b22b64909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 test acc 0.8847452731092438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326be76e01f242f182e816bbdc3c1edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.19351744651794434 train acc 0.953125\n",
      "epoch 3 batch id 201 loss 0.21963518857955933 train acc 0.910214552238806\n",
      "epoch 3 batch id 401 loss 0.22846311330795288 train acc 0.9343827930174564\n",
      "epoch 3 train acc 0.9375656512605042\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84002f4ea2894800b7143ce5f59dbc14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 test acc 0.8808902310924369\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e70ed1fc9e94db7a5ffb3fe38a4b3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.11253446340560913 train acc 0.984375\n",
      "epoch 4 batch id 201 loss 0.09374964237213135 train acc 0.9520366915422885\n",
      "epoch 4 batch id 401 loss 0.053571879863739014 train acc 0.9660614089775561\n",
      "epoch 4 train acc 0.9686515231092437\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65132ab9e2446a5a089ca18280a8625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 test acc 0.8814154411764705\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05e7de9ec1943e19fa00dab2317b360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 0.09038379788398743 train acc 0.984375\n",
      "epoch 5 batch id 201 loss 0.032305121421813965 train acc 0.9762126865671642\n",
      "epoch 5 batch id 401 loss 0.04237523674964905 train acc 0.9831281172069826\n",
      "epoch 5 train acc 0.984375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83af77a025184e98a99057590e39bdcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 test acc 0.883844537815126\n",
      "using cached model\n",
      "using cached model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378035fed723491ab08f356795bc47ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 2.1174163818359375 train acc 0.0625\n",
      "epoch 1 batch id 201 loss 0.6084966659545898 train acc 0.5509950248756219\n",
      "epoch 1 batch id 401 loss 0.96811842918396 train acc 0.7176979426433915\n",
      "epoch 1 train acc 0.7392733134920635\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d876c8441b4e6c876b7f04d4e4fdaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 test acc 0.8693172268907563\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21894c7518474f2da5f094d3261dcc7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.38549482822418213 train acc 0.90625\n",
      "epoch 2 batch id 201 loss 0.4073885679244995 train acc 0.8570429104477612\n",
      "epoch 2 batch id 401 loss 0.5986412167549133 train acc 0.8935084164588528\n",
      "epoch 2 train acc 0.8960084033613446\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938394d4fe9446c29d3b6a60020a9fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 test acc 0.8749448529411764\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0e93fe338b4904b1bf2c648fe5386a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.18147116899490356 train acc 0.953125\n",
      "epoch 3 batch id 201 loss 0.2666902542114258 train acc 0.9085820895522388\n",
      "epoch 3 batch id 401 loss 0.24250313639640808 train acc 0.9353569201995012\n",
      "epoch 3 train acc 0.9383534663865546\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22da007c6a64d62a200520ead650cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 test acc 0.8750288865546219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33fd5fa1f6284ae1ab4e37f842c725a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.035235315561294556 train acc 1.0\n",
      "epoch 4 batch id 201 loss 0.18514370918273926 train acc 0.9497046019900498\n",
      "epoch 4 batch id 401 loss 0.0731431245803833 train acc 0.965126246882793\n",
      "epoch 4 train acc 0.9680278361344538\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13c0d32e071432abd6fb932a542858e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 test acc 0.8750577731092436\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d698053ce414999871947b84926e1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 0.02078711986541748 train acc 1.0\n",
      "epoch 5 batch id 201 loss 0.12366640567779541 train acc 0.9736473880597015\n",
      "epoch 5 batch id 401 loss 0.056561797857284546 train acc 0.9818812344139651\n",
      "epoch 5 train acc 0.983390231092437\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05c4c3c388f496ea19ee6aeb404d582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 test acc 0.8790519957983193\n"
     ]
    }
   ],
   "source": [
    "best_models = [] # 폴드별로 가장 validation acc가 높은 모델 저장\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "# dirty_mnist_answer에서 train_idx와 val_idx를 생성\n",
    "best_models = [] # 폴드별로 가장 validation acc가 높은 모델 저장\n",
    "for fold_index, (trn_idx, val_idx) in enumerate(kfold.split(train['title'],train['topic_idx'])):\n",
    "    \n",
    "    # cuda cache 초기화\n",
    "    torch.cuda.empty_cache()\n",
    "    train_data = train.loc[trn_idx]\n",
    "    valid_data = train.loc[val_idx]\n",
    "\n",
    "    data_train = BERTDataset(train_data, 0, 1, tok, max_len, True, False)\n",
    "    data_test = BERTDataset(valid_data, 0, 1, tok, max_len, True, False)\n",
    "\n",
    "    # pytorch용 DataLoader 사용\n",
    "    train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "    test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)\n",
    "    bertmodel, _ = get_pytorch_kobert_model()\n",
    "    model = BERTClassifier(bertmodel, dr_rate=0.7).to(device)\n",
    "    \n",
    "    # Prepare optimizer and schedule (linear warmup and decay)\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "    # 옵티마이저 선언\n",
    "    optimizer = AdamP(optimizer_grouped_parameters, lr=learning_rate)\n",
    "    loss_fn = nn.CrossEntropyLoss() # softmax용 Loss Function 정하기 <- binary classification도 해당 loss function 사용 가능\n",
    "   \n",
    "    #scheduler\n",
    "    t_total = len(train_dataloader) * num_epochs\n",
    "    warmup_step = int(t_total * warmup_ratio)\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    valid_acc_max = 0\n",
    "    # 모델 학습 시작\n",
    "    model.train()\n",
    "    \n",
    "    for e in range(5):\n",
    "        \n",
    "        train_acc = 0.0\n",
    "        test_acc = 0.0\n",
    "        tqdm_dataset = tqdm(enumerate(train_dataloader))\n",
    "        for batch_id, items in tqdm_dataset:\n",
    "            optimizer.zero_grad()\n",
    "            token_ids = items['token_ids'].to(device)\n",
    "            segment_ids = items['segment_ids'].to(device)\n",
    "            valid_length= items['valid_length']\n",
    "            label = items['label'].to(device)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = model(token_ids, valid_length, segment_ids)\n",
    "                loss = loss_fn(out, label)\n",
    "            #loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm) # gradient clipping\n",
    "            #optimizer.step()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            scheduler.step()  # Update learning rate schedule\n",
    "            train_acc += calc_accuracy(out, label)\n",
    "            if batch_id % log_interval == 0:\n",
    "                print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "        print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "        \n",
    "        \n",
    "        model.eval() # 평가 모드로 변경\n",
    "        tqdm_dataset = tqdm(enumerate(test_dataloader))\n",
    "        for batch_id, items in tqdm_dataset:\n",
    "            token_ids = items['token_ids'].to(device)\n",
    "            segment_ids = items['segment_ids'].to(device)\n",
    "            valid_length= items['valid_length']\n",
    "            label = items['label'].to(device)\n",
    "            with torch.no_grad():\n",
    "                out = model(token_ids, valid_length, segment_ids)\n",
    "                test_acc += calc_accuracy(out, label)\n",
    "        print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n",
    "        \n",
    "                # 모델 저장\n",
    "        if valid_acc_max < test_acc:\n",
    "            valid_acc_max = test_acc\n",
    "            best_model = model\n",
    "\n",
    "\n",
    "    # 폴드별로 가장 좋은 모델 저장\n",
    "    best_models.append(best_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(best_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "# 시간 표시 함수\n",
    "def format_time(elapsed):\n",
    "\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## 1 : 번째 모델 예측 진행 ##########\n",
      "  Batch 1,000  of  9,131.    Elapsed: 0:01:25.\n",
      "  Batch 2,000  of  9,131.    Elapsed: 0:02:56.\n",
      "  Batch 3,000  of  9,131.    Elapsed: 0:04:23.\n",
      "  Batch 4,000  of  9,131.    Elapsed: 0:04:37.\n",
      "  Batch 5,000  of  9,131.    Elapsed: 0:04:47.\n",
      "  Batch 6,000  of  9,131.    Elapsed: 0:04:57.\n",
      "  Batch 7,000  of  9,131.    Elapsed: 0:05:08.\n",
      "  Batch 8,000  of  9,131.    Elapsed: 0:05:18.\n",
      "  Batch 9,000  of  9,131.    Elapsed: 0:05:28.\n",
      "########## 2 : 번째 모델 예측 진행 ##########\n",
      "  Batch 1,000  of  9,131.    Elapsed: 0:05:40.\n",
      "  Batch 2,000  of  9,131.    Elapsed: 0:05:50.\n",
      "  Batch 3,000  of  9,131.    Elapsed: 0:06:00.\n",
      "  Batch 4,000  of  9,131.    Elapsed: 0:06:11.\n",
      "  Batch 5,000  of  9,131.    Elapsed: 0:06:21.\n",
      "  Batch 6,000  of  9,131.    Elapsed: 0:06:31.\n",
      "  Batch 7,000  of  9,131.    Elapsed: 0:06:42.\n",
      "  Batch 8,000  of  9,131.    Elapsed: 0:06:52.\n",
      "  Batch 9,000  of  9,131.    Elapsed: 0:07:02.\n",
      "########## 3 : 번째 모델 예측 진행 ##########\n",
      "  Batch 1,000  of  9,131.    Elapsed: 0:07:14.\n",
      "  Batch 2,000  of  9,131.    Elapsed: 0:07:24.\n",
      "  Batch 3,000  of  9,131.    Elapsed: 0:07:34.\n",
      "  Batch 4,000  of  9,131.    Elapsed: 0:07:45.\n",
      "  Batch 5,000  of  9,131.    Elapsed: 0:07:55.\n",
      "  Batch 6,000  of  9,131.    Elapsed: 0:08:06.\n",
      "  Batch 7,000  of  9,131.    Elapsed: 0:08:16.\n",
      "  Batch 8,000  of  9,131.    Elapsed: 0:08:26.\n",
      "  Batch 9,000  of  9,131.    Elapsed: 0:08:36.\n"
     ]
    }
   ],
   "source": [
    "preds = [[0,0,0,0,0,0,0]]*9131\n",
    "#시작 시간 설정\n",
    "t0 = time.time()\n",
    "\n",
    "\n",
    "for idx,Best_Model in enumerate(best_models):\n",
    "    print('#'*10,idx+1,\": 번째 모델 예측 진행\",'#'*10)\n",
    "    \n",
    "    model = Best_Model\n",
    "    model.eval()\n",
    "    pred = []\n",
    "    for step in range(len(test)):\n",
    "        if step % 1000 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step,len(test), elapsed))\n",
    "        test_sentence = test.title[step]\n",
    "        test_label = 0\n",
    "\n",
    "\n",
    "        unseen_test = pd.DataFrame([[test_sentence, test_label]], columns = [['title', 'topic_idx']])\n",
    "        #unseen_values = unseen_test.values\n",
    "        test_set = BERTDataset(unseen_test, 0, 1, tok, max_len, True, False)\n",
    "        test_input = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "        for batch_id, items in enumerate(test_input):\n",
    "            token_ids = items['token_ids'].to(device)\n",
    "            segment_ids = items['segment_ids'].to(device)\n",
    "            valid_length= items['valid_length']\n",
    "            #label = items['label'].to(device)\n",
    "            out = model(token_ids, valid_length, segment_ids)\n",
    "            preds[step] =  [x+y for x,y in zip(preds[step],out.cpu().tolist()[0])]\n",
    "    #preds.append(pred)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(preds).T\n",
    "#df= df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9121</th>\n",
       "      <th>9122</th>\n",
       "      <th>9123</th>\n",
       "      <th>9124</th>\n",
       "      <th>9125</th>\n",
       "      <th>9126</th>\n",
       "      <th>9127</th>\n",
       "      <th>9128</th>\n",
       "      <th>9129</th>\n",
       "      <th>9130</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.667165</td>\n",
       "      <td>-3.866979</td>\n",
       "      <td>4.488541</td>\n",
       "      <td>11.860032</td>\n",
       "      <td>-3.718804</td>\n",
       "      <td>-2.755945</td>\n",
       "      <td>-4.444994</td>\n",
       "      <td>-3.753890</td>\n",
       "      <td>0.614055</td>\n",
       "      <td>-4.164204</td>\n",
       "      <td>...</td>\n",
       "      <td>16.427015</td>\n",
       "      <td>-3.262003</td>\n",
       "      <td>-4.897614</td>\n",
       "      <td>-2.985478</td>\n",
       "      <td>-6.104986</td>\n",
       "      <td>-4.418587</td>\n",
       "      <td>-5.863899</td>\n",
       "      <td>-5.362651</td>\n",
       "      <td>-1.555378</td>\n",
       "      <td>-0.616131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.521968</td>\n",
       "      <td>-6.094561</td>\n",
       "      <td>-3.294170</td>\n",
       "      <td>-4.449213</td>\n",
       "      <td>-4.559633</td>\n",
       "      <td>-6.880569</td>\n",
       "      <td>-3.786137</td>\n",
       "      <td>-5.418990</td>\n",
       "      <td>-3.187023</td>\n",
       "      <td>7.983979</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.087390</td>\n",
       "      <td>-3.760720</td>\n",
       "      <td>-0.886129</td>\n",
       "      <td>-5.732688</td>\n",
       "      <td>5.409344</td>\n",
       "      <td>-5.515036</td>\n",
       "      <td>-5.305467</td>\n",
       "      <td>-5.347836</td>\n",
       "      <td>-1.777936</td>\n",
       "      <td>-2.531429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.286655</td>\n",
       "      <td>2.031129</td>\n",
       "      <td>14.032648</td>\n",
       "      <td>7.899144</td>\n",
       "      <td>-0.005563</td>\n",
       "      <td>7.502763</td>\n",
       "      <td>-4.334594</td>\n",
       "      <td>2.862215</td>\n",
       "      <td>0.082223</td>\n",
       "      <td>-4.055860</td>\n",
       "      <td>...</td>\n",
       "      <td>2.513294</td>\n",
       "      <td>17.852494</td>\n",
       "      <td>18.372711</td>\n",
       "      <td>1.687749</td>\n",
       "      <td>16.000155</td>\n",
       "      <td>4.139222</td>\n",
       "      <td>16.646433</td>\n",
       "      <td>12.452720</td>\n",
       "      <td>16.883722</td>\n",
       "      <td>14.179807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.363702</td>\n",
       "      <td>18.977965</td>\n",
       "      <td>-3.174287</td>\n",
       "      <td>-3.796049</td>\n",
       "      <td>19.356687</td>\n",
       "      <td>15.504914</td>\n",
       "      <td>-3.385758</td>\n",
       "      <td>18.690104</td>\n",
       "      <td>-4.388184</td>\n",
       "      <td>-5.492827</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.047382</td>\n",
       "      <td>0.167450</td>\n",
       "      <td>-1.350195</td>\n",
       "      <td>19.294460</td>\n",
       "      <td>-5.450295</td>\n",
       "      <td>18.915262</td>\n",
       "      <td>-3.887768</td>\n",
       "      <td>12.494433</td>\n",
       "      <td>-0.161193</td>\n",
       "      <td>-5.725516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.919490</td>\n",
       "      <td>-3.888075</td>\n",
       "      <td>-7.066977</td>\n",
       "      <td>-4.937459</td>\n",
       "      <td>-3.478719</td>\n",
       "      <td>-4.091285</td>\n",
       "      <td>0.486040</td>\n",
       "      <td>-5.366935</td>\n",
       "      <td>16.613049</td>\n",
       "      <td>13.783195</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.423872</td>\n",
       "      <td>-5.405681</td>\n",
       "      <td>-4.487484</td>\n",
       "      <td>-3.280332</td>\n",
       "      <td>-5.767435</td>\n",
       "      <td>-4.495910</td>\n",
       "      <td>0.788115</td>\n",
       "      <td>-2.974014</td>\n",
       "      <td>-6.081923</td>\n",
       "      <td>-6.096978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-6.348941</td>\n",
       "      <td>-3.846668</td>\n",
       "      <td>-7.934662</td>\n",
       "      <td>-5.334093</td>\n",
       "      <td>-2.971946</td>\n",
       "      <td>-4.157031</td>\n",
       "      <td>20.223135</td>\n",
       "      <td>-3.670496</td>\n",
       "      <td>-5.752652</td>\n",
       "      <td>-4.497931</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.376342</td>\n",
       "      <td>-4.479762</td>\n",
       "      <td>-6.989762</td>\n",
       "      <td>-3.768748</td>\n",
       "      <td>-5.790782</td>\n",
       "      <td>-4.000992</td>\n",
       "      <td>-5.828168</td>\n",
       "      <td>-6.073047</td>\n",
       "      <td>-5.866058</td>\n",
       "      <td>-6.074246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-7.730973</td>\n",
       "      <td>-2.115520</td>\n",
       "      <td>1.842198</td>\n",
       "      <td>-2.378694</td>\n",
       "      <td>-3.727029</td>\n",
       "      <td>-4.712382</td>\n",
       "      <td>-1.446084</td>\n",
       "      <td>-2.423363</td>\n",
       "      <td>-3.561395</td>\n",
       "      <td>-3.139828</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.517046</td>\n",
       "      <td>-0.809342</td>\n",
       "      <td>0.469748</td>\n",
       "      <td>-4.331096</td>\n",
       "      <td>0.697267</td>\n",
       "      <td>-3.800290</td>\n",
       "      <td>4.088277</td>\n",
       "      <td>-5.138861</td>\n",
       "      <td>-2.363933</td>\n",
       "      <td>6.038428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 9131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0          1          2          3          4          5     \\\n",
       "0  10.667165  -3.866979   4.488541  11.860032  -3.718804  -2.755945   \n",
       "1  -2.521968  -6.094561  -3.294170  -4.449213  -4.559633  -6.880569   \n",
       "2   6.286655   2.031129  14.032648   7.899144  -0.005563   7.502763   \n",
       "3   3.363702  18.977965  -3.174287  -3.796049  19.356687  15.504914   \n",
       "4  -4.919490  -3.888075  -7.066977  -4.937459  -3.478719  -4.091285   \n",
       "5  -6.348941  -3.846668  -7.934662  -5.334093  -2.971946  -4.157031   \n",
       "6  -7.730973  -2.115520   1.842198  -2.378694  -3.727029  -4.712382   \n",
       "\n",
       "        6          7          8          9     ...       9121       9122  \\\n",
       "0  -4.444994  -3.753890   0.614055  -4.164204  ...  16.427015  -3.262003   \n",
       "1  -3.786137  -5.418990  -3.187023   7.983979  ...  -1.087390  -3.760720   \n",
       "2  -4.334594   2.862215   0.082223  -4.055860  ...   2.513294  17.852494   \n",
       "3  -3.385758  18.690104  -4.388184  -5.492827  ...  -4.047382   0.167450   \n",
       "4   0.486040  -5.366935  16.613049  13.783195  ...  -5.423872  -5.405681   \n",
       "5  20.223135  -3.670496  -5.752652  -4.497931  ...  -5.376342  -4.479762   \n",
       "6  -1.446084  -2.423363  -3.561395  -3.139828  ...  -4.517046  -0.809342   \n",
       "\n",
       "        9123       9124       9125       9126       9127       9128  \\\n",
       "0  -4.897614  -2.985478  -6.104986  -4.418587  -5.863899  -5.362651   \n",
       "1  -0.886129  -5.732688   5.409344  -5.515036  -5.305467  -5.347836   \n",
       "2  18.372711   1.687749  16.000155   4.139222  16.646433  12.452720   \n",
       "3  -1.350195  19.294460  -5.450295  18.915262  -3.887768  12.494433   \n",
       "4  -4.487484  -3.280332  -5.767435  -4.495910   0.788115  -2.974014   \n",
       "5  -6.989762  -3.768748  -5.790782  -4.000992  -5.828168  -6.073047   \n",
       "6   0.469748  -4.331096   0.697267  -3.800290   4.088277  -5.138861   \n",
       "\n",
       "        9129       9130  \n",
       "0  -1.555378  -0.616131  \n",
       "1  -1.777936  -2.531429  \n",
       "2  16.883722  14.179807  \n",
       "3  -0.161193  -5.725516  \n",
       "4  -6.081923  -6.096978  \n",
       "5  -5.866058  -6.074246  \n",
       "6  -2.363933   6.038428  \n",
       "\n",
       "[7 rows x 9131 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(preds,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub['topic_idx'] = pred\n",
    "#sub.to_csv('3fold.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
