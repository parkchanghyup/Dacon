{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "from transformers import AdamW\n",
    "from adamp import AdamP\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "from transformers import AutoTokenizer, ElectraForSequenceClassification, AdamW\n",
    "\n",
    "##GPU 사용 시\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0+cu111'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45654, 3)\n",
      "(9131, 2)\n"
     ]
    }
   ],
   "source": [
    "# 학습용 데이터셋 불러오기\n",
    "import pandas as pd\n",
    "# 판다스로 훈련셋과 테스트셋 데이터 로드\n",
    "train = pd.read_csv('train_data.csv')\n",
    "test = pd.read_csv('test_data.csv')\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.iloc[:,1:]\n",
    "test = test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기(Okt) 불러오기 \n",
    "okt=Okt() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조사, 어미, 구두점 제거\n",
    "def func(text):\n",
    "    clean = []\n",
    "    for word in okt.pos(text, stem=True): #어간 추출\n",
    "        if word[1] not in ['Josa', 'Eomi', 'Punctuation']: #조사, 어미, 구두점 제외 \n",
    "            clean.append(word[0])\n",
    "    \n",
    "    \n",
    "    return \" \".join(clean) \n",
    "\n",
    "#train['title'] = train['title'].apply(lambda x : func(x))\n",
    "test['title'] = test['title'].apply(lambda x : func(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bertmodel, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape is: 36523\n",
      "valid shape is: 9131\n"
     ]
    }
   ],
   "source": [
    "# Train / Test set 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, valid = train_test_split(train, test_size=0.2, random_state=42)\n",
    "print(\"train shape is:\", len(train))\n",
    "print(\"valid shape is:\", len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ElectraModel, ElectraTokenizer\n",
    "\n",
    "#model = ElectraModel.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "tok = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class koelectradataset(Dataset):  \n",
    "    def __init__(self, dataset,max_len,bert_tokenizer):\n",
    "        \n",
    "        self.tokenizer = bert_tokenizer\n",
    "        self.dataset = dataset\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataset.iloc[idx, :2].values\n",
    "        text = row[0]\n",
    "        y = row[1]\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            text, \n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "            max_length=max_len,\n",
    "            pad_to_max_length=True,\n",
    "            add_special_tokens=True\n",
    "            )\n",
    "    \n",
    "        input_ids = inputs['input_ids'][0]\n",
    "        attention_mask = inputs['attention_mask'][0]\n",
    "\n",
    "        return input_ids, attention_mask, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 64\n",
    "train_dataset = koelectradataset(train,max_len,tok)\n",
    "test_dataset = koelectradataset(valid,max_len,tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-base-v3-discriminator\",num_labels  =7).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 128\n",
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "# 옵티마이저 선언\n",
    "optimizer = AdamP(optimizer_grouped_parameters, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## 1 epoch start ##############################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d49056fa7e44fd911bbf181e6d0575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dacon/anaconda3/envs/pch/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2126: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 177.07592499256134 Accuracy: 0.36375\n",
      "Batch Loss: 284.4376451969147 Accuracy: 0.5587109375\n",
      "Train Loss: 339.235979616642 Train Accuracy: 0.6453741477972784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d997aea67ba4ee2a61a34520a9ac4bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid  Accuracy: 0.8679224619428321\n",
      "\n",
      "\n",
      "############################## 2 epoch start ##############################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba511fd3ef94ce79d93d14a341a1423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 49.173006534576416 Accuracy: 0.869921875\n",
      "Batch Loss: 93.21230611205101 Accuracy: 0.8713671875\n",
      "Train Loss: 233.59542471170425 Train Accuracy: 0.7595898474933603\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0624eb084ecc4d35b394b000f737b490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid  Accuracy: 0.8774504435439711\n",
      "\n",
      "\n",
      "############################## 3 epoch start ##############################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac00723d01314fcb8f1b1d063fce04c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 37.18137355148792 Accuracy: 0.886953125\n",
      "Batch Loss: 73.28861501812935 Accuracy: 0.888984375\n",
      "Train Loss: 192.48561105132103 Train Accuracy: 0.8004088747729741\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb5947f5dfd438db1b4ab342c7eae93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid  Accuracy: 0.8636512977768043\n",
      "\n",
      "\n",
      "############################## 4 epoch start ##############################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08af26cc818f420daaea74fdccc47af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 37.954682528972626 Accuracy: 0.881640625\n",
      "Batch Loss: 74.79807116091251 Accuracy: 0.8821484375\n",
      "Train Loss: 171.0097978375852 Train Accuracy: 0.8206267283629494\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de9a0d13a57431baa23a5f8f5014c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid  Accuracy: 0.882488226919286\n",
      "\n",
      "\n",
      "############################## 5 epoch start ##############################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d6c5b51019491b98974429c4715edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 32.332585245370865 Accuracy: 0.897578125\n",
      "Batch Loss: 66.58066669106483 Accuracy: 0.89359375\n",
      "Train Loss: 155.78937041461467 Train Accuracy: 0.8352380691618979\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48e1c0ac08b4d85a69a01a9266f4b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid  Accuracy: 0.8836929142481655\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    print('#'*30,i+1,'epoch start','#'*30)\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batches = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for input_ids_batch, attention_masks_batch, y_batch in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        y_batch = y_batch.to(device)\n",
    "        y_pred = model(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0]\n",
    "        loss = F.cross_entropy(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        predicted = torch.argmax(y_pred, 1)\n",
    "        correct += (predicted == y_batch).sum()\n",
    "        total += len(y_batch)\n",
    "\n",
    "        batches += 1\n",
    "        if batches % 100 == 0:\n",
    "            print(\"Batch Loss:\", total_loss, \"Accuracy:\", correct.cpu().numpy() / total)\n",
    "\n",
    "    losses.append(total_loss)\n",
    "    accuracies.append(correct.cpu().numpy() / total)\n",
    "    print(\"Train Loss:\", sum(losses) / len(losses), \"Train Accuracy:\", sum(accuracies) / len(accuracies))\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    for input_ids_batch, attention_masks_batch, y_batch in tqdm(test_loader):\n",
    "        y_batch = y_batch.to(device)\n",
    "        y_pred = model(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0]\n",
    "        predicted = torch.argmax(y_pred, 1)\n",
    "        test_correct += (predicted == y_batch).sum()\n",
    "        test_total += len(y_batch)\n",
    "\n",
    "    print(\"valid  Accuracy:\", test_correct.cpu().numpy() / test_total)\n",
    "    print()\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pred'] = 0\n",
    "test_dataset = koelectradataset(test,max_len,tok)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>유튜브 내달 2일까지 크리에이터 지원 공간 운영</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>어버이날 맑다가 흐려져…남부지방 옅은 황사</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>내년부터 국가RD 평가 때 논문건수는 반영 않는다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>김명자 신임 과총 회장 원로와 젊은 과학자 지혜 모을 것</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>회색인간 작가 김동식 양심고백 등 새 소설집 2권 출간</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9126</th>\n",
       "      <td>인천 오후 3시35분 대설주의보…눈 3.1cm 쌓여</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9127</th>\n",
       "      <td>노래방에서 지인 성추행 외교부 사무관 불구속 입건종합</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9128</th>\n",
       "      <td>40년 전 부마항쟁 부산 시위 사진 2점 최초 공개</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9129</th>\n",
       "      <td>게시판 아리랑TV 아프리카개발은행 총회 개회식 생중계</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9130</th>\n",
       "      <td>유영민 과기장관 강소특구는 지역 혁신의 중심…지원책 강구</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9131 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title  pred\n",
       "0          유튜브 내달 2일까지 크리에이터 지원 공간 운영     0\n",
       "1             어버이날 맑다가 흐려져…남부지방 옅은 황사     0\n",
       "2         내년부터 국가RD 평가 때 논문건수는 반영 않는다     0\n",
       "3     김명자 신임 과총 회장 원로와 젊은 과학자 지혜 모을 것     0\n",
       "4      회색인간 작가 김동식 양심고백 등 새 소설집 2권 출간     0\n",
       "...                               ...   ...\n",
       "9126     인천 오후 3시35분 대설주의보…눈 3.1cm 쌓여     0\n",
       "9127    노래방에서 지인 성추행 외교부 사무관 불구속 입건종합     0\n",
       "9128     40년 전 부마항쟁 부산 시위 사진 2점 최초 공개     0\n",
       "9129    게시판 아리랑TV 아프리카개발은행 총회 개회식 생중계     0\n",
       "9130  유영민 과기장관 강소특구는 지역 혁신의 중심…지원책 강구     0\n",
       "\n",
       "[9131 rows x 2 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472160bfb4a04a8d92400646f67a6bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/143 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dacon/anaconda3/envs/pch/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2126: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 평가모드로 변경\n",
    "model.eval()\n",
    "\n",
    "pred = []\n",
    "for input_ids_batch, attention_masks_batch, y_batch in tqdm(test_loader):\n",
    "    y_batch = y_batch.to(device)\n",
    "    y_pred = model(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0]\n",
    "    predicted = torch.argmax(y_pred, 1)\n",
    "    #test_correct += (predicted == y_batch).sum()\n",
    "    #test_total += len(y_batch)\n",
    "    pred.extend(predicted.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9131"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "max_len = 64 # 해당 길이를 초과하는 단어에 대해선 bert가 학습하지 않음\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 5\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes = 7, # softmax 사용 <- binary일 경우는 2\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = ElectraModel.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        bert_output = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        pooler = bert_output['pooler_output']\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)\n",
    "      \n",
    "model = BERTClassifier(model, dr_rate=0.7).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "# 옵티마이저 선언\n",
    "optimizer = AdamP(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss() # softmax용 Loss Function 정하기 <- binary classification도 해당 loss function 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train = BERTDataset(train, 0, 1, tok, max_len, True, False)\n",
    "# data_test = BERTDataset(valid, 0, 1, tok, max_len, True, False)\n",
    "\n",
    "# # pytorch용 DataLoader 사용\n",
    "# train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "# test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 학습 평가 지표인 accuracy 계산 -> 얼마나 타겟값을 많이 맞추었는가\n",
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "# 시간 표시 함수\n",
    "def format_time(elapsed):\n",
    "\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "#시작 시간 설정\n",
    "t0 = time.time()\n",
    "\n",
    "\n",
    "for idx,Best_Model in enumerate(best_models):\n",
    "    print('#'*10,idx+1,\": 번째 모델 예측 진행\",'#'*10)\n",
    "    \n",
    "    model = Best_Model\n",
    "    model.eval()\n",
    "    pred = []\n",
    "    for step in range(len(test)):\n",
    "        if step % 1000 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step,len(test), elapsed))\n",
    "        test_sentence = test.title[step]\n",
    "        test_label = 0\n",
    "\n",
    "\n",
    "        unseen_test = pd.DataFrame([[test_sentence, test_label]], columns = [['title', 'topic_idx']])\n",
    "        #unseen_values = unseen_test.values\n",
    "        test_set = BERTDataset(unseen_test, 0, 1, tok, max_len, True, False)\n",
    "        test_input = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "        for batch_id, items in enumerate(test_input):\n",
    "            token_ids = items['token_ids'].to(device)\n",
    "            segment_ids = items['segment_ids'].to(device)\n",
    "            valid_length= items['valid_length']\n",
    "            #label = items['label'].to(device)\n",
    "            out = model(token_ids, valid_length, segment_ids)\n",
    "            pred.append(int(torch.argmax(out).cpu().numpy()))\n",
    "    preds.append(pred)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(preds).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.mode(axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['topic_idx'] = df\n",
    "sub['topic_idx'] = sub['topic_idx'].apply(lambda x : int(x))\n",
    "#sub.to_csv('hyup_전처리 x drop_out:0.7.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "# 테스트 데이터 예측\n",
    "\n",
    "#시작 시간 설정\n",
    "t0 = time.time()\n",
    "\n",
    "# 평가모드로 변경\n",
    "model.eval()\n",
    "\n",
    "pred = []\n",
    "for step in range(len(test)):\n",
    "    if step % 500 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step,len(test), elapsed))\n",
    "    test_sentence = test.title[step]\n",
    "    test_label = 0\n",
    "\n",
    "\n",
    "    unseen_test = pd.DataFrame([[test_sentence, test_label]], columns = [['title', 'topic_idx']])\n",
    "    #unseen_values = unseen_test.values\n",
    "    test_set = BERTDataset(unseen_test, 0, 1, tok, max_len, True, False)\n",
    "    test_input = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "    for batch_id, items in enumerate(test_input):\n",
    "        token_ids = items['token_ids'].to(device)\n",
    "        segment_ids = items['segment_ids'].to(device)\n",
    "        valid_length= items['valid_length']\n",
    "        #label = items['label'].to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        pred.append(int(torch.argmax(out).cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['topic_idx'] = pred\n",
    "#sub['topic_idx'] = sub['topic_idx'].apply(lambda x : int(x))\n",
    "#sub.to_csv('hyup_전처리 x drop_out:0.7.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol =  pd.read_csv('solution_sample.csv')\n",
    "#sol2 = pd.read_csv('solution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2 = pred[0:len(sol)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>topic_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45654</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45655</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45656</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45657</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45658</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4560</th>\n",
       "      <td>50214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>50215</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>50216</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4563</th>\n",
       "      <td>50217</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4564</th>\n",
       "      <td>50218</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4565 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  topic_idx\n",
       "0     45654          3\n",
       "1     45655          3\n",
       "2     45656          2\n",
       "3     45657          2\n",
       "4     45658          3\n",
       "...     ...        ...\n",
       "4560  50214          1\n",
       "4561  50215          2\n",
       "4562  50216          4\n",
       "4563  50217          5\n",
       "4564  50218          6\n",
       "\n",
       "[4565 rows x 2 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8414019715224534"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(sol.topic_idx, sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pch",
   "language": "python",
   "name": "pch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
